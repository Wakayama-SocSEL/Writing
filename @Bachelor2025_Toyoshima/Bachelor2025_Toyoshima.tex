\documentclass[11pt]{jreport}
\usepackage{wuse_thesis}
\usepackage{indentfirst}
\usepackage{url}	% \url{}コマンド用．URLを表示する際に便利
\usepackage[dvipdfmx]{graphicx,xcolor}
\usepackage{listings}
\lstset{
  basicstyle={\ttfamily},
  identifierstyle={\small},
  commentstyle={\smallitshape},
  keywordstyle={\small\bfseries},
  ndkeywordstyle={\small},
  stringstyle={\small\ttfamily},
  frame={tb},
  captionpos=t,
  breaklines=true,
  columns=[l]{fullflexible},
  numbers=left,
  xrightmargin=0zw,
  xleftmargin=3zw,
  numberstyle={\scriptsize},
  stepnumber=1,
  numbersep=1zw,
  lineskip=-0.5ex
}
\usepackage{siunitx}
\sisetup{group-separator={,}} % 3桁ごとにコンマを入れる設定
%\usepackage{graphicx}  % ←graphicx.styを用いてEPSを取り込む場合有効にする
			% 他のパッケージ・スタイルを使う場合には適宜追加
\newcommand{\todo}[1]{\colorbox{yellow}{{\bf TODO}:}{\color{red} {\textbf{[#1]}}}}
\newcommand{\memo}[1]{\colorbox{magenta}{\textbf{MEMO}}{\color{red}\textbf{[#1]}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% 主に表紙を作成するための情報
%%

%%  タイトル(修論の場合は英語表記も指定)
\title{大規模言語モデルによるソースコード生成のための最適化プロセスと反復プロセス}
%\etitle{Test\\Test\\Test}

%%  著者名(修論の場合は英語表記も指定)
\author{豊嶋 浩基}
%\eauthor{Akinori Ihara}

%% 卒業論文・修士論文(以下のどちらかを選択)
\bachelar	% 卒業論文(4年生用)
%\master  	% 修士論文(M2用)

%%  学科・クラスタ
\department{システム工}
%\department{デザイン情報}
%\department{デザイン科学}

%%  学生番号
\studentid{60276157}

%%  卒業年度
\gyear{2025}		% 提出年が2022年なら，2021年度

%%  論文提出日
\date{2026年2月10日}	% 修士の場合は月(2021年2月)までとし，英語表記も指定
%\edate{February 2021}	% 修士の場合，こちら(英語表記)も有効化

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

%%
%%  概要
%%
\begin{abstract}
大規模言語モデル(LLM) はソフトウェア開発自動化に大きく貢献するが，複雑な要件を持つソフトウェア開発の実現には課題が多い．
本研究は，このような課題の解決に向けて，自然言語からソースコードを自動生成するマルチエージェント型のプラットフォームChatDevを拡張する．
具体的には，few-shot学習を用いた要件の細分化と各ステップの開発を行う大規模言語モデル に要件の全体概要の学習によるソースコード自動生成並びに，生成ステップ毎の差分行数に基づく要件の統合及び，統合結果を分割例と再分割を組み合わせた反復的に進める開発プロセスを提案する．
ケーススタディとして，競技プログラミングサイトであるAtCoderの問題を題材に，この提案手法を実施した結果，few-shot学習と全体概要の共有の組み合わせによりテスト通過率が向上し，統合に基づく要件の再分割により生成されたソースコードはさらにテスト通過率が向上することを明らかにした．
\begin{quote}
  \begin{description}
    \item[\tt wuse\_thesis.sty:] 卒業/修士論文用スタイルファイル
    \item[\tt thesis\_sample.tex:] スタイルファイル利用例
  \end{description}
\end{quote}
からなる．

なお，この卒業論文用スタイルファイル(p\LaTeX 版)に関する質問は，
メールにて
\begin{quote}
ihara@wakayama-u.ac.jp
\end{quote}
まで．

\end{abstract}

%%  目次
\tableofcontents

%%  図目次 (図目次をいれたければ以下のコメントをはずす)
%\listoffigures

%%  表目次 (表目次をいれたければ以下のコメントをはずす)
%\listoftables

\newpage
\pagenumbering{arabic}	% 以降のページ番号を算用数字に

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%%  本文はここから
%%

\chapter{はじめに}

大規模言語モデル(LLM)技術の急速な発展に伴い\todo{引用}，大規模言語モデルはこれまで人間が時間や労力をかけて取り組んできたタスクの自動化を実現し，幅広い分野において作業を効率化する技術として関心を集めている．
ソフトウェア開発においても同様に，コードレビュー，リファクタリング，テストケース生成など，様々な場面において飛躍的に生産性を向上させることが確認されている．\todo{引用，引用，引用} 
その中でも，開発者の意図や要件をプロンプトとして提示し，ソースコードを自動生成するタスクに対して大きな期待が寄せられている．

大規模言語モデルは，自然言語で記述された要求文に基づきソースコードの自動生成を実現し，昨今では複雑で，大規模なソフトウェア開発の自動化に向けた研究が進められている．\todo{引用} 
規模が小さいソフトウェア開発の自動化に向けた研究が進められている\todo{引用}．
規模が小さいソフトウェアの要求は実現できる一方で，ソフトウェア要件が複数内包し，それぞれが相互に依存し合う大規模なソフトウェア要件を満たすソースコード生成には課題が多い．
従来研究ではソフトウェア要件が複雑になると，大規模言語モデル が十分に推論せずに，短絡的なソースコードを生成することが示されている\todo{引用}．
例えば，仕様の一部が欠損している場合や，要件の文脈を正しく理解できない場合には，生成されるコードの構造的なロジックの誤りが見られることがある．
これは，要件文から要求を抽出し，それらを元にソースコードを生成する，という流れを大規模言語モデルが実施するが，複雑な要件からソースコードを生成する場合，大規模言語モデルは要件を元にソースコードの生成を行うため，要求から抽出される要件の誤りが，不完全なソースコードを生成する原因の1つであると考えられる．

大規模言語モデル の理解や推論を補助するプロンプト技術として，思考の過程を明示的に示すChain of Thought (CoT) や，要求を満たす例を少数提示するfew-shot 学習が用いられてる\todo{引用}．
これらは局所的な推論の補完や思考パターンの学習には有効である一方で，プログラミング言語のように記述方法や実装方法によって同一の要件に対して多様な解が存在する領域では，これらの手法のみでは十分な性能を発揮しにくい．

これに対して先行研究では，全体の流れから要件を抽出するフェーズと，それらを基にソースコードを生成するフェーズの2 つに分割する手法が取り入れられてい\todo{引用}．
前者では，大量のデータ収集やそれに対するラベリング，再学習などを要するファインチューニングと比較して，追加学習することなく大規模言語モデル の挙動を制御できるfew-shot 学習が採用されている．
当該研究では，複数の各機能を並列に生成し，生成されたすべてのソースコード片の結合時に，各断片における前提が共有されず，関数やファイル単位での依存関係や，グローバル変数の扱いや，エラーハンドリングなど，ソースコード単位での整合性が破綻する課題に言及している．

本研究では，従来研究\todo{引用} の要求抽出の不安定さや，段階的開発におけるソースコードの断片化の課題解決に向けて，複雑な要件の細分化および，細分化した要件ごとの開発における全体整合を実施することでソースコード自動生成を実現する．
さらに，細分化した要件をベースとして生成したソースコードを評価し，要件の統合と再分割によるソースコード自動生成を複数回繰り返すことでプロンプト作成の最適化を目指す開発プロセスを提案する．
本手法により，各工程において大規模言語モデル に対して全体概要を明示的に提示し，分割した要件の統合と再分割を繰り返すことで，マルチエージェント型ソースコード自動生成の品質を向上を期待する．

論文構成は以下の通りである．
2章で本研究で使用するプラットフォームや，キーアイディアのベースとなる先行研究について，3章ではそれらに基づいたアプローチを述べ，4章でそのアプローチに関する実験設定やRQ列挙し，5章でそれに対する結果を，6章と7章ででそれらを基にした考察と妥当性の脅威について議論した上で，8章で結論を述べる．

\chapter{ソフトウェア開発における大規模言語モデルの活用} \memo{関連研究っぽくする}
\section{ソフトウェア開発工程の大規模言語モデルによる再現・自動化}
\subsection{工程ベースでの自動化}
大規模言語モデルを活用したソフトウェア開発の全プロセスの自動化を目的としたシステムとして，MetaGPT，AutoDev などの開発が盛んに進められている \todo{引用，引用}．
本システムは，ソフトウェア開発プロセスにおける各工程（要求定義，設計，実装，テスト，保守）を自然言語理解と生成能力により自動化する仕組みである．
本研究では，各工程の役割を担う大規模言語モデル エージェントがそれぞれ要件定義から実装までを実現するChatDev\todo{引用}を用いる．

ChatDev は，要件定義，設計，実装をウォーターフォールモデルに則って開発を進める過程で，各工程においてプログラマやプロダクトマネージャといった役割を与えられた2つの大規模言語モデル エージェントが対話しながら開発を行うプラットフォームである．
各工程では，開発を担当するエージェントが，プロンプトで与えられた要件文，または前工程で生成された成果物（ソースコード）に基づき，新たな成果物を生成する．
生成した成果物は別の検証を担当するエージェントと共有される．共有を受けたエージェントは，成果物を検証し，開発と検証を担当するエージェント間で合意形成を図って，成果物を完成させる．

ChatDev の枠組みは，各工程のタスクが明確である点や，フレームワークがオープンソースとして公開されており，自体の構造の確認や書き換えが可能であるため，拡張性に優れている．
一方で，各工程で開発を担当する大規模言語モデルに対して，同一の要件（プロンプト）が与えられるため，多数の機能を内包するような複雑・大規模な要件の場合，各フェーズでのタスクの粒度が大きくなり，不完全なソースコードが生成されやすくなってしまう．

\subsection{複雑な要求の分割に基づくコード生成}
Jiang ら\todo{引用(TOSEM)} は，few-shot により大規模言語モデル を用いて要求文から小さな実装単位の要件に分割する「計画フェーズ」と，分割後の要件を基に開発を行なっていく実装フェーズを組み合わせた手法を提案している．計画フェーズにおいてfew-shot 学習として分割例を入力して要求文を分割することで，分割した要件を最適な粒度に均一化する事を目指している．
このように，当該研究が提案する分割後要件の粒度の最適化を図る「要件の細分化」と「細分化後要件の統合と再分割」は，大規模言語モデル の推論の最適化プロセスの1つとして重要であると考えられる．
さらに実装フェーズにおいては，分割後の要件文を個別に並行的に実装していくのではなく，開発順序を定めるガイドとして順次参照しつつ，全体を一体として一括で生成する構成が最も高性能であると報告されている．
これは，複数の要件からソースコードに並行して生成し，最終的に結合を行う方式は，コンテキストの欠如により，インタフェースやデータ構造の不整合が発生する可能性が高くなると言及されている．

本研究では，プロンプトとその時点で作成された成果物を基に開発を行う構造へとChatDevを変化させる事で段階的開発を実施しながらも，断片化を回避する手法について調査する．
\todo{断片化をはじめとする説明不足箇所の修正}


\section{要求分割と分割粒度}

\subsection{大規模言語モデルにとって好ましい分割粒度}
Shojaee ら\todo{引用} は，複雑度の制御が可能かつ，解法が明確な数学的パズル問題を用いて，大規模言語モデル の最終的な解とそこに至るまでの推論過程を調査した．その結果，難易度が上昇するにつれて正答率は緩やかに低下すると同時に，複雑度が一定の閾値を超えるまでは推論過程での思考量が増加した．一方で，複雑度が一定の閾値を超えると思考量は急減し，推論が打ち切られ，大規模言語モデル の推論精度が低下することが確認された．加えて，推論過程の調査により，複雑度が低い場合は正解まで早く到達するが，その後も不要に探索を続けてしまう過剰な推論ステップを踏むことが確認された．このような大規模言語モデル の挙動は，高い推論能力を要する自然言語からのソースコード自動生成においても同様に発生し得るものである．複数の要求を内包する複雑な要件文からは，依存関係の見落としや，断片化したソースコードの生成により，全体整合性の破綻が発生しやすい．

\subsection{分割粒度が生成品質に与える影響}
大規模言語モデルを用いたコード生成では，要求をそのまま一括で実装させるのではなく，要求を複数の要件に分割を行い，計画・実装という順で段階的に開発を進める手法が検討されている\todo{引用(TOSEM)}．
この際重要となるのが，要求をどの程度の大きさに区切るのか，即ち分割粒度である．
分割粒度は，分割する際の要件数だけでなく，各要件が内包する処理の範囲や抽象度などとして捉えられる．
分割粒度の設計を誤ると，大規模言語モデルに対する理解孵化の増大化により，生成品質の低下が発生する恐れがある．

分割粒度が粗すぎる，即ち要件1つあたりの粒度が大きすぎる場合，大規模言語モデルは入出力条件や例外処理，データ構造などをはじめとする多くの制約を保持しながら実装する必要がある．
その結果，仕様の取りこぼしや，局所最適的実装などが発生しやすくなる．

一方で，分割粒度が細かすぎる場合にも問題が発生する．分割後要件を独立に実装して，後々に結合する実装を取る場合，大規模言語モデルが学習可能なコンテキストが限定され，関数名や引数，戻り値などのインタフェース，共有するデータ構造．前提条件の齟齬などが発生しやすい．
また，統合やレビュー・再生成などの回数が増加することから，運用上のコストが増大するなども考えられる．

以上のことから，要件の分割には大規模言語モデルが生合成を保ちながら扱うことのできる分割単位を見極める必要がある事が考えられる．



\subsection{たいせな}
\todo{ワンチャン消す}

\section{本研究の位置付け}
\todo{分割粒度の再検討をここに置く？参考文献と離れるから要検討}

LLMを用いたソフトウェア開発支援・自動化の研究は大きく分けて，要件定義から実装・テストまでを工程として分担し，複数のLLMエージェントの協調によって開発プロセス全体を再現するアプローチと，複雑な要求を小さな実装単位へ分割し，計画に基づいて段階的にコードの生成を行うアプローチに整理することが出来る．
前者の代表例としてChatDevは，ウォーターフォールモデルの工程に役割を当てたエージェント同士が対話と開発途中のコードの共有を行いながらコードを生成する枠組みを提供する一方で，要求文を分割して段階的に開発を進める仕組みは想定されておらず，単一プロンプトに依存する為，複雑な応急では各工程のタスク粒度が過大になりやすい．
後者の要求分割ベースのアプローチは，分割によって一括で生成させる場合と比較して大規模言語モデルにかかる理解負荷を軽減する一方で，要件感の断片化や全体整合の崩れが発生し得る．

以上を踏まえ，本研究で，要求文の分割による段階的開発をベースとしつつ，随時成果物の共有を行う工程ベースのChatDevを取り入れる事により，開発の断片化と取りこぼしの抑制を抑えたコードの生成を可能にすることを目指す．
 

\chapter{段階的開発と分割粒度の再検討}
\section{アプローチ概要}
従来の ChatDev\todo{引用} は，単一のプロンプトから設計，実装，コードレビュー，テストのようにウォーターフォールモデルの流れを実施し，ソースコードを生成している．
ChatDev は従来研究 \todo{引用} において，要求文を分割して，段階的に開発を進める仕組みを持たない．
それに対して本研究では，分割された要件文からそれに対応する開発が実施できるように構造を拡張し，ソフトウェア生成の精度向上を目指す．
具体的には，本手法は要求文を要件に細分化する「計画フェーズ」と，細分化された要件を基にソースコードの生成を行う「実装フェーズ」, 実装フェーズで生成されたソースコードを基に要件の統合と再分割を実施する「再計画フェーズ」の3フェーズで構成する．図\ref{approach_abst}は，本手法の概略図を示す．

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{./Toyoshima_fig/approach_abst.pdf}
    \caption{アプローチ概要}
    \label{approach-abst}
\end{figure}

計画フェーズは，ソフトウェアの要求文を 大規模言語モデル に対してfew-shot 学習を実施することで，要求文を要件に細分化する．

実装フェーズは，細分化された要件をウォーターフォールモデルの流れで段階的にそれぞれ実装を進める．
各ステップで 大規模言語モデル には3 種類のデータを入力する．
(1) 実装する要件文，(2) 分割前の要求文，(3) 2つ目以降の要件の実装時には，それまでに開発された成果物．
これらのデータに基づき，各要件を 大規模言語モデル により実装する．

再計画フェーズでは，計画フェーズで要求文から分割された要件の粒度が過大・過少により生成されるソースコードがテストを通過しないケースを考慮し，実装フェーズまでで生成したソースコードを基に，計画フェーズで要求文から分割された要件群の統合を実施する．

分割されたソースコードの結果を基に要件の統合を実施し，統合した要件大規模言語モデル に学習させる事により要求から要件への再分割を実施する．
統合した要件から生成されたソースコードに対しても同様に入出力テストを実施し，統合によるソースコードの劣化が発生するかを調査する．

そして，これらの3つのフェーズを反復する事により，要求の分割粒度を最適化を図ることで，テスト通過率の高いソースコードを生成する手法の提案を目指す．


\section{計画フェーズ}

要求文の分割は，異なる開発者が行うと分割粒度が異なることも少なくない \todo{引用}．
大規模言語モデル も同様に，共通した粒度で要求文を要件に分割することは容易でない．
本手法では，評価対象とは別のソフトウェア開発における要求文を手動で要件に分割した結果を few-shot 学習を行った 大規模言語モデル モデルを用いて，要求文の分割を実施する．
Listing \ref{split_prompt}は，要求文を分割するプロンプトの一部を抜粋したものである．

\begin{lstlisting}[caption={要求文分割プロンプト（一部抜粋）},label={split_prompt}]
# Role
You are an expert in software requirements elicitation.

# Objective
From an AtCoder problem statement and its constraints, extract the requirements and split them into 10 or fewer subtasks.

# Requirements
- Identify the input format and state how it will be handled in the first requirement.
- Decide which function to pass the given arguments to, and name functions/variables wherever possible.
- Mention the output format in the last requirement.
- Think of this as converting a story-like text into a list of implementable events.
- Return only the subtask list (no extra commentary).
\end{lstlisting}

few-shot 学習に用いるソフトウェア開発データは，分割後の要件に基づき 大規模言語モデル で生成したソースコードが入出力テストを全て通過しているものとする．
また，分割時に「重要な機能であればあるほど前方に配置する」という命令を与え，ソースコードの主要処理から実装するように実装する順番も 大規模言語モデル が決定する．
実装する順に要件には，r1，r2，r3，. . . ,rn のようにラベルを付与する．


\section{実装フェーズ}
実装フェーズは，各要件を満たすソースコードを 大規模言語モデルを用いて生成する．
Jiang らは，分割した要件のみに基づき，各要件を実現するソースコードを並行して生成する場合，要求間の断片化が発生し，全体整合性が崩壊するという課題が発生している \todo{引用}． 
本研究は，要件 r1 に加え，要求文を 大規模言語モデル に入力し，ソースコードを生成する．
Listing \ref{sample_prompt}は，開発を担当する 大規模言語モデル へ与えるプロンプトの一部を抜粋したものである．

\begin{lstlisting}[caption={実装を行う LLM へ与えるプロンプト例},label={sample_prompt}]
"Programmer_2": [
"You are Programmer_1 at ChatDev. Focus subtask: {subtask2}.",
"The overall outline of the project is as follows: {overall_task}",
"Strictly follow the current phase’s Output rules.",
"Constraints: single file 'main.py'; STDIN/STDOUT only; stdlib only; no extra logs.",
"Respect any required region markers (e.g., '# [SUBTASK 2 START]' / '# [SUBTASK 2 END]'); do NOT add '__main__' unless asked.",
"Output EXACTLY ONE file in the requested format: start with 'FILENAME: main.py' then a single code block."
]
\end{lstlisting}


ここで生成されたソースコード一式をスナップショット 1 (S1) とする．次の要件要件 r2 は，要求文と前の要件 r1 で生成したスナップショット 1S1 を入力とし，ソースコードを生成する．
ここで生成されたソースコード一式をスナップショット 2 (S2) とする．
このように，本研究では従来研究のような要件のみでソースコードを生成するのとは異なり，要求文と前の要件で生成したスナップショットも入力として用いる．

\section{再計画フェーズ}
再計画フェーズでは，スナップショットの追加行数に基づく要件の統合と，統合した結果を用いた再分割を実施する．

2.2 節で示したように，要件に対する実装量が過度に小さい場合，大規模言語モデル の注意資源や推論能力を必要以上に消費し，意図しない要件を実装する可能性が存在する\todo{引用}．
本研究では，各要件に対して生成されたソースコード規模が小さい場合，ソースコード生成後に要件の分割粒度を再検討し，要件を統合して再生成する．
本研究では，各要件の重要度をその要件 ri を実装するステップで新規に追加・修正された行数を用いて評価し，その重要度を用いて要件の統合の判断基準として使用する．
具体的には，問題毎の要求から分割された要件の総数を n，i 番目の要件 ri に基づき生成したソースコードのスナップショット Si において，ソースコードの総行数を LoCi とする．
連続する 2 つのスナップショット対を Si−1 から Si までで追加及び修正された行数を \todo{デルタ} LoCi = LoCi − LoCi−1 とする．
\todo{表現調整}

式 (1) で算出した差分行数\todo{デルタ}LoCi が，本研究で決定した閾値を下回ると，要件 ri は直前の要件 ri−1 と統合する．

\begin{equation}
  \Delta \mathrm{LoC}_{i} \le \mathrm{LoC}_{n} / n
\end{equation}

統合後は，統合した要件群を基にコードを生成し直す事で，要件統合が生成結果に与える影響を調査する．
具体的には，統合後の要件列に基づいて，実装フェーズを再実行し，得られた成果物に対して入出力テストを用いて，テスト通過率の変化を調査する．


\section{プロセス反復}

取得した統合後要件の集合から無作為にサンプルを抽出し，計画フェーズと同様にfew-shot学習の学習例として与える．
これにより，要求文から要件へ分割する際の粒度や分割方針を，テストを通過した分割例に基づいて更新すると共に，分割粒度を大規模言語モデルが学習しやすいレベルへと変化させる事を狙う．
そして，以上の手順を繰り返す事で，要求文から分割・抽出される要件の粒度最適化を図り，それにより，分割粒度の不適切さに起因する断片化や取りこぼしを軽減しながら，入出力テストの通過率の向上を目指す．


\chapter{評価実験}
\section{データセット}
本研究では，満たすべき要件が自然言語で明確に記述され，生成したソースコードを検証可能なデータセットとして，競技プログラミングサイトである AtCoder の問題を対象に評価実験を行う．
特に，few-shot 学習のために問題 8問（C 問題 4 問と D 問題 4 問）を使用し，評価実験のために 200 問（C 問題と D 問題をそれぞれ 100 問）の問題を使用する．
難易度の低い問題では要件の分割により，タスク粒度が過度に小さくなってしまう可能性を考慮して，C 問題と D 問題を対象とする．
各問題は 2 件から 4 件程度の入出力サンプルを備えており，これを評価用テストとして活用し，生成したソースコードの評価に用いる．
また，大規模言語モデルの事前学習に用いられる学習用データの多くは英語が中心であり，他言語と比較して性能の差が挙げられる \todo{引用}．要件の理解の一貫性や再現性を担保するために，問題文などの自然言語は全て英語の問題を対象とする．
\todo{SE-benchの話も入れたい}

\section{実験設定}
計画フェーズでは，著者が手動で要求文から要件分を作成し，それらを 大規模言語モデル に few-shot 学習させ，AtCoder の問題 200 問の分割の自動化を行った．
大規模言語モデル へ入力するプロンプトには，要求文と要件群の例以外に，「根幹となる機能ほど順番を前にする事」，「分割コストの観点から分割の上限数を 10 個に制限する事」の 2 点を指示した．Jiang らの研究 \todo{引用} で，要件の分割を行う際に few-shot 学習で与える分割例の最適な数は 4 個から 8 個であったため，本研究では 8 問（C 問題，D 問題をそれぞれ 4 問）の例を提示した．

大規模言語モデル は実行ごとに生成結果にばらつきが生じるため，AtCoder の 200 問を対象に，要件の細分化およびソースコード生成を各問題につき 3 回ずつ実行し，結果の一般化を図った．
生成したソースコードの評価は，問題ごとに提供される入出力サンプルを入出力テストとして扱い，テスト通過率を用いる．
AtCoder の問題の特性上，入出力は標準入力・出力が想定されているため，3.1 節で拡張した段階的に開発を行う各 大規模言語モデル に対して，アプリケーションのようなインタフェースは作成しないように命令を追加した．

本研究では要件の細分化やプログラマやソースコードレビュアーなどの段階的ソースコード生成において，料金と性能を考慮し，大規模言語モデル として GPT-4o-mini\todo{引用} を使用した．


\section{RQs}
\subsection{RQ1: 計画フェーズ・実装フェーズに基づくソースコード生成は，従来手法と比較して有効であるか？}
大規模言語モデル に対して全体概要を学習することで，生成結果の断片化を抑制し整合性を担保する．
また，few-shot 学習による要求文から要件文への分割により，ソースコードを生成できるか否かをテスト通過率により評価する．
RQ1 では，要件の分割を行わない従来の ChatDev との比較だけでなく，対照実験として従来研究 \todo{引用} と同様に few-shot学習のみを行わなかった場合（zero-shot 学習による要件の細分化を実施し，各 大規模言語モデル の入力に全体概要を含む）と，全体概要の提示のみを行わなかった場合（few-shot 学習による要件の細分化を実施し，各 大規模言語モデル の入力に全体概要を含まない）場合の結果を比較する．

\subsection{RQ2: 要件の統合により，テスト通過率に変化は見られるか？}
 4.2 節で述べたスナップショットの差分行数に基づく統合指標に基づき，過小な要件を統合して生成するソースコードはテスト通過率に影響を与えるか否かを調査した．
 これは，統合する事によりテスト通過率が低下する場合，統合後の要件は統合前の要件より 大規模言語モデル にとって適切でないと判断できる．
 RQ2 では，RQ1 と同様に，200 問の問題に対して 3回の分割とソースコード生成し，統合前のテスト通過率と比較し，評価する．

 \subsection{RQ3: 要件の再分割により，分割粒度の再検討が行われるか？}
RQ3では，統合された要件群を基に，要求文を再分割した新たな要件群を基に要件群の粒度の再検討，即ち再分割前と比較して分割粒度に変化が見られるかを調査する．

RQ3では，再計画フェーズで得られた統合後の要件群を分割例として用いて要求文の再分割を行い，得られた新たな要件群が再分割前の要件群と比較して分割粒度に変化を与えるかを目視を用いてケーススタディ的に調査する．
具体的には，要件数の増減や，1つの要件に含まれる制約条件や出力形式などの仕様制約，1つあたりのテキスト量について目視で調査を行う．

 \subsection{RQ4: 要件の再分割により，テスト通過率は向上するか？}
RQ4 は，統合後に再分割することでテスト通過率に影響するかを評価する．
具体的には，手動で作成した要件に代わり，統合した要件と分割前の要求文を 大規模言語モデル の入力とし，再度 few-shot 学習による要件の分割およびソースコード生成を行う．他の RQ と同様に，テスト通過率で評価を実施する．
 

 \subsection{RQ5: プロセスの反復により，テスト通過率に変化は見られるか？}

 \chapter{結果}
 \section{RQ1}
図\ref{RQ1}，200 問を対象に提案手法によって各 3 回ソースコード生成した結果のテスト通過率を示す．

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{./Toyoshima_fig/RQ1.pdf}
    \caption{few-shot 学習，全体概要の有無，統合によるテスト通過率比較}
    \label{RQ1}
\end{figure}

実験の結果，few-shot 学習による要件の細分化を実施し，各 大規模言語モデル の入力に全体概要を含む場合に，テスト通過率が最も高い 67.07\%となった．zero-shot の場合は，テストで失敗したケースにおいても入出力でエラーが発生したケースは少なく，入出力の取り扱いは概ね正しく実装されているが，出力不一致などによる失敗が多く見られた．
これは全体概要の学習で，関数の呼び出しやデータの入出力構造などをはじめとする全体の整合性が保たれる一方で，局所的推論の部分でテスト失敗となっていると示唆される．
一方で，全体概要の学習を行わず，few-shot のみの場合では，タイムアウトや関数呼び出しなど，実行時の構造的不整合に起因するエラーが相対的に多くみられた．
これは，局所的な構造自体は与えられているが，全体像が欠如している事による開発の断片化により発生したものであると考えられる．


\section{RQ2}
図\ref{RQ2_1}には，データセットに含まれるAtCoderの問題200問に備わった入出力テスト全体のテスト通過率を示す．
要件の統合前ではテスト通過率が67.07\%であるのに対して，統合後には68.76\%とおおよそ横ばいの結果が確認された．

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{./Toyoshima_fig/RQ2_1.pdf}
    \caption{RQ2: 全テストでのテスト通過率}
    \label{RQ2_1}
\end{figure}

また，図\ref{RQ2_2}にはデータセットの問題200問(C問題100問，D問題100問)において，各3回ずつソースコードを生成し，それに対するテスト通過数の分布を示す．
具体的には，3回とも統合前後の両方でテストを通過した場合，3回とも統合前後の両方でテストを通過しなかった場合，統合前ではテストを通過せず統合後にテストを通過が1回以上通過するようになった場合，そしてそれ以外の場合で分類を行った．
尚，「テストを通過する」とは，問題に備わった入出力テストを全て通過したケースを指し，1つでもテストを通過しない入出力テストが存在する場合には，未通過という定義とする．
その結果，全200問のうち168問が統合前後で入出力テストの結果に変化が発生しなかった事から，テスト通過率の優位的な劣化は見られない事が

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{./Toyoshima_fig/RQ2_2.pdf}
    \caption{RQ2: 問題単位でのテスト通過数}
    \label{RQ2_2}
\end{figure}

\subsection{RQ3}
RQ2において，要件を統合した場合においても，統合前後でテストを通過する問題数に明示的な差は確認できなかったため，RQ4では統合した要件をfew-shotの学習例として活用する事で再分割した要件からソースコードを生成するために，要求文の再分割を実施した．
few-shotで提示する分割例は，要件の統合を行った際に入出力テストを通過したケースを無作為に8問(C問題4問，D問題4問)を取得し，これら８問を除いた192問の統合を行った．

その中の一部をケーススタディ的に調査した結果を以下に示す．
\todo{目視の結果を載せる}

\subsection{RQ4}
RQ3で実施した統合後の要件から要求文を再分割した要件群を基に192問の問題からソースコードの生成を行い，その入出力テストを実施し，そのテスト通過の可否の結果を示す．

図\ref{RQ4_1}に，対象の192問のデータセットに備わった入出力テスト全体に対するテスト通過率を示す．
再分割前では68.76\%であったのに対して，再分割後は87.59\%とおよそ18\%のテスト通過率の向上が確認された．

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{./Toyoshima_fig/RQ4_1.pdf}
    \caption{RQ4: }
    \label{RQ4_1}
\end{figure}


図\ref{RQ4_2}に，対象192問から各3回ずつソースコードを生成した際のテスト通過数の分布を示す．
具体的には，3回全てで再分割前後の両方でテストを通過した場合，3回全てで再分割によりテストを通過するようになった場合，3回のうち1回以上でテストを通過するようになった場合，そしてその他の4つに分類する．

その結果，3回全てで再分割によりテストを通過するようになったケースがC問題で24問，D問題で37問となっており，合計で192問のうち約32\%を占める結果となった．

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{./Toyoshima_fig/RQ4_2.pdf}
    \caption{RQ4: }
    \label{RQ4_2}
\end{figure}

\section{RQ5}
RQ1からRQ4までで計画フェーズ・実装フェーズ・再計画フェーズ並びに要件粒度の再検討が，生成されるソースコードのテスト通過率の向上に寄与し得る事が示唆される．この事から，要件粒度を再検討する反復プロセスを繰り返し行っていく事でテスト更なるテスト通過率の向上の可能性を調査する．

具体的には，これまでのRQと同様にテスト通過数の変遷についてや，再計画フェーズ時の要件数の変化について調査する．

図\ref{RQ5}に3回ずつソースコードを生成した際に3回すべてテストを通過した問題テスト通過数の変遷の結果を示す．

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{./Toyoshima_fig/RQ5.pdf}
    \caption{RQ5: }
    \label{RQ5}
\end{figure}

要件粒度の再検討を繰り返した場合において，C問題，D問題共に反復回数とテストを通過する問題数に有意的な変化は確認されなかった．


\chapter{考察}

\section{テスト通過率向上の要因分析}

\subsection{統合前・統合後・再分割後の全てでテストを全て通過するケース}

\subsection{再分割により改善が見られたケース}

\subsection{プロセスの反復による要件粒度の変化}

\section{追加分析の結果次第}


\chapter{妥当性の脅威}

\section{内的妥当性}

\section{外的妥当性}

\chapter{終わりに}

\chapter{参考文献}

文献を参照する場合には，論文の最後に参考文献として列挙するとともに，
\verb|\cite|を使って，例えば，
\begin{quote}
  文献\cite{latex}によれば…
\end{quote}
や，
\begin{quote}
  …である\cite{latex2e}．
\end{quote}
のように参照する．

文献の列挙には，{\tt thebibliography}環境などを用いる\footnote{使い方
は，この資料のソースを参照．}．

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% 謝辞
%%
%% \begin{acknowledgements}
%% 感謝します．
%% \end{acknowledgements}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% 参考文献
%%
\begin{thebibliography}{99}

\bibitem{wusethesis}
  伊原彰紀，
  卒業論文スタイルファイル（和歌山大学システム工学部用），\\
  \url{https://github.com/fukuyasu/wuse_thesis}．

\bibitem{tex}
  Knuth, D.,
  Remarks to Celebrate the Publication of Computers \& Typesetting,
  TUGboat, Vol.7, No.2, pp.95--98, 1986.

\bibitem{latex}
  Lamport, L.,
  文書処理システム\LaTeXe{}，
  ピアソン・エデュケーション，1999，
  \newblock{}阿瀬はる美 訳．

\bibitem{latex_j}
  奥村晴彦，\LaTeX{}入門 ---美文書作成のポイント---，技術評論社，1993．

\bibitem{latex2e}
  奥村晴彦，黒木裕介，[改定第6版] \LaTeXe~美文書作成入門，技術評論社，2013．

\bibitem{latexcomp}
  Goossens, M., Mittelbach, F. and Samarin, A.,
  The \LaTeX{}コンパニオン，アスキー出版局，1998，
  \newblock{}アスキー書籍編集部 監訳．

\bibitem{texwiki}
  \LaTeX 入門 --- \TeX{} Wiki，\\
  \url{https://texwiki.texjp.org/?LaTeX%E5%85%A5%E9%96%80}，
  2021年12月3日閲覧．
\end{thebibliography}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% 付録
%%
% \appendix
% 
% \chapter{サンプルプログラム}
% 
% プログラムリストや実行結果など，本論を補足する上で必要と思われるものが
% あれば付録として付ける．
% 
% {
% \footnotesize
% \begin{verbatim}
% #include <stdio.h>
% int main(void)
% {
%     printf("Hello, World!\n");
%     return 0;
% }
% \end{verbatim}
% }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
