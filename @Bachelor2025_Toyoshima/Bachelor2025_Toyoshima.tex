\documentclass[11pt]{jreport}
\usepackage{wuse_thesis}
\usepackage{indentfirst}
\usepackage{url}	% \url{}コマンド用．URLを表示する際に便利
\usepackage[dvipdfmx]{graphicx,xcolor}
\usepackage{listings}
\lstset{
  basicstyle={\ttfamily},
  identifierstyle={\small},
  commentstyle={\smallitshape},
  keywordstyle={\small\bfseries},
  ndkeywordstyle={\small},
  stringstyle={\small\ttfamily},
  frame={tb},
  captionpos=t,
  breaklines=true,
  columns=[l]{fullflexible},
  numbers=left,
  xrightmargin=0zw,
  xleftmargin=3zw,
  numberstyle={\scriptsize},
  stepnumber=1,
  numbersep=1zw,
  lineskip=-0.5ex
}
\usepackage{siunitx}
\sisetup{group-separator={,}} % 3桁ごとにコンマを入れる設定
%\usepackage{graphicx}  % ←graphicx.styを用いてEPSを取り込む場合有効にする
			% 他のパッケージ・スタイルを使う場合には適宜追加
\newcommand{\todo}[1]{\colorbox{yellow}{{\bf TODO}:}{\color{red} {\textbf{[#1]}}}}
\newcommand{\memo}[1]{\colorbox{magenta}{\textbf{MEMO}}{\color{red}\textbf{[#1]}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% 主に表紙を作成するための情報
%%

%%  タイトル(修論の場合は英語表記も指定)
% \title{大規模言語モデルによるソースコード生成のための最適化プロセスと反復プロセス}
\title{反復的要求分割に基づくLLMマルチエージェント段階的ソースコード生成}
%\etitle{Test\\Test\\Test}

%%  著者名(修論の場合は英語表記も指定)
\author{豊嶋 浩基}
%\eauthor{Akinori Ihara}

%% 卒業論文・修士論文(以下のどちらかを選択)
\bachelar	% 卒業論文(4年生用)
%\master  	% 修士論文(M2用)

%%  学科・クラスタ
\department{システム工}
%\department{デザイン情報}
%\department{デザイン科学}

%%  学生番号
\studentid{60276157}

%%  卒業年度
\gyear{2025}		% 提出年が2022年なら，2021年度

%%  論文提出日
\date{2026年2月10日}	% 修士の場合は月(2021年2月)までとし，英語表記も指定
%\edate{February 2021}	% 修士の場合，こちら(英語表記)も有効化

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

%%
%%  概要
%%
\begin{abstract}
大規模言語モデル(LLM)はソフトウェア開発の自動化に貢献する一方で，複数の機能や制約が相互に依存する複雑な要求に対しては，要件の取りこぼしや開発の断片化により，要求を満たしたソースコード生成が困難である．本研究では，大規模言語モデルを用いたマルチエージェント型ソースコード生成プラットフォームであるChatDevを拡張し，要件分割と段階的実装を統合した反復的な開発プロセスを提案する．提案手法として，few-shot学習にを用いて要求文を実装すべき要件文の集合へ分割する計画フェーズ，各要件を実装する際にその時点で生成された成果物と分割前の要求文を参照しながらソースコードの実装を行う実装フェーズ，分割された要件の粒度に着目し，生成コードの差分行数に基づいて過小な要件を統合し，統合結果を基に再度要求文の分割を行う再計画フェーズの3フェーズで構成され，これらを反復することにより，要求を満たしたコードの生成を目指す．競技プログラミングサイトであるAtCoderの問題を用いたケーススタディにより評価を実施した結果，few-shot学習による要求分割と全体概要の共有の組み合わせによるテスト通過率の向上や，さらに統合結果を用いた再分割によりテスト通過率を向上することを示した．

\end{abstract}

%%  目次
\tableofcontents

%%  図目次 (図目次をいれたければ以下のコメントをはずす)
%\listoffigures

%%  表目次 (表目次をいれたければ以下のコメントをはずす)
%\listoftables

\newpage
\pagenumbering{arabic}	% 以降のページ番号を算用数字に

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%%  本文はここから
%%

\chapter{はじめに}

大規模言語モデル(LLM)技術の急速な発展に伴い，大規模言語モデルはこれまで人間が時間や労力をかけて取り組んできたタスクの自動化を実現し，幅広い分野において作業を効率化する技術として関心を集めている．\cite{LLM_Development}
ソフトウェア開発においても同様に，コードレビュー，リファクタリング，テストケース生成など，様々な場面において飛躍的に生産性を向上させることが確認されている．\cite{Use_LLM_1, Use_LLM_2, Use_LLM_3}
その中でも，開発者の意図や要件をプロンプトとして提示し，ソースコードを自動生成するタスクに対して大きな期待が寄せられている．\cite{LLM_Code_Generation}

大規模言語モデルは，自然言語で記述された要求文に基づきソースコードの自動生成を実現し，昨今では複雑で，大規模なソフトウェア開発の自動化に向けた研究が進められている．\cite{LLM_Code_Generation}
規模が小さいソフトウェアの要求は実現できる一方で，ソフトウェア要件が複数内包し，それぞれが相互に依存し合う大規模なソフトウェア要件を満たすソースコード生成には課題が多い．
従来研究ではソフトウェア要件が複雑になると，大規模言語モデル が十分に推論せずに，短絡的なソースコードを生成することが示されている.\cite{Abandonment_of_Inference}
例えば，仕様の一部が欠損している場合や，要件の文脈を正しく理解できない場合には，生成されるコードの構造的なロジックの誤りが見られることがある．
これは，要件文から要求を抽出し，それらを元にソースコードを生成する，という流れを大規模言語モデルが実施するが，複雑な要件からソースコードを生成する場合，大規模言語モデルは要件を元にソースコードの生成を行うため，要求から抽出される要件の誤りが，不完全なソースコードを生成する原因の1つであると考えられる．

大規模言語モデル の理解や推論を補助するプロンプト技術として，思考の過程を明示的に示すChain of Thought (CoT) や，要求を満たす例を少数提示するfew-shot 学習が用いられてる.\cite{LLM_few_shot}
これらは局所的な推論の補完や思考パターンの学習には有効である一方で，プログラミング言語のように記述方法や実装方法によって同一の要件に対して多様な解が存在する領域では，これらの手法のみでは十分な性能を発揮しにくい．

これに対して先行研究では，全体の流れから要件を抽出するフェーズと，それらを基にソースコードを生成するフェーズの2 つに分割する手法が取り入れられてい．\cite{TOSEM}
前者では，大量のデータ収集やそれに対するラベリング，再学習などを要するファインチューニングと比較して，追加学習することなく大規模言語モデル の挙動を制御できるfew-shot 学習が採用されている．
当該研究では，複数の各機能を並列に生成し，生成されたすべてのソースコード片の結合時に，各断片における前提が共有されず，関数やファイル単位での依存関係や，グローバル変数の扱いや，エラーハンドリングなど，ソースコード単位での整合性が破綻する課題に言及している．

本研究では，従来研究\cite{TOSEM} の要求抽出の不安定さや，段階的開発におけるソースコードの断片化の課題解決に向けて，複雑な要件の細分化および，細分化した要件ごとの開発における全体整合を実施することでソースコード自動生成を実現する．
さらに，細分化した要件をベースとして生成したソースコードを評価し，要件の統合と再分割によるソースコード自動生成を複数回繰り返すことでプロンプト作成の最適化を目指す開発プロセスを提案する．
本手法により，各工程において大規模言語モデル に対して全体概要を明示的に提示し，分割した要件の統合と再分割を繰り返すことで，マルチエージェント型ソースコード自動生成の品質を向上を期待する．

論文構成は以下の通りである．
2章で本研究で使用するプラットフォームや，キーアイディアのベースとなる先行研究について，3章ではそれらに基づいたアプローチを述べ，4章でそのアプローチに関する実験設定やRQ列挙し，5章でそれに対する結果を，6章と7章ででそれらを基にした考察と妥当性の脅威について議論した上で，8章で結論を述べる．

\chapter{ソフトウェア開発における大規模言語モデルの活用} \memo{関連研究っぽくする}
\section{ソフトウェア開発工程の大規模言語モデルによる再現・自動化}
\subsection{工程ベースでの自動化}
大規模言語モデルを活用したソフトウェア開発の全プロセスの自動化を目的としたシステムとして，MetaGPT，AutoDev などの開発が盛んに進められている．\cite{META_GPT, AutoDev}
本システムは，ソフトウェア開発プロセスにおける各工程（要求定義，設計，実装，テスト，保守）を自然言語理解と生成能力により自動化する仕組みである．
本研究では，各工程の役割を担う大規模言語モデル エージェントがそれぞれ要件定義から実装までを実現するChatDev\cite{ChatDev}を用いる．

ChatDev は，要件定義，設計，実装をウォーターフォールモデルに則って開発を進める過程で，各工程においてプログラマやプロダクトマネージャといった役割を与えられた2つの大規模言語モデル エージェントが対話しながら開発を行うプラットフォームである．
各工程では，開発を担当するエージェントが，プロンプトで与えられた要件文，または前工程で生成された成果物（ソースコード）に基づき，新たな成果物を生成する．
生成した成果物は別の検証を担当するエージェントと共有される．共有を受けたエージェントは，成果物を検証し，開発と検証を担当するエージェント間で合意形成を図って，成果物を完成させる．

ChatDev の枠組みは，各工程のタスクが明確である点や，フレームワークがオープンソースとして公開されており，自体の構造の確認や書き換えが可能であるため，拡張性に優れている．
一方で，各工程で開発を担当する大規模言語モデルに対して，同一の要件（プロンプト）が与えられるため，多数の機能を内包するような複雑・大規模な要件の場合，各フェーズでのタスクの粒度が大きくなり，不完全なソースコードが生成されやすくなってしまう．

\subsection{複雑な要求の分割に基づくコード生成}
Jiang ら\cite{TOSEM} は，few-shot により大規模言語モデル を用いて要求文から小さな実装単位の要件に分割する「計画フェーズ」と，分割後の要件を基に開発を行なっていく実装フェーズを組み合わせた手法を提案している．計画フェーズにおいてfew-shot 学習として分割例を入力して要求文を分割することで，分割した要件を最適な粒度に均一化する事を目指している．
このように，当該研究が提案する分割後要件の粒度の最適化を図る「要件の細分化」と「細分化後要件の統合と再分割」は，大規模言語モデル の推論の最適化プロセスの1つとして重要であると考えられる．
さらに実装フェーズにおいては，分割後の要件文を個別に並行的に実装していくのではなく，開発順序を定めるガイドとして順次参照しつつ，全体を一体として一括で生成する構成が最も高性能であると報告されている．
これは，複数の要件からソースコードに並行して生成し，最終的に結合を行う方式は，コンテキストの欠如により，インタフェースやデータ構造の不整合が発生する可能性が高くなると言及されている．

本研究では，プロンプトとその時点で作成された成果物を基に開発を行う構造へとChatDevを変化させる事で段階的開発を実施しながらも，断片化を回避する手法について調査する．
\todo{断片化をはじめとする説明不足箇所の修正}


\section{要求分割と分割粒度}

\subsection{大規模言語モデルにとって好ましい分割粒度}
Shojaee ら\cite{Abandonment_of_Inference} は，複雑度の制御が可能かつ，解法が明確な数学的パズル問題を用いて，大規模言語モデル の最終的な解とそこに至るまでの推論過程を調査した．その結果，難易度が上昇するにつれて正答率は緩やかに低下すると同時に，複雑度が一定の閾値を超えるまでは推論過程での思考量が増加した．一方で，複雑度が一定の閾値を超えると思考量は急減し，推論が打ち切られ，大規模言語モデル の推論精度が低下することが確認された．加えて，推論過程の調査により，複雑度が低い場合は正解まで早く到達するが，その後も不要に探索を続けてしまう過剰な推論ステップを踏むことが確認された．このような大規模言語モデル の挙動は，高い推論能力を要する自然言語からのソースコード自動生成においても同様に発生し得るものである．複数の要求を内包する複雑な要件文からは，依存関係の見落としや，断片化したソースコードの生成により，全体整合性の破綻が発生しやすい．

\subsection{分割粒度が生成品質に与える影響}
大規模言語モデルを用いたコード生成では，要求をそのまま一括で実装させるのではなく，要求を複数の要件に分割を行い，計画・実装という順で段階的に開発を進める手法が検討されている．\cite{TOSEM}
この際重要となるのが，要求をどの程度の大きさに区切るのか，即ち分割粒度である．
分割粒度は，分割する際の要件数だけでなく，各要件が内包する処理の範囲や抽象度などとして捉えられる．
分割粒度の設計を誤ると，大規模言語モデルに対する理解孵化の増大化により，生成品質の低下が発生する恐れがある．

分割粒度が粗すぎる，即ち要件1つあたりの粒度が大きすぎる場合，大規模言語モデルは入出力条件や例外処理，データ構造などをはじめとする多くの制約を保持しながら実装する必要がある．
その結果，仕様の取りこぼしや，局所最適的実装などが発生しやすくなる．

一方で，分割粒度が細かすぎる場合にも問題が発生する．分割後要件を独立に実装して，後々に結合する実装を取る場合，大規模言語モデルが学習可能なコンテキストが限定され，関数名や引数，戻り値などのインタフェース，共有するデータ構造．前提条件の齟齬などが発生しやすい．
また，統合やレビュー・再生成などの回数が増加することから，運用上のコストが増大するなども考えられる．

以上のことから，要件の分割には大規模言語モデルが生合成を保ちながら扱うことのできる分割単位を見極める必要がある事が考えられる．



\section{本研究の位置付け}
\todo{分割粒度の再検討をここに置く？参考文献と離れるから要検討}

大規模言語モデルを用いたソフトウェア開発支援・自動化の研究は大きく分けて，要件定義から実装・テストまでを工程として分担し，複数のLLMエージェントの協調によって開発プロセス全体を再現するアプローチと，複雑な要求を小さな実装単位へ分割し，計画に基づいて段階的にコードの生成を行うアプローチに整理することが出来る．
前者の代表例としてChatDevは，ウォーターフォールモデルの工程に役割を当てたエージェント同士が対話と開発途中のコードの共有を行いながらコードを生成する枠組みを提供する一方で，要求文を分割して段階的に開発を進める仕組みは想定されておらず，単一プロンプトに依存する為，複雑な応急では各工程のタスク粒度が過大になりやすい．
後者の要求分割ベースのアプローチは，分割によって一括で生成させる場合と比較して大規模言語モデルにかかる理解負荷を軽減する一方で，要件感の断片化や全体整合の崩れが発生し得る．

以上を踏まえ，本研究で，要求文の分割による段階的開発をベースとしつつ，随時成果物の共有を行う工程ベースのChatDevを取り入れる事により，開発の断片化と取りこぼしの抑制を抑えたコードの生成を可能にすることを目指す．
 

\chapter{段階的開発と分割粒度の再検討}
\section{アプローチ概要}
従来の ChatDev\cite{ChatDev} は，単一のプロンプトから設計，実装，コードレビュー，テストのようにウォーターフォールモデルの流れを実施し，ソースコードを生成している．
従来のChatDevにおいては，要求文を分割して，段階的に開発を進める仕組みを持たない．
それに対して本研究では，分割された要件文からそれに対応する開発が実施できるように構造を拡張し，ソフトウェア生成の精度向上を目指す．
具体的には，本手法は要求文を要件に細分化する「計画フェーズ」と，細分化された要件を基にソースコードの生成を行う「実装フェーズ」, 実装フェーズで生成されたソースコードを基に要件の統合と再分割を実施する「再計画フェーズ」の3フェーズで構成する．図\ref{approach_abst}は，本手法の概略図を示す．

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{./Toyoshima_fig/approach_abst.pdf}
    \caption{アプローチ概要}
    \label{approach-abst}
\end{figure}

計画フェーズは，ソフトウェアの要求文を 大規模言語モデル に対してfew-shot 学習を実施することで，要求文を要件に細分化する．

実装フェーズは，細分化された要件をウォーターフォールモデルの流れで段階的にそれぞれ実装を進める．
各ステップで 大規模言語モデル には3 種類のデータを入力する．
(1) 実装する要件文，(2) 分割前の要求文，(3) 2つ目以降の要件の実装時には，それまでに開発された成果物．
これらのデータに基づき，各要件を 大規模言語モデル により実装する．

再計画フェーズでは，計画フェーズで要求文から分割された要件の粒度が過大・過少により生成されるソースコードがテストを通過しないケースを考慮し，実装フェーズまでで生成したソースコードを基に，計画フェーズで要求文から分割された要件群の統合を実施する．

分割されたソースコードの結果を基に要件の統合を実施し，統合した要件大規模言語モデル に学習させる事により要求から要件への再分割を実施する．
統合した要件から生成されたソースコードに対しても同様に入出力テストを実施し，統合によるソースコードの劣化が発生するかを調査する．

そして，これらの3つのフェーズを反復する事により，要求の分割粒度を最適化を図ることで，テスト通過率の高いソースコードを生成する手法の提案を目指す．


\section{計画フェーズ}

要求文の分割は，異なる開発者が行うと分割粒度が異なることも少なくない．\cite{Division_Size}
大規模言語モデル も同様に，共通した粒度で要求文を要件に分割することは容易でない．
本手法では，評価対象とは別のソフトウェア開発における要求文を手動で要件に分割した結果を few-shot 学習を行った 大規模言語モデル モデルを用いて，要求文の分割を実施する．
Listing \ref{split_prompt}は，要求文を分割するプロンプトの一部を抜粋したものである．

\begin{lstlisting}[caption={要求文分割プロンプト（一部抜粋）},label={split_prompt}]
# Role
You are an expert in software requirements elicitation.

# Objective
From an AtCoder problem statement and its constraints, extract the requirements and split them into 10 or fewer subtasks.

# Requirements
- Identify the input format and state how it will be handled in the first requirement.
- Decide which function to pass the given arguments to, and name functions/variables wherever possible.
- Mention the output format in the last requirement.
- Think of this as converting a story-like text into a list of implementable events.
- Return only the subtask list (no extra commentary).
\end{lstlisting}

few-shot 学習に用いるソフトウェア開発データは，分割後の要件に基づき 大規模言語モデル で生成したソースコードが入出力テストを全て通過しているものとする．
また，分割時に「重要な機能であればあるほど前方に配置する」という命令を与え，ソースコードの主要処理から実装するように実装する順番も 大規模言語モデル が決定する．
実装する順に要件には，r1，r2，r3，. . . ,rn のようにラベルを付与する．


\section{実装フェーズ}
実装フェーズは，各要件を満たすソースコードを 大規模言語モデルを用いて生成する．
Jiang らは，分割した要件のみに基づき，各要件を実現するソースコードを並行して生成する場合，要求間の断片化が発生し，全体整合性が崩壊するという課題が発生している．\cite{TOSEM} 
本研究は，要件 r1 に加え，要求文を 大規模言語モデル に入力し，ソースコードを生成する．
Listing \ref{sample_prompt}は，開発を担当する 大規模言語モデル へ与えるプロンプトの一部を抜粋したものである．

\begin{lstlisting}[caption={実装を行う LLM へ与えるプロンプト例},label={sample_prompt}]
"Programmer_2": [
"You are Programmer_1 at ChatDev. Focus subtask: {subtask2}.",
"The overall outline of the project is as follows: {overall_task}",
"Strictly follow the current phase’s Output rules.",
"Constraints: single file 'main.py'; STDIN/STDOUT only; stdlib only; no extra logs.",
"Respect any required region markers (e.g., '# [SUBTASK 2 START]' / '# [SUBTASK 2 END]'); do NOT add '__main__' unless asked.",
"Output EXACTLY ONE file in the requested format: start with 'FILENAME: main.py' then a single code block."
]
\end{lstlisting}


ここで生成されたソースコード一式をスナップショット 1 (S1) とする．次の要件要件 r2 は，要求文と前の要件 r1 で生成したスナップショット 1S1 を入力とし，ソースコードを生成する．
ここで生成されたソースコード一式をスナップショット 2 (S2) とする．
このように，本研究では従来研究のような要件のみでソースコードを生成するのとは異なり，要求文と前の要件で生成したスナップショットも入力として用いる．

\section{再計画フェーズ}
再計画フェーズでは，スナップショットの追加行数に基づく要件の統合と，統合した結果を用いた再分割を実施する．

2.2 節で示したように，要件に対する実装量が過度に小さい場合，大規模言語モデル の注意資源や推論能力を必要以上に消費し，意図しない要件を実装する可能性が存在する．\cite{TOSEM}
本研究では，各要件に対して生成されたソースコード規模が小さい場合，ソースコード生成後に要件の分割粒度を再検討し，要件を統合して再生成する．
本研究では，各要件の重要度をその要件 ri を実装するステップで新規に追加・修正された行数を用いて評価し，その重要度を用いて要件の統合の判断基準として使用する．
具体的には，問題毎の要求から分割された要件の総数を n，i 番目の要件 ri に基づき生成したソースコードのスナップショット Si において，ソースコードの総行数を LoCi とする．
連続する 2 つのスナップショット対を Si−1 から Si までで追加及び修正された行数を \todo{デルタ} LoCi = LoCi − LoCi−1 とする．
\todo{表現調整}

式 (1) で算出した差分行数\todo{デルタ}LoCi が，本研究で決定した閾値を下回ると，要件 ri は直前の要件 ri−1 と統合する．

\begin{equation}
  \Delta \mathrm{LoC}_{i} \le \mathrm{LoC}_{n} / n
\end{equation}

統合後は，統合した要件群を基にコードを生成し直す事で，要件統合が生成結果に与える影響を調査する．
具体的には，統合後の要件列に基づいて，実装フェーズを再実行し，得られた成果物に対して入出力テストを用いて，テスト通過率の変化を調査する．


\section{プロセス反復}

取得した統合後要件の集合から無作為にサンプルを抽出し，計画フェーズと同様にfew-shot学習の学習例として与える．
これにより，要求文から要件へ分割する際の粒度や分割方針を，テストを通過した分割例に基づいて更新すると共に，分割粒度を大規模言語モデルが学習しやすいレベルへと変化させる事を狙う．
そして，以上の手順を繰り返す事で，要求文から分割・抽出される要件の粒度最適化を図り，それにより，分割粒度の不適切さに起因する断片化や取りこぼしを軽減しながら，入出力テストの通過率の向上を目指す．



\chapter{評価実験}
\section{データセット}
本研究では，満たすべき要件が自然言語で明確に記述され，生成したソースコードを検証可能なデータセットとして，競技プログラミングサイトである AtCoder の問題を対象に評価実験を行う．
特に，few-shot 学習のために問題 8問（C 問題 4 問と D 問題 4 問）を使用し，評価実験のために 200 問（C 問題と D 問題をそれぞれ 100 問）の問題を使用する．
難易度の低い問題では要件の分割により，タスク粒度が過度に小さくなってしまう可能性を考慮して，C 問題と D 問題を対象とする．
各問題は 2 件から 4 件程度の入出力サンプルを備えており，これを評価用テストとして活用し，生成したソースコードの評価に用いる．
また，大規模言語モデルの事前学習に用いられる学習用データの多くは英語が中心であり，他言語と比較して性能の差が挙げられる \cite{LLM_English}．
要件の理解の一貫性や再現性を担保するために，問題文などの自然言語は全て英語の問題を対象とする．
\todo{SE-benchの話も入れたい}

\section{実験設定}
計画フェーズでは，著者が手動で要求文から要件分を作成し，それらを 大規模言語モデル に few-shot 学習させ，AtCoder の問題 200 問の分割の自動化を行った．
大規模言語モデル へ入力するプロンプトには，要求文と要件群の例以外に，「根幹となる機能ほど順番を前にする事」，「分割コストの観点から分割の上限数を 10 個に制限する事」の 2 点を指示した．Jiang らの研究 \cite{TOSEM} で，要件の分割を行う際に few-shot 学習で与える分割例の最適な数は 4 個から 8 個であったため，本研究では 8 問（C 問題，D 問題をそれぞれ 4 問）の例を提示した．

大規模言語モデル は実行ごとに生成結果にばらつきが生じるため，AtCoder の 200 問を対象に，要件の細分化およびソースコード生成を各問題につき 3 回ずつ実行し，結果の一般化を図った．
生成したソースコードの評価は，問題ごとに提供される入出力サンプルを入出力テストとして扱い，テスト通過率を用いる．
AtCoder の問題の特性上，入出力は標準入力・出力が想定されているため，3.1 節で拡張した段階的に開発を行う各 大規模言語モデル に対して，アプリケーションのようなインタフェースは作成しないように命令を追加した．

本研究では要件の細分化やプログラマやソースコードレビュアーなどの段階的ソースコード生成において，料金と性能を考慮し，大規模言語モデル として GPT-4o-mini\cite{GPT_4o_mini} を使用した．


\section{RQs}
\subsection{RQ1: 計画フェーズ・実装フェーズに基づくソースコード生成は，従来手法と比較して有効であるか？}
大規模言語モデル に対して全体概要を学習することで，生成結果の断片化を抑制し整合性を担保する．
また，few-shot 学習による要求文から要件文への分割により，ソースコードを生成できるか否かをテスト通過率により評価する．
RQ1 では，要件の分割を行わない従来の ChatDev との比較だけでなく，対照実験として従来研究 \cite{TOSEM} と同様に few-shot学習のみを行わなかった場合（zero-shot 学習による要件の細分化を実施し，各 大規模言語モデル の入力に全体概要を含む）と，全体概要の提示のみを行わなかった場合（few-shot 学習による要件の細分化を実施し，各 大規模言語モデル の入力に全体概要を含まない）場合の結果を比較する．

\subsection{RQ2: 要件の統合により，テスト通過率に変化は見られるか？}
 4.2 節で述べたスナップショットの差分行数に基づく統合指標に基づき，過小な要件を統合して生成するソースコードはテスト通過率に影響を与えるか否かを調査した．
 これは，統合する事によりテスト通過率が低下する場合，統合後の要件は統合前の要件より 大規模言語モデル にとって適切でないと判断できる．
 RQ2 では，RQ1 と同様に，200 問の問題に対して 3回の分割とソースコード生成し，統合前のテスト通過率と比較し，評価する．

 \subsection{RQ3: 要件の再分割により，分割粒度の再検討が行われるか？}
RQ3では，統合された要件群を基に，要求文を再分割した新たな要件群を基に要件群の粒度の再検討，即ち再分割前と比較して分割粒度に変化が見られるかを調査する．

RQ3では，再計画フェーズで得られた統合後の要件群を分割例として用いて要求文の再分割を行い，得られた新たな要件群が再分割前の要件群と比較して分割粒度に変化を与えるかを目視を用いてケーススタディ的に調査する．
具体的には，要件数の増減や，1つの要件に含まれる制約条件や出力形式などの仕様制約，1つあたりのテキスト量について目視で調査を行う．

 \subsection{RQ4: 要件の再分割により，テスト通過率は向上するか？}
RQ4 は，統合後に再分割することでテスト通過率に影響するかを評価する．
具体的には，手動で作成した要件に代わり，統合した要件と分割前の要求文を 大規模言語モデル の入力とし，再度 few-shot 学習による要件の分割およびソースコード生成を行う．他の RQ と同様に，テスト通過率で評価を実施する．
 

 \subsection{RQ5: プロセスの反復により，テスト通過率に変化は見られるか？}

 \chapter{結果}
 \section{RQ1}
図\ref{RQ1}，200 問を対象に提案手法によって各 3 回ソースコード生成した結果のテスト通過率を示す．

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{./Toyoshima_fig/RQ1.pdf}
    \caption{few-shot 学習，全体概要の有無，統合によるテスト通過率比較}
    \label{RQ1}
\end{figure}

実験の結果，few-shot 学習による要件の細分化を実施し，各 大規模言語モデル の入力に全体概要を含む場合に，テスト通過率が最も高い 67.07\%となった．zero-shot の場合は，テストで失敗したケースにおいても入出力でエラーが発生したケースは少なく，入出力の取り扱いは概ね正しく実装されているが，出力不一致などによる失敗が多く見られた．
これは全体概要の学習で，関数の呼び出しやデータの入出力構造などをはじめとする全体の整合性が保たれる一方で，局所的推論の部分でテスト失敗となっていると示唆される．
一方で，全体概要の学習を行わず，few-shot のみの場合では，タイムアウトや関数呼び出しなど，実行時の構造的不整合に起因するエラーが相対的に多くみられた．
これは，局所的な構造自体は与えられているが，全体像が欠如している事による開発の断片化により発生したものであると考えられる．


\section{RQ2}
図\ref{RQ2_1}には，データセットに含まれるAtCoderの問題200問に備わった入出力テスト全体のテスト通過率を示す．
要件の統合前ではテスト通過率が67.07\%であるのに対して，統合後には68.76\%とおおよそ横ばいの結果が確認された．

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{./Toyoshima_fig/RQ2_1.pdf}
    \caption{RQ2: 全テストでのテスト通過率}
    \label{RQ2_1}
\end{figure}

また，図\ref{RQ2_2}にはデータセットの問題200問(C問題100問，D問題100問)において，各3回ずつソースコードを生成し，それに対するテスト通過数の分布を示す．
具体的には，3回とも統合前後の両方でテストを通過した場合，3回とも統合前後の両方でテストを通過しなかった場合，統合前ではテストを通過せず統合後にテストを通過が1回以上通過するようになった場合，そしてそれ以外の場合で分類を行った．
尚，「テストを通過する」とは，問題に備わった入出力テストを全て通過したケースを指し，1つでもテストを通過しない入出力テストが存在する場合には，未通過という定義とする．
その結果，全200問のうち168問が統合前後で入出力テストの結果に変化が発生しなかった事から，テスト通過率の優位的な劣化は見られない事が

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{./Toyoshima_fig/RQ2_2.pdf}
    \caption{RQ2: 問題単位でのテスト通過数}
    \label{RQ2_2}
\end{figure}

\section{RQ3}
RQ2において，要件を統合した場合においても，統合前後でテストを通過する問題数に明示的な差は確認できなかったため，RQ4では統合した要件をfew-shotの学習例として活用する事で再分割した要件からソースコードを生成するために，要求文の再分割を実施した．
few-shotで提示する分割例は，要件の統合を行った際に入出力テストを通過したケースを無作為に8問(C問題4問，D問題4問)を取得し，これら８問を除いた192問の統合を行った．

その中の一部をケーススタディ的に調査した結果を以下に示す．
\todo{目視の結果を載せる}

\section{RQ4}
RQ3で実施した統合後の要件から要求文を再分割した要件群を基に192問の問題からソースコードの生成を行い，その入出力テストを実施し，そのテスト通過の可否の結果を示す．

図\ref{RQ4_1}に，対象の192問のデータセットに備わった入出力テスト全体に対するテスト通過率を示す．
再分割前では68.76\%であったのに対して，再分割後は87.59\%とおよそ18\%のテスト通過率の向上が確認された．

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{./Toyoshima_fig/RQ4_1.pdf}
    \caption{RQ4: }
    \label{RQ4_1}
\end{figure}


図\ref{RQ4_2}に，対象192問から各3回ずつソースコードを生成した際のテスト通過数の分布を示す．
具体的には，3回全てで再分割前後の両方でテストを通過した場合，3回全てで再分割によりテストを通過するようになった場合，3回のうち1回以上でテストを通過するようになった場合，そしてその他の4つに分類する．

その結果，3回全てで再分割によりテストを通過するようになったケースがC問題で24問，D問題で37問となっており，合計で192問のうち約32\%を占める結果となった．

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{./Toyoshima_fig/RQ4_2.pdf}
    \caption{RQ4: }
    \label{RQ4_2}
\end{figure}

\section{RQ5}
RQ1からRQ4までで計画フェーズ・実装フェーズ・再計画フェーズ並びに要件粒度の再検討が，生成されるソースコードのテスト通過率の向上に寄与し得る事が示唆される．この事から，要件粒度を再検討する反復プロセスを繰り返し行っていく事でテスト更なるテスト通過率の向上の可能性を調査する．

具体的には，これまでのRQと同様にテスト通過数の変遷についてや，再計画フェーズ時の要件数の変化について調査する．

図\ref{RQ5}に3回ずつソースコードを生成した際に3回すべてテストを通過した問題テスト通過数の変遷の結果を示す．

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{./Toyoshima_fig/RQ5.pdf}
    \caption{RQ5: }
    \label{RQ5}
\end{figure}


要件粒度の再検討を繰り返した場合において，C問題，D問題共に反復回数とテストを通過する問題数における有意的な変化は確認されなかった．


\chapter{考察}
% \section{テスト通過率向上の要因分析}
本章では，第５章の結果を踏まえ，提案手法がテスト通過率の向上に寄与した要因を考察する．
本研究の結果から，計画フェーズにおけるfew-ashot学習による要求分割と，実装フェーズにおける分割前要求文(全体概要)を併用した場合に，従来手法や片方のみを導入した場合と比較して高い通過率が得られることが確認された．
さらに，差分行数に基づく要件統合は通過率を大きく悪化させず，統合後要件を分割例として用いた再分割ではテスト通過率を向上させうることが示された．
一方で，反復を重ねても通過数に顕著な改善が見られないケースも確認された．

以下では，統合・再分割の前後でテストの結果が一貫したケースを対象に，要件の区切り方と実装の対応関係に着目して考察を行う．
次に，再分割を実施することによりテストが通過するように転じたケースを対象に，要件文に含まれる意図の明治度の観点から考察する．
その後，反復による要件粒度変化と改善が頭打ちになるケースについて議論する．


\section{統合前・統合後・再分割後の全てでテストを全て通過するケース}
統合前・統合語・再分割後のいずれにおいてもテストを通過したケースでは，生成されたソースコードの主要機能は一貫して満たされているため，差異は主に「要件の区切り方」に確認される．
統合前の要件群は，変数・関数の宣言，値の代入，単一の条件分岐といった「作業単位」の細かい粒度で列挙する傾向が見られた．\todo{具体例提示する？キモくなるだけ？}
この場合，ここの要件は局所的に明示されている一方で，要件間で前提や状態，データ構造の共有が複数回において必要となり，実装時に影響を及ぼす可能性が考えられる．
しかし，問題構造が比較的単純であったり，要件間の依存関係が薄い場合においては，細かな粒度でも破綻が発生せずに通過し得る．

一方で，再分割後の要件群では，宣言から初期化，関数呼び出しまでのように，意味的に連続した処理が1つの要件として束ねられる傾向が確認された．
このような区切り方は実装時に参照すべき文脈をまとまりとして保持しやすく，整合性のを持ったソースコードを生成しやすい．
即ち，機能を維持し，一貫性を保った状態で生成可能な最小単位へと要件が再編成されたことが，全ての状態においてテストを通過したケースであることが考えられる．

また本研究の実装フェーズでは，各ステップでの分割前要求文(全体概要)と直前までの成果物を参照する．この設計により，要件の粒度が細かな場合においても全体としての入出力形式や主要データの流れが参照可能となり，変数名・関数名の揺らぎやインタフェースの不整合を抑制可能となる．そのため，統合前後で要件1つあたりの粒度が違っている場合でも，テストが通過した可能性が考えられる．\todo{ここの段落はRQ1に対応する部分なので，この考察だけは前に持ってくる？}


\section{再分割により改善が見られたケース}
再分割によって未通過から通過へ転じたケースでは，大きくく分けて「再分割前の要件に意図が十分に明示されているか」と「要件文に沿ったコードが生成されているか」の2点に分けて考察を行う．

\subsection{再分割前の要件に意図が明示されているか}
統合前・統合後の段階では，要件が過度に細かい場合に大規模言語モデルは要件間の接続を推測しながら実装を進める必要がある．
この時，変数に格納された値の更新手順や，分岐条件，境界値の扱い，例外処理などといった細やかな意図が要件群の中に分散する．
その結果，各要件を局所的に満たした場合においても，他の要件の理解が不十分となることに起因する解釈の揺らぎが発生してしまう．
この揺らぎは入出力テストにおいて出力不一致や，条件分岐の漏れとして健在化し，未通過の要因となり得る．

一方，再分割の過程では統合語要件を分割例として参照することで，要件1つあたりの粒度が問題の構造に合わせて再編成される．
その結果，宣言から更新，分岐，出力までのように，意味的に連続した処理が同一の要件にない方されやすくなり，要件間の工程的な繋ぎ目が現象したことが確認された．
また，要件粒度の向上により，各要件1つあたりに記述できる情報量の余地が発生し，これまで反映しきれていなかった意図を要件内で提示することが可能となった．
実際に改善が見られた事例では，細かな値の更新や分岐制御，境界値の扱い，入出力形式，例外時処理の扱いなどが要件文内に含まれるようになった事が確認さえた．
このような意図の明示化により，前提や出力の揺らぎが抑制され，糸が一貫して実装に反映されるようになった可能性がある．


\subsection{要件文に沿ったコードが生成されているか}
再分割前に意図が部分的に記述されていた場合においても，要件粒度が細かく分散している場合では，大規模言語モデルが要件間の依存関係や変数の意味やデータ構造などの前提を正しく理解できない場合がある．
本研究の実装フェーズでは，要求文と同時に分割前の要求文を提示し，全体の前提条件を参照しながらコードを生成する工夫を実施しているが，要求文を平気した場合においても前提条件が要件のどの箇所にどのように適応されるべきかのコンテキストを大規模言語モデルが十分に読み取ることができない場合があり，その結果として要求文を満たすソースコードを生成できないケースが発生している．

これに対し，再分割後は要件が意味的まとまりとして提示され，各要件内で入出力条件や，格納した値の更新，分岐などがまとまって記述される傾向が確認された．\memo{やっぱり具体例提示しないとイメージしてもらえる気がしない}
その結果，1つあたりの要件粒度が大きくなり，先行研究でも提示された大規模言語モデルが学習しやすい粒度へと変化し，コンテキストや前提条件の理解不足が抑制され，要件に沿ったソースコードが生成されるようになったことが考えられる．


\section{プロセスの反復によるテスト通過の可否}
本節では再分割によって得られた「テストを通過した要件群」を分割例として再利用し，計画・実装・再計画の3フェーズを反復がテスト通過率に与える影響について議論する．


先の節子で示した通り，反復に回数の増加に伴う通過数の一環した増加は確認できず，特に高難易度問題においては未解決となった問題が多く残った．
反復による改善が頭打ちとなった要因として，要件の区切り方や粒度の調整ではなく，問題文のコンテキストの理解における失敗が考えられる．\memo{文キモい気がする．あとで見直す．}

実際にプロセスの反復を実施した中で，テストが継続して通過しなかったケースをケーススタディ的に確認したところ，境界条件や偶奇処理の誤解，配列インデックスの取り違えや，処理の順序誤りなどが確認された．
また，加えて，処理に無関係な関数の定義などの過剰実装が行われ，重要な処理の検討が不十分となる例も観察された．これらのように，コンテキストの誤解が生成されるソースコードに与える影響は甚大であり，大規模言語モデル上で誤解を解くためのアプローチが行われない限り，生成されるソースコードには同種の誤りを内包してしまう事が考えられる．
大規模言語モデルの持つ生成結果の「揺らぎ」〜〜〜．\memo{どう考えてもキモい．LLMなんだから生成毎に結果変わりうるよね．でも，基本のモデルはおんなじなんだからコンテキストの誤解を解くのってそんなに簡単かな？みたいな文を作る．}

これらは，データセットとして使用するAtCoderの問題が競技プログラミング用の問題であるため，状況説明などをはじめとするストーリー性を問題文が包含している事から，暗黙の制約や規則を読み取る必要がある，という性質が一因である事が考えられる．
即ち，反復プロセスが「要件粒度の最適化」であるのに対しては有効に働く一歩上，問題そのものの誤解に起因する失敗が原因となる場合には，反復だけでは継続的な改善が困難である事が考えられる．

以上により，反復によるテスト通過率向上を安定して得るには，要件再分割の前段階として，問題文から制約条件，例外処理，入出力フォーマットなどを明示的に構造化して抽出し，大規模言語モデルが誤解しにくい形式へ変換する処理の導入が求められることが考えられる．


\chapter{妥当性の脅威}
本章では，本研究における結果の信頼性に影響を及ぼす可能性のある要因を，内的妥当性および外的妥当性の観点から述べる．

\section{内的妥当性}
本研究では，生成したソースコードの正しさを入出力テストの通過可否を用いて評価する．
しかし，競技プログラミングであるAtCodernの入出力サンプルは，仕様全体を網羅するテストの集合ではないため，テストを通過しても未検出の欠陥を見逃してしまう可能性がある．
その結果，提案手法間の差が「使用適合度」ではなく，「サンプルへの適応度」として観測される恐れがある．\memo{なんか文がキモい？入出力サンプルにだけガゴンしすぎてる可能性についてわかりやすく．データセットの拡張が必要みたいな？(流石にここでSWE-benchの話はキモすぎる？)}

また，本研究では要件統合の際に，ソースコードのスナップショット間の差分行数を用いる．
差分行数は，要件と直接関与しないような警備な変更の影響を受けるため，差分行数が要件の重要度や粒度を正確に表現しない可能性がある．
この点は統合の閾値設定や差分抽出方法により結果が変動し得るという恐れもある．\memo{ここをあっさり流しすぎ？}

そして，本研究には大規模言語モデルを使用しており，その特徴として「同一入力に対しても生成結果が変動し得る」という点が挙げられる．
本研究では各問題につき複数回実行することでその大規模言語モデル特有の「揺らぎ」を低減している一方で，モデルの更新や実行環境の差により再現性が損なわれる可能性がある．


\section{外的妥当性}
本研究の評価対象は競技プログラミングサイトのAtCoderの問題であり，標準入力・出力によってテストが判定される形式である．
この形式では，入出力使用や制約が比較的明確である一方で，実システムの開発で扱う非機能要件や外部APIの使用，運用制約などは含まれにくい．
そのため，本研究で得られた有効性が実務的な開発業務へ同程度に一般化可能であるかは未知数である．

また，実験は単一ファイル・標準入出力を前提としたソースコード生成であり，複数モジュール構成や依存関係管理，結合時のインタフェース整合性など，実システムで重要となる要素を十分に反映できていない．
よって，本研究で確認されたソースコードの品質向上の効果が，複数ファイル構成の開発で同様に得られるかについても未検証である．

本研究では，要求理解の一貫性や，大規模言語モデルの学習データ量をベースに英語の問題文を対象としている．
そのため，日本語要求や箇条書き形式の仕様書などの要求形式が異なる場合に提案手法が同様に機能するかは不明であり，言語・形式の違いに対する一般化は今後の検証が必要となる．


\chapter{終わりに}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%
% 謝辞
%
\begin{acknowledgements}


% written on 2026-01-09

\end{acknowledgements}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% 参考文献
%%
\bibliographystyle{junsrt}
\bibliography{@Bachelor2025_Toyoshima/references}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% 付録
%%
% \appendix
% 
% \chapter{サンプルプログラム}
% 
% プログラムリストや実行結果など，本論を補足する上で必要と思われるものが
% あれば付録として付ける．
% 
% {
% \footnotesize
% \begin{verbatim}
% #include <stdio.h>
% int main(void)
% {
%     printf("Hello, World!\n");
%     return 0;
% }
% \end{verbatim}
% }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
