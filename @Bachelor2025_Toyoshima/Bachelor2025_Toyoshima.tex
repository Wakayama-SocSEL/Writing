\documentclass[11pt]{jreport}
\usepackage{wuse_thesis}
\usepackage{indentfirst}
\usepackage{url}	% \url{}コマンド用．URLを表示する際に便利
\usepackage[dvipdfmx]{graphicx,xcolor}
\usepackage{listings}
\lstset{
  basicstyle={\ttfamily},
  identifierstyle={\small},
  commentstyle={\smallitshape},
  keywordstyle={\small\bfseries},
  ndkeywordstyle={\small},
  stringstyle={\small\ttfamily},
  frame={tb},
  captionpos=t,
  breaklines=true,
  columns=[l]{fullflexible},
  numbers=left,
  xrightmargin=0zw,
  xleftmargin=3zw,
  numberstyle={\scriptsize},
  stepnumber=1,
  numbersep=1zw,
  lineskip=-0.5ex
}
\usepackage{siunitx}
\sisetup{group-separator={,}} % 3桁ごとにコンマを入れる設定
%\usepackage{graphicx}  % ←graphicx.styを用いてEPSを取り込む場合有効にする
			% 他のパッケージ・スタイルを使う場合には適宜追加
\newcommand{\todo}[1]{\colorbox{yellow}{{\bf TODO}:}{\color{red} {\textbf{[#1]}}}}
\newcommand{\memo}[1]{\colorbox{magenta}{\textbf{MEMO}}{\color{red}\textbf{[#1]}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% 主に表紙を作成するための情報
%%

%%  タイトル(修論の場合は英語表記も指定)
% \title{大規模言語モデルによるソースコード生成のための最適化プロセスと反復プロセス}
\title{反復的要求分割に基づくLLMマルチエージェント段階的ソースコード生成}
%\etitle{Test\\Test\\Test}

%%  著者名(修論の場合は英語表記も指定)
\author{豊嶋 浩基}
%\eauthor{Akinori Ihara}

%% 卒業論文・修士論文(以下のどちらかを選択)
\bachelar	% 卒業論文(4年生用)
%\master  	% 修士論文(M2用)

%%  学科・クラスタ
\department{システム工}
%\department{デザイン情報}
%\department{デザイン科学}

%%  学生番号
\studentid{60276157}

%%  卒業年度
\gyear{2025}		% 提出年が2022年なら，2021年度

%%  論文提出日
\date{2026年2月10日}	% 修士の場合は月(2021年2月)までとし，英語表記も指定
%\edate{February 2021}	% 修士の場合，こちら(英語表記)も有効化

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

%%
%%  概要
%%
\begin{abstract}
大規模言語モデル(LLM)はソフトウェア開発の自動化に貢献する一方で，複数の機能や制約が相互に依存する複雑な要求に対しては，要件の取りこぼしや開発の断片化により，要求を満たしたソースコード生成が困難である．本研究では，大規模言語モデルを用いたマルチエージェント型ソースコード生成プラットフォームであるChatDevを拡張し，要件分割と段階的実装を統合した反復的な開発プロセスを提案する．提案手法として，few-shot学習にを用いて要求文を実装すべき要件文の集合へ分割する計画フェーズ，各要件を実装する際にその時点で生成された成果物と分割前の要求文を参照しながらソースコードの実装を行う実装フェーズ，分割された要件の粒度に着目し，生成コードの差分行数に基づいて過小な要件を統合し，統合結果を基に再度要求文の分割を行う再計画フェーズの3フェーズで構成され，これらを反復することにより，要求を満たしたコードの生成を目指す．競技プログラミングサイトであるAtCoderの問題を用いたケーススタディにより評価を実施した結果，few-shot学習による要求分割と全体概要の共有の組み合わせによるテスト通過率の向上や，さらに統合結果を用いた再分割によりテスト通過率を向上することを示した．

\end{abstract}

%%  目次
\tableofcontents

%%  図目次 (図目次をいれたければ以下のコメントをはずす)
%\listoffigures

%%  表目次 (表目次をいれたければ以下のコメントをはずす)
%\listoftables

\newpage
\pagenumbering{arabic}	% 以降のページ番号を算用数字に

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%%  本文はここから
%%

\chapter{はじめに}

大規模言語モデル(LLM)技術の急速な発展に伴い，大規模言語モデルはこれまで人間が時間や労力をかけて取り組んできたタスクの自動化を実現し，幅広い分野において作業を効率化する技術として関心を集めている．\cite{LLM_Development}
ソフトウェア開発においても同様に，コードレビュー，リファクタリング，テストケース生成など，様々な場面において飛躍的に生産性を向上させることが確認されている．\cite{Use_LLM_1, Use_LLM_2, Use_LLM_3}
その中でも，開発者の意図や要件をプロンプトとして提示し，ソースコードを自動生成するタスクに対して大きな期待が寄せられている．\cite{LLM_Code_Generation}

大規模言語モデルは，自然言語で記述された要求文に基づきソースコードの自動生成を実現し，昨今では複雑で，大規模なソフトウェア開発の自動化に向けた研究が進められている．\cite{LLM_Code_Generation}
規模が小さいソフトウェアの要求は実現できる一方で，ソフトウェア要件が複数内包し，それぞれが相互に依存し合う大規模なソフトウェア要件を満たすソースコード生成には課題が多い．
従来研究ではソフトウェア要件が複雑になると，大規模言語モデル が十分に推論せずに，短絡的なソースコードを生成することが示されている.\cite{Abandonment_of_Inference}
例えば，仕様の一部が欠損している場合や，要件の文脈を正しく理解できない場合には，生成されるコードの構造的なロジックの誤りが見られる．
このようなロジックの誤りは，大規模言語モデルが要求文を解釈し，機能ごとの要件へ分解した上で実装へと落とし込むという処理過程において発生する．
要件が複雑で相互に依存する場合，要件を解釈する段階て誤解が発生しやすく，その誤りが開発に波及することで，不完全なソースコードの生成に繋がると考えられる．

大規模言語モデル の理解や推論を補助するプロンプト技術として，思考の過程を明示的に示すChain of Thought (CoT) や，要求を満たす例を少数提示するfew-shot 学習が用いられてる.\cite{LLM_few_shot}
これらは局所的な推論の補完や思考パターンの学習には有効である一方で，プログラミング言語のように記述方法や実装方法によって同一の要件に対して多様な解が存在する領域では，これらの手法のみでは十分な性能を発揮しにくい．

このような課題に対して先行研究では，要求文から要件を抽出しするフェーズと，それらを基にソースコードを生成するフェーズの2つに分割する手法が取り入れられている．\cite{TOSEM}
前者では，大量のデータ収集やそれに対するラベリング，再学習などを要するファインチューニングと比較して，追加学習することなく大規模言語モデル の挙動を制御できるfew-shot学習が採用されている．
後者では，抽出した要件を基に段階的に開発する手法では，生成されたソースコード断片の結合時に，各断片における前提が共有されず，ソースコード単位での整合性が破綻する課題に言及している．

本研究では，従来研究\cite{TOSEM}で指摘された要求抽出の不安定さ，及び段階的開発におけるソースコードの断片化に対し，依存関係を保ったまま要件の抽出を行い，各要件の実装を退く列で並列的に生成するのではなく，既に生成されたソースコードを基に逐次的に・統合を行う段階的開発を行う手法を提案する．
段階的に開発する各工程において，大規模言語モデルに対して実装すべき要件に加えて，全体概要を明示することで生成されるコードの全体整合を目指す．
加えて，分割された要件に基づく生成結果を評価し，要件の統合と再分割及び，再分割された要件を基にソースコードの再生成するアプローチを複数回反復することで，プロンプトと要件構造を更新し，マルチエージェント型ソースコード自動生成の品質向上を狙う．

論文構成は以下の通りである．
2章で本研究で使用するプラットフォームや，キーアイディアのベースとなる先行研究について，3章ではそれらに基づいたアプローチを述べ，4章でそのアプローチに関する実験設定やRQ列挙し，5章でそれに対する結果を，6章と7章ででそれらを基にした考察と妥当性の脅威について議論した上で，8章で結論を述べる．


\chapter{ソフトウェア開発における大規模言語モデルの活用} \memo{関連研究っぽくする}

\section{ソフトウェア開発工程の大規模言語モデルによる再現・自動化}

\subsection{工程分担型の開発自動化}
大規模言語モデルを活用したソフトウェア開発プロセスの全肯定では，自動化を目的としたシステムとして，MetaGPT，AutoDev などの開発が盛んに進められている．\cite{META_GPT, AutoDev}
本システムは，ソフトウェア開発プロセスにおける各工程（要求定義，設計，実装，テスト，保守）を自然言語理解と生成能力により自動化する仕組みである．
本研究では，各工程の役割を担う大規模言語モデル エージェントがそれぞれ要件定義から実装までを実現するChatDev\cite{ChatDev}を用いる．

ChatDev は，要件定義，設計，実装をウォーターフォールモデルに則って開発を進める過程で，各工程においてプログラマやプロダクトマネージャといった役割を与えられた2つの大規模言語モデルエージェントが対話しながら開発を行うプラットフォームである．
ここにおけるエージェントとは，大規模言語モデルに対して役割(プログラマやコードレビュアなど)や実装すべき要件を与えることで，工程ごとの振る舞いを分担させた実行単位である．
各工程で開発を担当するエージェントが，プロンプトで与えられた要件文，または前工程で生成された成果物（ソースコード）に基づき，新たな成果物を生成する．
図\ref{ChatDev_abst}に，ChatDevの工程分担と，工程内でのエージェントと成果物共有の流れを示す．

\begin{figure}[tb]
    \centering
    \includegraphics[width=0.7\linewidth]{./Toyoshima_fig/ChatDev_abst.pdf}
    \caption{ChatDev概要}
    \label{ChatDev_abst}
\end{figure}


ChatDev の枠組みは，各工程のタスクが明確である点や，フレームワークがオープンソースとして公開されており，自体の構造の確認や書き換えが可能であるため，拡張性に優れている．
一方で，各工程で開発を担当する大規模言語モデルに対して，同一の要件（プロンプト）が与えられるため，多数の機能を内包するような複雑・大規模な要件の場合，各フェーズでのタスクの粒度が大きくなり，不完全なソースコードが生成されルコとが多い．

\subsection{複雑な要求の分割に基づくコード生成}
Jiang ら\cite{TOSEM} は，few-shot学習により大規模言語モデル を用いて要求文から小さな実装単位の要件に分割する「計画フェーズ」と，分割後の要件を基に開発を行なっていく「実装フェーズ」を組み合わせた手法を提案している．計画フェーズにおいてfew-shot 学習として分割例を入力して要求文を分割することで，分割した要件を最適な粒度に均一化する事を目指している．
当該研究が提案する分割後要件の粒度の最適化を図る「要件の細分化」と「細分化後要件の統合と再分割」は，大規模言語モデル の推論の最適化プロセスの1つとして重要である．
さらに実装フェーズにおいては，分割後の要件文を個別に並行に実装するよりも，開発順序を定めるガイドとして参照しつつも，全体を一括で生成する構成が最も高性能であると報告されている．
以上の結果を踏まえ，先行研究では要件ごとにコード断片を並列にう生成してから最終的に結合する方式は，各断片間においてコンテキストの理解のズレが発生しやすく，結合時に不整合が生じて全体の生合成が崩れてしまう，断片化，が発生すると指摘されている．

以上を踏まえ，本研究ではプロンプトとその時点で作成された成果物を基に開発を行う構造へとChatDevを変化させる事で段階的開発を実施しながらも，断片化を回避する手法について調査する．


\section{要求分割と分割粒度}

\subsection{問題複雑度が推論家庭に与える影響}
Shojaee ら\cite{Abandonment_of_Inference} は，複雑度の制御が可能かつ，解法が明確な数学的パズル問題を用いて，大規模言語モデル の最終的な解とそこに至るまでの推論過程を調査した．その結果，難易度が上昇するにつれて正答率は緩やかに低下すると同時に，複雑度が一定の閾値を超えるまでは推論過程での思考量が増加した．一方で，複雑度が一定の閾値を超えると思考量は急減し，推論が打ち切られ，大規模言語モデル の推論精度が低下することが確認された．加えて，推論過程の調査により，複雑度が低い場合は正解まで早く到達するが，その後も不要に探索を続けてしまう過剰な推論ステップを踏むことが確認された．このような大規模言語モデル の挙動は，高い推論能力を要する自然言語からのソースコード自動生成においても同様に発生し得るものである．複数の要求を内包する複雑な要件文からは，依存関係の見落としや，断片化したソースコードの生成により，全体整合性の破綻が発生しやすい．

\subsection{分割粒度が生成品質に与える影響}
大規模言語モデルを用いたソースコード生成では，要求文から一括で実装させるのではなく，要求を複数の要件に分割し，分割した要件を基に逐次的に段階的開発を進める手法が検討されている．\cite{TOSEM}
ここで重要となるのが，要求文から分割する要件文の大きさ，即ち分割粒度である．
分割粒度は，単に要件文の分割数だけでなく，各要件が内包する処理の範囲や抽象度などとして捉えられる．
分割粒度の設計を誤ると，大規模言語モデルに対する理解負荷の増大化により，要求を満たしたソースコードが生成されなくなる恐れがある．

分割粒度が粗すぎる，即ち要件1つあたりの粒度が大きすぎる場合，大規模言語モデルは入出力条件や例外処理，データ構造などをはじめとする多くの制約を保持しながら実装する必要がある．
その結果，仕様の取りこぼしや，局所最適実装などが発生する．
一方で，分割粒度が細かすぎる場合にも，分割後要件を独立に実装して，後々に結合する時に，大規模言語モデルが学習可能なコンテキストが限定し，関数名や引数，戻り値などのインタフェース，共有するデータ構造，前提条件の齟齬などが発生しやすい．
また，そのようなコードに対しては，統合やレビュー，再生成の回数が増加することから，運用上のコストが増大する．

以上のことから，要件の分割には大規模言語モデルが生合成を保ちながら扱うことのできる分割単位を見極める必要がある．



\section{本研究の位置付け}

大規模言語モデルを用いたソフトウェア開発支援，自動化の研究は大きく分けて，要件定義から実装・テストまでを工程として分担し，複数のLLMエージェントの協調によって開発プロセス全体を再現するアプローチと，複雑な要求を小さな実装単位へ分割し，計画に基づいて段階的にコードの生成を行うアプローチに整理することが出来る．
前者の代表例としてChatDevでは，ウォーターフォールモデルの工程に役割を当てたエージェント同士が対話と開発途中のコードの共有を行いながらコードを生成する枠組みを提供する一方で，要求文を分割して段階的に開発を進める仕組みは想定されておらず，単一プロンプトに依存する為，複雑な応急では各工程のタスク粒度が過大になりやすい．
後者の要求分割ベースのアプローチは，分割によって一括で生成させる場合と比較して大規模言語モデルにかかる理解負荷を軽減する一方で，要件間の断片化や全体整合の崩れが発生し得る．

本研究で，要求文の分割による段階的開発をベースとしつつ，随時成果物の共有を行う工程ベースのChatDevを取り入れる事により，開発の断片化と取りこぼしの抑制を抑えたコードの生成を可能にする．


\chapter{段階的開発と分割粒度の再検討}
\section{アプローチ概要}
ChatDev\cite{ChatDev} は，単一のプロンプトから設計，実装，コードレビュー，テストのようにウォーターフォールモデルの流れを実施し，ソースコードを生成している．
従来のChatDevにおいては，要求文を分割して，段階的に開発を進める仕組みを持たない．
それに対して本研究では，分割された要件文からそれに対応する開発が実施できるように構造を拡張し，ソフトウェア生成の精度向上を目指す．
具体的には，本手法は要求文を複数の要件文に細分化する「計画フェーズ」と，細分化された要件文を基にソースコードの生成を行う「実装フェーズ」, 実装フェーズで生成されたソースコードを基に要件の統合と再分割を実施する「再計画フェーズ」の3フェーズで構成する．図\ref{approach_abst}は，本手法の概略図を示す．

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{./Toyoshima_fig/approach_abst.pdf}
    \caption{アプローチ概要}
    \label{approach_abst}
\end{figure}

計画フェーズは，ソフトウェアの要求文を 大規模言語モデル に対してfew-shot学習を実施することで，要求文を要件文に細分化する．

実装フェーズは，細分化された要件をウォーターフォールモデルの流れで段階的にそれぞれ実装を進める．
各ステップで 大規模言語モデル には3 種類のデータを入力する．
(1) 実装する要件文，(2) 分割前の要求文，(3) プロセス反復後の要件の実装時には，それまでに開発された成果物．
これらのデータに基づき，各要件を大規模言語モデルにより実装する．

再計画フェーズでは，計画フェーズで要求文から分割された要件の粒度が過大・過少により生成されるソースコードがテストを通過しないケースを考慮し，実装フェーズまでで生成したソースコードを基に，計画フェーズで要求文から分割された要件群を統合する．
要件文の統合して作成した要件文を大規模言語モデルに学習させる事で要求から要件への再分割を実施する．
統合した要件から生成されたソースコードに対しても同様に入出力テストを実施し，統合によるソースコードの劣化が発生するかを調査する．

そして，これらの3つのフェーズを反復する事により，要求の分割粒度を最適化を図ることで，テスト通過率の高いソースコードを生成する．


\section{計画フェーズ}

要求文の分割は，異なる開発者が行うと分割粒度が異なることも少なくない．\cite{Division_Size}
大規模言語モデルも同様に，共通した粒度で要求文を要件文に分割することは容易でない．
また，分割粒度が不適切な場合，大規模言語モデルが解釈を誤ったり，2.2.2節で示したように推論を放棄してしまう恐れがある．
分割粒度が過大な場合には，1つの要件に複数の機能や制約が混在することで複雑化し，重要な条件の取りこぼしが発生しやすくなり，過小な場合には要件数が増加することにより要件間の依存関係や，不明瞭な状態で局所的実装が進むため，全体の不整合が生じる．
これらを回避するために，本研究では大規模言語モデルに対して少数の正解例を提示し，膨大な教師データを用いることなくタスクに適応させるfew-shot学習を大規模言語モデルに対して実施し，要求文の分割を実施することと，要件粒度の見直しプロセスを導入することで要件文の粒度の最適化を目指す．
また，本研究でfew-shot学習で提示する正解例は，著者が手動で要求文から要件文への分割を実施し，それらの要件文に基づいてソースコードを生成した結果，入出力テストを通過したものを提示するものとする．

Listing \ref{split_prompt}は，要求文を分割するプロンプトの一部を抜粋したものである．

\memo{ChatDevのロール割り当てのプロンプトのフォーマットをベースに文は自分(とGPT)で作成しました．}

\begin{lstlisting}[caption={要求文分割プロンプト（一部抜粋）},label={split_prompt}]
# Role
You are an expert in software requirements elicitation.

# Objective
From an AtCoder problem statement and its constraints, extract the requirements and split them into 10 or fewer subtasks.

# Requirements
- Identify the input format and state how it will be handled in the first requirement.
- Decide which function to pass the given arguments to, and name functions/variables wherever possible.
- Mention the output format in the last requirement.
- Think of this as converting a story-like text into a list of implementable events.
- Return only the subtask list (no extra commentary).
\end{lstlisting}

few-shot 学習に用いるソフトウェア開発データは，分割後の要件に基づき大規模言語モデルで生成したソースコードが入出力テストを全て通過しているものとする．
また，分割時に「重要な機能であればあるほど前方に配置する」という命令を与え，ソースコードの主要処理から実装するように実装する順番も 大規模言語モデル が決定する．
実装する順に要件には，$R_1，R_2，R_3... R_10$のようにラベルを付与する．

\section{実装フェーズ}
実装フェーズは，各要件を満たすソースコードを 大規模言語モデルを用いて生成する．
Jiang らは，分割した要件のみに基づき，各要件を実現するソースコードを並行して生成していた．
その場合，要件間での断片化が発生し，生成されるコードの整合性が崩壊する課題が発生した．\cite{TOSEM} 
本研究は，個々の要件文に加え，要求文を 大規模言語モデル に入力し，ソースコードを生成する．
Listing \ref{sample_prompt}は，開発を担当する 大規模言語モデル へ与えるプロンプトの一部を抜粋したものである．

\begin{lstlisting}[caption={実装を行う LLM へ与えるプロンプト例},label={sample_prompt}]
"Programmer_2": [
"You are Programmer_1 at ChatDev. Focus subtask: {subtask2}.",
"The overall outline of the project is as follows: {overall_task}",
"Strictly follow the current phase’s Output rules.",
"Constraints: single file 'main.py'; STDIN/STDOUT only; stdlib only; no extra logs.",
"Respect any required region markers (e.g., '# [SUBTASK 2 START]' / '# [SUBTASK 2 END]'); do NOT add '__main__' unless asked.",
"Output EXACTLY ONE file in the requested format: start with 'FILENAME: main.py' then a single code block."
]
\end{lstlisting}


ここで要件文$R_1$と要求文に基づいて生成されたソースコード一式をスナップショット 1 ($S_1$) とする．次の要件 $R_2$ は，要求文と前の要件$R_1$ で生成したスナップショット1($S_1$) を入力とし，ソースコードを生成する．
ここで生成されたソースコード一式をスナップショット2 ($S_2$) とする．
このように，本研究では従来研究のような要件のみでソースコードを生成するのとは異なり，要求文と前の要件で生成したスナップショットも入力として用いる．

一方で，段階的に生成されたソースコード(成果物)が大きくなり，大規模言語モデルが参照すべき情報を取りこぼしたり，生成されたソースコードやコンテキストに対して誤った理解を行ってしまう場合がある．
また，段階的生成は直前の成果物への依存が強いため，初期段階で誤った実装や前提の取り違えが発生すると，その誤りが後々まで波及してしまう可能性がある．
\memo{この対策についてはあとできれいに書く}

誤ったソースコードが生成された場合には，後に参照されるスナップショット自体が誤りを含むため，誤りが残存し，最終的に入出力テストが見通貨になりうる．
この場合，本手法は再計画フェーズへ移行し，差分行数に基づいた要件統合・再分割によって要件粒度の見直した上で，更新後の要件列から実装フェーズを再実行し，再度ソースコードを生成する．
但し，失敗の原因が分割粒度や問題文の前提の誤解などに起因する場合には，再分割のみでは改善しない可能性があり，この点は手法上の限界として位置づけられる．


\section{再計画フェーズ}
再計画フェーズでは，スナップショットの追加行数に基づく要件の統合と，統合した結果を用いた再分割を実施する．

2.2 節で示したように，要件に対する実装量が過度に小さい場合，大規模言語モデル の注意資源や推論能力を必要以上に消費し，意図しない要件を実装する可能性が存在する．\cite{TOSEM}
本研究では，各要件に対して生成されたソースコード規模が小さい場合，ソースコード生成後に要件の分割粒度を再検討し，要件を統合して再生成する．
本研究では，要件$R_i$を実装するステップで新たに作成された行数を，要件が生成されるコードの変更規模として扱い，要件統合の判断基準として用いる．
具体的には，問題毎の要求から分割された要件の総数を n，i番目の要件 $R_i$ に基づき生成したソースコードのスナップショット $S_i$ において，ソースコードの総行数を $LoC_i$ とする．
連続する 2 つのスナップショット対を Si−1 から Si までで追加及び修正された行数を $\Delta \mathbf{LoC}_i = \mathrm{LoC}_i − \mathrm{LoC}_{i-1}$ とする．

式 (1) で算出した差分行数$\Delta \mathrm{LoC}_i$ が，本研究で決定した閾値を下回ると，要件 $R_i$ は直前の要件 $R_{i−1}$ と統合する．
尚，本閾値は探索s的に採用した仮定であり，妥当性の厳密な検証は今後の課題である．

\begin{equation}
  \Delta \mathrm{LoC}_{i} \le \mathrm{LoC}_{n} / n
\end{equation}

統合後は，統合した要件群を基にコードを生成し直す事で，要件統合が生成結果に与える影響を調査する．
具体的には，統合後の要件列に基づいて，実装フェーズを再実行し，得られた成果物に対して入出力テストを用いて，テスト通過率の変化を調査する．


\section{プロセス反復}

取得した統合後要件の集合から無作為にサンプルを抽出し，計画フェーズと同様にfew-shot学習の学習例として与える．
これにより，要求文から要件文へ分割する際の粒度や分割方針を，テストを通過した分割例に基づいて更新すると共に，分割粒度を大規模言語モデルが学習しやすいレベルへと変化させる事を狙う．
そして，以上の手順を繰り返す事で，要求文から分割・抽出される要件の粒度最適化を図り，それにより，分割粒度の不適切さに起因する断片化や取りこぼしを軽減しながら，入出力テストの通過率の向上を目指す．



\chapter{評価実験}
\section{データセット}
本研究では，満たすべき要件が自然言語で明確に記述され，生成したソースコードを検証可能なデータセットとして，競技プログラミングサイトである AtCoder の問題を対象に評価実験を行う．
AtCoderはAから難易度が低い順に問題の難易度が設定されており，評価実験のためにC・D・E・F問題を各200問の800問と，few-shot学習の学習用に各難易度で4問ずつを使用する．
難易度の低い問題では要件の分割により，タスク粒度が過度に小さくなってしまう可能性を考慮して，A問題とB問題は，実験から除外する．

\section{評価手法}
各問題は 2件から4件程度の入出力サンプルを備えており，これを評価用テストとして活用し，生成したソースコードの評価に用いる．
また，大規模言語モデルの事前学習に用いられる学習用データの多くは英語が中心であり，他言語と比較して性能の差が挙げられる \cite{LLM_English}．
要件の理解の一貫性や再現性を担保するために，問題文などの自然言語は全て英語の問題を対象とする．


\section{実験設定}
計画フェーズでは，著者が手動で要求文から要件分を作成し，それらを 大規模言語モデル に few-shot 学習させ，AtCoderの問題800問の分割の自動化を行った．
大規模言語モデル へ入力するプロンプトには，要求文と要件群の例以外に，「根幹となる機能ほど順番を前にする事」，「分割コストの観点から分割の上限数を 10 個に制限する事」の 2点を指示した．Jiangらの研究 \cite{TOSEM} で，要件の分割を行う際に few-shot 学習で与える分割例の最適な数は 4 個から 8 個であったため，本研究では 8問（C 問題，D 問題をそれぞれ 4 問）の例を提示した．

大規模言語モデル は実行ごとに生成結果にばらつきが生じるため，AtCoderの800問を対象に，要件の細分化およびソースコード生成を各問題につき 3回ずつ実行し，結果の一般化を図った．
生成したソースコードの評価は，問題ごとに提供される入出力サンプルを入出力テストとして扱い，テスト通過率を用いる．
AtCoder の問題の特性上，入出力は標準入力・出力が想定されているため，3.1 節で拡張した段階的に開発を行う各大規模言語モデルエージェントに対して，アプリケーションのようなインタフェースは作成しないように命令を追加した．

本研究では要件の細分化やプログラマやソースコードレビュアーなどの段階的ソースコード生成において，料金と性能を考慮し，大規模言語モデル として GPT-4o-mini\cite{GPT_4o_mini} を使用した．


\section{RQs}
\paragraph{RQ1: 計画フェーズ・実装フェーズに基づくソースコード生成は，従来手法と比較して有効であるか？}

大規模言語モデル に対して全体概要を学習することで，生成結果の断片化を抑制し整合性を担保する．
また，few-shot 学習による要求文から要件文への分割により，ソースコードを生成できるか否かをテスト通過率により評価する．
RQ1 では，要件の分割を行わない従来の ChatDev との比較だけでなく，対照実験として従来研究 \cite{TOSEM} と同様に few-shot学習のみを行わなかった場合（zero-shot 学習による要件の細分化を実施し，各 大規模言語モデル の入力に全体概要を含む）と，全体概要の提示のみを行わなかった場合（few-shot 学習による要件の細分化を実施し，各 大規模言語モデル の入力に全体概要を含まない）場合の結果を比較する．
先行研究\cite{TOSEM}では，段階的開発における整合性の断片化により，全体整合を保った実装が困難であると述べられている．
その為，計画フェーズでのfew-shot学習による要求分割と実装フェーズでの分割前要求文(全体概要)の共有がテスト通過率の改善に寄与するかを検証する．
一方で，評価がAtCoderに備わった入出力サンプルに依存する為，仕様網羅性に限界がある．

\paragraph{RQ2: 要件の統合により，テスト通過率に変化は見られるか？}
 再計画フェーズで実施した要件の統合により，テスト通過率が低下した場合，要件の統合のアプローチ又は，本研究で使用している閾値に問題があることが考えられる．
 よって4.2 節で述べたスナップショットの差分行数に基づく統合指標に基づき，過小な要件を統合して生成するソースコードはテスト通過率に影響を与えるか否かを調査した．
 統合する事によりテスト通過率が低下する場合，統合後の要件は統合前の要件より大規模言語モデルにとって適切でないと判断できる．
 RQ2 では，RQ1 と同様に，200 問の問題に対して3回の分割とソースコード生成し，統合前のテスト通過率と比較し，評価する．
 差分行数は要件内容と無関係な変更にも影響される為．粒度の代理指標として誤差を含み得る．
 また，統合判定の閾値が探索的である点は，結果の不確実性として残る．

\paragraph{RQ3: 要件の再分割により，分割粒度の再検討が行われるか？}
統合後王権を分割例として再利用する事で，分割された要件文の粒度を更新し，大規模言語モデルが「学習・実装しやすい単位」へ再編されるかを明らかにする．
その為の具体的手法として，要件数の増減や，1つの要件に含まれる制約条件や出力形式などの仕様制約，1つあたりのテキスト量について目視で調査を行う．
粒度変化の評価は目視で実施する為，評価者の主観が混入する恐れがある．
また，分割例として用いる分割例は無作為に選択されるため，分割の方針が偏る可能性も考えらえる．

\paragraph{RQ4: 要件の再分割により，テスト通過率は向上するか？}
RQ4では，RQ3で再分割された要件群が生成されるソースコードのテスト通過率に影響するかを確認する為，再分割前後でテスト通過率が向上するかを評価する．
具体的には，手動で作成した要件に代わり，統合した要件と分割前の要求文を 大規模言語モデル の入力とし，再度 few-shot 学習による要件の分割およびソースコード生成を行う．他の RQ と同様に，テスト通過率で評価を実施する．
改善が「粒度の改善」ではなく，few-shot学習で与えた分割例の差に起因する可能性がある．
さらに，統合後要件と分割前要求文(全体概要)の併用により，どの要素が寄与したかが解釈上不明瞭になり得る．

\paragraph{RQ5: プロセスの反復により，テスト通過率に変化は見られるか？}
本研究の提案手法は，計画フェーズ・実装フェーズ・再計画フェーズ並びに，これら3プロセスの反復を行うことで要件の粒度や構造を更新し，生成されるソースコードのテスト通過率の改善を狙う．
その為，反復回数の増加に伴い，テストが向上するか，あるいは頭打ちや劣化が生じるかを調査する．
RQ5では，初回のソースコード生成を基準とし，プロセスの反復を繰り返したテスト通過率を引比較する事で，反復が与える影響を評価する．

反復は改善だけでなく，誤った前提や不適切な要件の統合を増幅させる可能性を持つ．
また，改善が頭打ちになる場合には，その要因が粒度ではなく，問題文のコンテキストの誤解等に起因する恐れある．
また，改善が頭打ちになる場合，その要因が粒度ではなく問題文コンテキストの誤解等に起因する恐れがある．




 \chapter{結果}
 \section{RQ1}
図\ref{RQ1}，200 問を対象に提案手法によって各 3 回ソースコード生成した結果のテスト通過率を示す．

\begin{figure}[tb]
    \centering
    \includegraphics[width=0.7\linewidth]{./Toyoshima_fig/RQ1.pdf}
    \caption{few-shot 学習，全体概要の有無，統合によるテスト通過率比較}
    \label{RQ1}
\end{figure}

実験の結果，few-shot 学習による要件の細分化を実施し，各 大規模言語モデル の入力に全体概要を含む場合に，テスト通過率が最も高い 67.07\%となった．zero-shot の場合は，テストで失敗したケースにおいても入出力でエラーが発生したケースは少なく，入出力の取り扱いは概ね正しく実装されているが，出力不一致などによる失敗が多く見られた．
これは全体概要の学習で，関数の呼び出しやデータの入出力構造などをはじめとする全体の整合性が保たれる一方で，局所的推論の部分でテスト失敗となっていると示唆される．
一方で，全体概要の学習を行わず，few-shot のみの場合では，タイムアウトや関数呼び出しなど，実行時の構造的不整合に起因するエラーが相対的に多くみられた．
これは，局所的な構造自体は与えられているが，全体像が欠如している事による開発の断片化により発生したものであると考えられる．


\section{RQ2}
図\ref{RQ2_1}には，データセットに含まれるAtCoderの問題200問に備わった入出力テスト全体のテスト通過率を示す．
要件の統合前ではテスト通過率が67.07\%であるのに対して，統合後には68.76\%とおおよそ横ばいの結果が確認された．

\begin{figure}[tb]
    \centering
    \includegraphics[width=0.7\linewidth]{./Toyoshima_fig/RQ2_1.pdf}
    \caption{RQ2: 全テストでのテスト通過率}
    \label{RQ2_1}
\end{figure}

また，図\ref{RQ2_2}にはデータセットの問題200問(C問題100問，D問題100問)において，各3回ずつソースコードを生成し，それに対するテスト通過数の分布を示す．
具体的には，3回とも統合前後の両方でテストを通過した場合，3回とも統合前後の両方でテストを通過しなかった場合，統合前ではテストを通過せず統合後にテストを通過が1回以上通過するようになった場合，そしてそれ以外の場合で分類を行った．
尚，「テストを通過する」とは，問題に備わった入出力テストを全て通過したケースを指し，1つでもテストを通過しない入出力テストが存在する場合には，未通過という定義とする．
その結果，全200問のうち168問が統合前後で入出力テストの結果に変化が発生しなかった事から，テスト通過率の優位的な劣化は見られない事が

\begin{figure}[tb]
    \centering
    \includegraphics[width=0.7\linewidth]{./Toyoshima_fig/RQ2_2.pdf}
    \caption{RQ2: 問題単位でのテスト通過数}
    \label{RQ2_2}
\end{figure}

\section{RQ3}
RQ2において，要件を統合した場合においても，統合前後でテストを通過する問題数に明示的な差は確認できなかったため，RQ4では統合した要件をfew-shotの学習例として活用する事で再分割した要件からソースコードを生成するために，要求文の再分割を実施した．
few-shotで提示する分割例は，要件の統合を行った際に入出力テストを通過したケースを無作為に8問(C問題4問，D問題4問)を取得し，これら８問を除いた192問の統合を行った．

その中の一部をケーススタディ的に調査した結果を以下に示す．
\todo{目視の結果を載せる}

\section{RQ4}
RQ3で実施した統合後の要件から要求文を再分割した要件群を基に192問の問題からソースコードの生成を行い，その入出力テストを実施し，そのテスト通過の可否の結果を示す．

図\ref{RQ4_1}に，対象の192問のデータセットに備わった入出力テスト全体に対するテスト通過率を示す．
再分割前では68.76\%であったのに対して，再分割後は87.59\%とおよそ18\%のテスト通過率の向上が確認された．

\begin{figure}[tb]
    \centering
    \includegraphics[width=0.7\linewidth]{./Toyoshima_fig/RQ4_1.pdf}
    \caption{RQ4: }
    \label{RQ4_1}
\end{figure}


図\ref{RQ4_2}に，対象192問から各3回ずつソースコードを生成した際のテスト通過数の分布を示す．
具体的には，3回全てで再分割前後の両方でテストを通過した場合，3回全てで再分割によりテストを通過するようになった場合，3回のうち1回以上でテストを通過するようになった場合，そしてその他の4つに分類する．

その結果，3回全てで再分割によりテストを通過するようになったケースがC問題で24問，D問題で37問となっており，合計で192問のうち約32\%を占める結果となった．

\begin{figure}[tb]
    \centering
    \includegraphics[width=0.7\linewidth]{./Toyoshima_fig/RQ4_2.pdf}
    \caption{RQ4: }
    \label{RQ4_2}
\end{figure}

\section{RQ5}
RQ1からRQ4までで計画フェーズ・実装フェーズ・再計画フェーズ並びに要件粒度の再検討が，生成されるソースコードのテスト通過率の向上に寄与し得る事が示唆される．この事から，要件粒度を再検討する反復プロセスを繰り返し行っていく事でテスト更なるテスト通過率の向上の可能性を調査する．

具体的には，これまでのRQと同様にテスト通過数の変遷についてや，再計画フェーズ時の要件数の変化について調査する．

図\ref{RQ5}に3回ずつソースコードを生成した際に3回すべてテストを通過した問題テスト通過数の変遷の結果を示す．

\begin{figure}[tb]
    \centering
    \includegraphics[width=0.7\linewidth]{./Toyoshima_fig/RQ5.pdf}
    \caption{RQ5: }
    \label{RQ5}\end{figure}


要件粒度の再検討を繰り返した場合において，C問題，D問題共に反復回数とテストを通過する問題数における有意的な変化は確認されなかった．


\chapter{考察}
% \section{テスト通過率向上の要因分析}
本章では，第５章の結果を踏まえ，提案手法がテスト通過率の向上に寄与した要因を考察する．
本研究の結果から，計画フェーズにおけるfew-ashot学習による要求分割と，実装フェーズにおける分割前要求文(全体概要)を併用した場合に，従来手法や片方のみを導入した場合と比較して高い通過率が得られることが確認された．
さらに，差分行数に基づく要件統合は通過率を大きく悪化させず，統合後要件を分割例として用いた再分割ではテスト通過率を向上させうることが示された．
一方で，反復を重ねても通過数に顕著な改善が見られないケースも確認された．

以下では，統合・再分割の前後でテストの結果が一貫したケースを対象に，要件の区切り方と実装の対応関係に着目して考察を行う．
次に，再分割を実施することによりテストが通過するように転じたケースを対象に，要件文に含まれる意図の明治度の観点から考察する．
その後，反復による要件粒度変化と改善が頭打ちになるケースについて議論する．


\section{統合前・統合後・再分割後の全てでテストを全て通過するケース}
統合前・統合語・再分割後のいずれにおいてもテストを通過したケースでは，生成されたソースコードの主要機能は一貫して満たされているため，差異は主に「要件の区切り方」に確認される．
統合前の要件群は，変数・関数の宣言，値の代入，単一の条件分岐といった「作業単位」の細かい粒度で列挙する傾向が見られた．\todo{具体例提示する？キモくなるだけ？}
この場合，ここの要件は局所的に明示されている一方で，要件間で前提や状態，データ構造の共有が複数回において必要となり，実装時に影響を及ぼす可能性が考えられる．
しかし，問題構造が比較的単純であったり，要件間の依存関係が薄い場合においては，細かな粒度でも破綻が発生せずに通過し得る．

一方で，再分割後の要件群では，宣言から初期化，関数呼び出しまでのように，意味的に連続した処理が1つの要件として束ねられる傾向が確認された．
このような区切り方は実装時に参照すべき文脈をまとまりとして保持しやすく，整合性のを持ったソースコードを生成しやすい．
即ち，機能を維持し，一貫性を保った状態で生成可能な最小単位へと要件が再編成されたことが，全ての状態においてテストを通過したケースであることが考えられる．

また本研究の実装フェーズでは，各ステップでの分割前要求文(全体概要)と直前までの成果物を参照する．この設計により，要件の粒度が細かな場合においても全体としての入出力形式や主要データの流れが参照可能となり，変数名・関数名の揺らぎやインタフェースの不整合を抑制可能となる．そのため，統合前後で要件1つあたりの粒度が違っている場合でも，テストが通過した可能性が考えられる．\todo{ここの段落はRQ1に対応する部分なので，この考察だけは前に持ってくる？}


\section{再分割により改善が見られたケース}
再分割によって未通過から通過へ転じたケースでは，大きくく分けて「再分割前の要件に意図が十分に明示されているか」と「要件文に沿ったコードが生成されているか」の2点に分けて考察を行う．

\subsection{再分割前の要件に意図が明示されているか}
統合前・統合後の段階では，要件が過度に細かい場合に大規模言語モデルは要件間の接続を推測しながら実装を進める必要がある．
この時，変数に格納された値の更新手順や，分岐条件，境界値の扱い，例外処理などといった細やかな意図が要件群の中に分散する．
その結果，各要件を局所的に満たした場合においても，他の要件の理解が不十分となることに起因する解釈の揺らぎが発生してしまう．
この揺らぎは入出力テストにおいて出力不一致や，条件分岐の漏れとして健在化し，未通過の要因となり得る．

一方，再分割の過程では統合語要件を分割例として参照することで，要件1つあたりの粒度が問題の構造に合わせて再編成される．
その結果，宣言から更新，分岐，出力までのように，意味的に連続した処理が同一の要件にない方されやすくなり，要件間の工程的な繋ぎ目が現象したことが確認された．
また，要件粒度の向上により，各要件1つあたりに記述できる情報量の余地が発生し，これまで反映しきれていなかった意図を要件内で提示することが可能となった．
実際に改善が見られた事例では，細かな値の更新や分岐制御，境界値の扱い，入出力形式，例外時処理の扱いなどが要件文内に含まれるようになった事が確認さえた．
このような意図の明示化により，前提や出力の揺らぎが抑制され，糸が一貫して実装に反映されるようになった可能性がある．


\subsection{要件文に沿ったコードが生成されているか}
再分割前に意図が部分的に記述されていた場合においても，要件粒度が細かく分散している場合では，大規模言語モデルが要件間の依存関係や変数の意味やデータ構造などの前提を正しく理解できない場合がある．
本研究の実装フェーズでは，要求文と同時に分割前の要求文を提示し，全体の前提条件を参照しながらコードを生成する工夫を実施しているが，要求文を平気した場合においても前提条件が要件のどの箇所にどのように適応されるべきかのコンテキストを大規模言語モデルが十分に読み取ることができない場合があり，その結果として要求文を満たすソースコードを生成できないケースが発生している．

これに対し，再分割後は要件が意味的まとまりとして提示され，各要件内で入出力条件や，格納した値の更新，分岐などがまとまって記述される傾向が確認された．\memo{やっぱり具体例提示しないとイメージしてもらえる気がしない}
その結果，1つあたりの要件粒度が大きくなり，先行研究でも提示された大規模言語モデルが学習しやすい粒度へと変化し，コンテキストや前提条件の理解不足が抑制され，要件に沿ったソースコードが生成されるようになったことが考えられる．


\section{プロセスの反復によるテスト通過の可否}
本節では再分割によって得られた「テストを通過した要件群」を分割例として再利用し，計画・実装・再計画の3フェーズを反復がテスト通過率に与える影響について議論する．


先の節子で示した通り，反復に回数の増加に伴う通過数の一環した増加は確認できず，特に高難易度問題においては未解決となった問題が多く残った．
反復による改善が頭打ちとなった要因として，要件の区切り方や粒度の調整ではなく，問題文のコンテキストの理解における失敗が考えられる．\memo{文キモい気がする．あとで見直す．}

実際にプロセスの反復を実施した中で，テストが継続して通過しなかったケースをケーススタディ的に確認したところ，境界条件や偶奇処理の誤解，配列インデックスの取り違えや，処理の順序誤りなどが確認された．
また，加えて，処理に無関係な関数の定義などの過剰実装が行われ，重要な処理の検討が不十分となる例も観察された．これらのように，コンテキストの誤解が生成されるソースコードに与える影響は甚大であり，大規模言語モデル上で誤解を解くためのアプローチが行われない限り，生成されるソースコードには同種の誤りを内包してしまう事が考えられる．
大規模言語モデルの持つ生成結果の「揺らぎ」〜〜〜．\memo{どう考えてもキモい．LLMなんだから生成毎に結果変わりうるよね．でも，基本のモデルはおんなじなんだからコンテキストの誤解を解くのってそんなに簡単かな？みたいな文を作る．}

これらは，データセットとして使用するAtCoderの問題が競技プログラミング用の問題であるため，状況説明などをはじめとするストーリー性を問題文が包含している事から，暗黙の制約や規則を読み取る必要がある，という性質が一因である事が考えられる．
即ち，反復プロセスが「要件粒度の最適化」であるのに対しては有効に働く一歩上，問題そのものの誤解に起因する失敗が原因となる場合には，反復だけでは継続的な改善が困難である事が考えられる．

以上により，反復によるテスト通過率向上を安定して得るには，要件再分割の前段階として，問題文から制約条件，例外処理，入出力フォーマットなどを明示的に構造化して抽出し，大規模言語モデルが誤解しにくい形式へ変換する処理の導入が求められることが考えられる．


\chapter{妥当性の脅威}
本章では，本研究における結果の信頼性に影響を及ぼす可能性のある要因を，内的妥当性および外的妥当性の観点から述べる．

\section{内的妥当性}
本研究では，生成したソースコードの正しさを入出力テストの通過可否を用いて評価する．
しかし，競技プログラミングであるAtCodernの入出力サンプルは，仕様全体を網羅するテストの集合ではないため，テストを通過しても未検出の欠陥を見逃してしまう可能性がある．
その結果，提案手法間の差が「使用適合度」ではなく，「サンプルへの適応度」として観測される恐れがある．\memo{なんか文がキモい？入出力サンプルにだけガゴンしすぎてる可能性についてわかりやすく．データセットの拡張が必要みたいな？(流石にここでSWE-benchの話はキモすぎる？)}

また，本研究では要件統合の際に，ソースコードのスナップショット間の差分行数を用いる．
差分行数は，要件と直接関与しないような警備な変更の影響を受けるため，差分行数が要件の重要度や粒度を正確に表現しない可能性がある．
この点は統合の閾値設定や差分抽出方法により結果が変動し得るという恐れもある．\memo{ここをあっさり流しすぎ？}

そして，本研究には大規模言語モデルを使用しており，その特徴として「同一入力に対しても生成結果が変動し得る」という点が挙げられる．
本研究では各問題につき複数回実行することでその大規模言語モデル特有の「揺らぎ」を低減している一方で，モデルの更新や実行環境の差により再現性が損なわれる可能性がある．


\section{外的妥当性}
本研究の評価対象は競技プログラミングサイトのAtCoderの問題であり，標準入力・出力によってテストが判定される形式である．
この形式では，入出力使用や制約が比較的明確である一方で，実システムの開発で扱う非機能要件や外部APIの使用，運用制約などは含まれにくい．
そのため，本研究で得られた有効性が実務的な開発業務へ同程度に一般化可能であるかは未知数である．

また，実験は単一ファイル・標準入出力を前提としたソースコード生成であり，複数モジュール構成や依存関係管理，結合時のインタフェース整合性など，実システムで重要となる要素を十分に反映できていない．
よって，本研究で確認されたソースコードの品質向上の効果が，複数ファイル構成の開発で同様に得られるかについても未検証である．

本研究では，要求理解の一貫性や，大規模言語モデルの学習データ量をベースに英語の問題文を対象としている．
そのため，日本語要求や箇条書き形式の仕様書などの要求形式が異なる場合に提案手法が同様に機能するかは不明であり，言語・形式の違いに対する一般化は今後の検証が必要となる．


\chapter{終わりに}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%
% 謝辞
%
\begin{acknowledgements}


% written on 2026-01-09

\end{acknowledgements}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% 参考文献
%%
\bibliographystyle{junsrt}
\bibliography{@Bachelor2025_Toyoshima/references}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% 付録
%%
% \appendix
% 
% \chapter{サンプルプログラム}
% 
% プログラムリストや実行結果など，本論を補足する上で必要と思われるものが
% あれば付録として付ける．
% 
% {
% \footnotesize
% \begin{verbatim}
% #include <stdio.h>
% int main(void)
% {
%     printf("Hello, World!\n");
%     return 0;
% }
% \end{verbatim}
% }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
