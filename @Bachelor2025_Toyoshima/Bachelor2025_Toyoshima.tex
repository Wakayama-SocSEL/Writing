\documentclass[11pt]{jreport}
\usepackage{wuse_thesis}
\usepackage{indentfirst}
\usepackage{url}	% \url{}コマンド用．URLを表示する際に便利
\usepackage[dvipdfmx]{graphicx,xcolor}
\usepackage{listings}
\usepackage{enumitem}
\usepackage{fvextra}
\usepackage{otf}

\lstset{
  basicstyle={\ttfamily},
  identifierstyle={\small},
  commentstyle={\smallitshape},
  keywordstyle={\small\bfseries},
  ndkeywordstyle={\small},
  stringstyle={\small\ttfamily},
  frame={tb},
  captionpos=t,
  breaklines=true,
  columns=[l]{fullflexible},
  numbers=left,
  xrightmargin=0zw,
  xleftmargin=3zw,
  numberstyle={\scriptsize}, 
  stepnumber=1,
  numbersep=1zw,
  lineskip=-0.5ex
}
\usepackage{siunitx}
\sisetup{group-separator={,}} % 3桁ごとにコンマを入れる設定
%\usepackage{graphicx}  % ←graphicx.styを用いてEPSを取り込む場合有効にする
			% 他のパッケージ・スタイルを使う場合には適宜追加
\newcommand{\todo}[1]{\colorbox{yellow}{{\bf TODO}:}{\color{red} {\textbf{[#1]}}}}
\newcommand{\memo}[1]{\colorbox{magenta}{\textbf{MEMO}}{\color{red}\textbf{[#1]}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% 主に表紙を作成するための情報
%%

%%  タイトル(修論の場合は英語表記も指定)
% \title{大規模言語モデルによるソースコード生成のための最適化プロセスと反復プロセス}
\title{反復的要求文分割に基づくマルチエージェント\\段階的ソースコード生成}
%\etitle{Test\\Test\\Test}

%%  著者名(修論の場合は英語表記も指定)
\author{豊嶋 浩基}
%\eauthor{Akinori Ihara}

%% 卒業論文・修士論文(以下のどちらかを選択)
\bachelar	% 卒業論文(4年生用)
%\master  	% 修士論文(M2用)

%%  学科・クラスタ
\department{システム工}
%\department{デザイン情報}
%\department{デザイン科学}

%%  学生番号
\studentid{60276157}

%%  卒業年度
\gyear{2025}		% 提出年が2022年なら，2021年度

%%  論文提出日
\date{2026年2月10日}	% 修士の場合は月(2021年2月)までとし，英語表記も指定
%\edate{February 2021}	% 修士の場合，こちら(英語表記)も有効化

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle

%%
%%  概要
%%
\begin{abstract}
大規模言語モデル(LLM)はソフトウェア開発の自動化に貢献する一方で，複数の機能や制約が相互に依存する複雑な要求文に対しては，要件文の取りこぼしや開発の断片化により，要求文を満たしたソースコード生成が困難である．本研究では，大規模言語モデルを用いたマルチエージェント型ソースコード生成プラットフォームであるChatDevを拡張し，要件文分割と段階的実装を統合した反復的な開発プロセスを提案する．提案手法として，few-shot学習を用いて要求文を実装すべき要件文の集合へ分割する計画フェーズ，各要件文を実装する際にその時点で生成された成果物と分割前の要求文を参照しながらソースコードの実装を行う実装フェーズ，分割された要件文の粒度に着目し，生成されたソースコードの差分行数に基づいて過小な要件文を統合し，統合結果を基に再度要求文の分割を行う再計画フェーズの3フェーズで構成され，これらを反復することにより，要求文を満たしたソースコードの生成を目指す．競技プログラミングサイトであるAtCoder \footnote{\url{https://atcoder.jp/}}の問題を用いたケーススタディにより評価を実施した結果，few-shot学習による要求文分割と全体概要の共有の組み合わせによるテスト通過率の向上や，さらに統合結果を用いた再分割によりテスト通過率を向上することを示した．

\end{abstract}

%%  目次
\tableofcontents

%%  図目次 (図目次をいれたければ以下のコメントをはずす)
%\listoffigures

%%  表目次 (表目次をいれたければ以下のコメントをはずす)
%\listoftables

\newpage
\pagenumbering{arabic}	% 以降のページ番号を算用数字に

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%%  本文はここから
%%

\chapter{はじめに}

大規模言語モデル(LLM)技術の急速な発展に伴い，大規模言語モデルはこれまで人間が時間や労力をかけて取り組んできたタスクの自動化を実現し，幅広い分野において作業を効率化する技術として関心を集めている\cite{LLM_Development}．
ソフトウェア開発においても同様に，コードレビュー，リファクタリング，テストケース生成など，様々な場面において飛躍的に生産性を向上させることが確認されている\cite{Use_LLM_1, Use_LLM_2, Use_LLM_3}．
その中でも，開発者の意図や要件文をプロンプトとして提示し，ソースコードを自動生成するタスクに対して大きな期待が寄せられている\cite{LLM_Code_Generation}．

大規模言語モデルは，自然言語で記述された要求文に基づきソースコードの自動生成を実現し，昨今では複雑で，大規模なソフトウェア開発の自動化に向けた研究が進められている\cite{LLM_Code_Generation}．
規模が小さいソフトウェアの要求文は実現できる一方で，ソフトウェア要件文が複数内包し，それぞれが相互に依存し合う大規模なソフトウェア要件文を満たすソースコード生成には課題が多い．
従来研究ではソフトウェア要件文が複雑になると，大規模言語モデルが十分に推論せずに，短絡的なソースコードを生成することが示されている\cite{Abandonment_of_Inference}．
例えば，仕様の一部が欠損している場合や，要件文の文脈を正しく理解できない場合には，生成されるソースコードの構造的なロジックの誤りが見られる．
このようなロジックの誤りは，大規模言語モデルが要求文を解釈し，機能ごとの要件文へ分解した上で実装へと落とし込むという処理過程において発生する．
要件文が複雑で相互に依存する場合，要件文を解釈する段階で誤解が発生しやすく，その誤りが開発に波及することで，不完全なソースコードの生成に繋がると考えられる．

大規模言語モデルの理解や推論を補助するプロンプト技術として，思考の過程を明示的に示すChain of Thought(CoT)や，要求文を満たす例を少数提示するfew-shot学習が用いられてる\cite{LLM_few_shot}．
これらは局所的な推論の補完や思考パターンの学習には有効である一方で，プログラミング言語のように記述方法や実装方法によって同一の要件文に対して多様な解が存在する領域では，これらの手法のみでは十分な性能を発揮しにくい．

このような課題に対して先行研究では，要求文から要件文を抽出するフェーズと，それらを基にソースコードを生成するフェーズの2つに分割する手法が取り入れられている\cite{TOSEM}．
前者では，大量のデータ収集やそれに対するラベリング，再学習などを要するファインチューニングと比較して，追加学習することなく大規模言語モデルの挙動を制御できるfew-shot学習が採用されている．
後者の，抽出した要件文を基に段階的に開発する手法では，生成されたソースコード断片の統合時に，各断片における前提が共有されず，ソースコード単位での整合性が破綻する課題に言及している．

本研究では，従来研究\cite{TOSEM}で指摘された要求文抽出の不安定さ，及び段階的開発におけるソースコードの断片化に対し，依存関係を保ったまま要件文の抽出を行い，それらの要件文から並列的にソースコード生成するのではなく，既に生成されたソースコードを基に逐次的に統合を行う段階的開発を行う手法を提案する．
段階的に開発する各工程において，大規模言語モデルに対して実装すべき要件文に加えて，全体概要を明示することで生成されるソースコードの全体整合を目指す．
加えて，分割された要件文に基づく生成結果を評価し，要件文の統合と再分割及び，再分割された要件文を基にソースコードの再生成を実施するアプローチを複数回反復することで，プロンプトと要件文構造を更新し，マルチエージェント型ソースコード自動生成の品質向上を狙う．

論文構成は以下の通りである．
2章で本研究で使用するプラットフォームや，キーアイディアのベースとなる先行研究について，3章ではそれらに基づいたアプローチを述べ，4章でそのアプローチに関する実験設定やRQ列挙し，5章でそれに対する結果を，6章と7章でそれらを基にした考察と妥当性の脅威について議論した上で，8章で結論を述べる．


\chapter{ソフトウェア開発における大規模言語モデルの活用}

\section{ソフトウェア開発工程の大規模言語モデルによる再現・自動化}

\subsection{工程分担型の開発自動化}
大規模言語モデルを活用したソフトウェア開発プロセスの全工程では，自動化を目的としたシステムとして，MetaGPT，AutoDevなどの開発が盛んに進められている\cite{META_GPT, AutoDev}．
本システムは，ソフトウェア開発プロセスにおける各工程（要求文定義，設計，実装，テスト，保守）を自然言語の理解と生成能力により自動化する仕組みである．
本研究では，各工程の役割を担うエージェントがそれぞれ要件文定義から実装までを実現するChatDev\cite{ChatDev}を用いる．

ChatDevは，要件文定義，設計，実装をウォーターフォールモデルに則って開発を進める過程で，各工程において設計者やプログラマといった役割を与えられた2つの大規模言語モデルエージェントが対話しながら開発を行うプラットフォームである．
ここにおけるエージェントとは，大規模言語モデルに対して役割(プログラマやコードレビュアなど)や実装すべき要件文を与えることで，工程ごとの振る舞いを分担させた実行単位である．
各工程で開発を担当するエージェントが，プロンプトで与えられた要件文，または前工程で生成された成果物（ソースコード）に基づき，新たな成果物を生成する．
図\ref{ChatDev_abst}に，ChatDevの工程分担と，工程内でのエージェントと成果物共有の流れを示す．

\begin{figure}[tb]
    \centering
    \includegraphics[width=0.7\linewidth]{./Toyoshima_fig/ChatDev_abst.pdf}
    \caption{ChatDev概要}
    \label{ChatDev_abst}
\end{figure}


ChatDevの枠組みは，各工程のタスクが明確である点や，フレームワークがオープンソースとして公開されており，自体の構造の確認や書き換えが可能であるため，拡張性に優れている．
一方で，各工程で開発を担当する大規模言語モデルに対して，同一の要件文（プロンプト）が与えられるため，多数の機能を内包するような複雑・大規模な要件文の場合，各フェーズでのタスクの粒度が大きくなり，不完全なソースコードが生成される．

\subsection{複雑な要求文の分割に基づくソースコード生成}
Jiangら\cite{TOSEM}は，few-shot学習により大規模言語モデルを用いて要求文から小さな実装単位の要件文に分割する「計画フェーズ」と，分割後の要件文を基に開発を行なっていく「実装フェーズ」を組み合わせた手法を提案している．計画フェーズにおいてfew-shot学習として分割例を入力して要求文を分割することで，分割した要件文を最適な粒度に均一化することを目指している．
当該研究が提案する分割後要件文の粒度の最適化を図る「要件文の細分化」と「細分化後要件文の統合と再分割」は，大規模言語モデルの推論の最適化プロセスの1つとして重要である．
さらに実装フェーズにおいては，分割後の要件文を個別に並行に実装するよりも，開発順序を定めるガイドとして参照しつつも，全体を一括で生成する構成が最も高性能であると報告されてる．
先行研究では要件文ごとにソースコード断片を並列に生成してから最終的に統合する方式は，各ソースコード断片を生成する大規模言語モデルがそれらの要件文のコンテキストを誤解しやすく，統合時に不整合が生じて全体の，断片化，が発生すると指摘されている．

以上を踏まえ，本研究ではプロンプトとその時点で生成された成果物を基に開発を行う構造へとChatDevを変化させることで段階的開発を実施しながらも，断片化を回避する手法について調査する．


\section{要求文の分割と分割粒度}

\subsection{問題複雑度が推論過程に与える影響}
Shojaeeら\cite{Abandonment_of_Inference}は，複雑度の制御が可能かつ，解法が明確な数学的パズル問題を用いて，大規模言語モデルの最終的な解とそこに至るまでの推論過程を調査した．
その結果，難易度が上昇するにつれて正答率は緩やかに低下すると同時に，複雑度が一定の閾値を超えない場合においては推論過程での思考量が増加することが確認された．
一方で，複雑度が一定の閾値を超えると思考量は急減し，推論が打ち切られ，大規模言語モデルの推論精度が低下することが確認された．
加えて，推論過程の調査により，複雑度が低い場合は正解まで早く到達するが，その後も不要に探索を続けてしまう過剰な推論ステップを踏むことが確認された．
このような大規模言語モデルの挙動は，高い推論能力を要する自然言語からのソースコード自動生成においても同様に発生し得るものである．
複数要件文を内包する複雑な要求文からは，依存関係の見落としや，断片化したソースコードの生成により，全体整合性の破綻が発生しやすい．

\subsection{分割粒度が生成品質に与える影響}
大規模言語モデルを用いたソースコード生成では，要求文から一括で実装させるのではなく，要求文を複数の要件文に分割し，分割した要件文を基に逐次的に段階的開発を進める手法が検討されている\cite{TOSEM}．
ここで重要となるのが，要求文から分割する要件文の大きさ，即ち分割粒度である．
分割粒度は，単に要件文の分割数だけでなく，各要件文が内包する処理の範囲や抽象度などとして捉えられる．
分割粒度の設計を誤ると，大規模言語モデルに対する理解負荷の増大化により，要求文を満たしたソースコードが生成されなくなる恐れがある．

分割粒度が粗すぎる，即ち要件文1つあたりの粒度が大きすぎる場合，大規模言語モデルは入出力条件や例外処理，データ構造などをはじめとする多くの制約を保持しながら実装する必要がある．
その結果，仕様の取りこぼしや，局所最適実装などが発生する．
一方で，分割粒度が細かすぎる場合にも，分割後要件文を独立に実装して，後々に統合する時に，大規模言語モデルが学習可能なコンテキストが限定され，関数名や引数，戻り値などのインタフェース，共有するデータ構造，前提条件の齟齬などが発生しやすい．
また，そのようなソースコードに対しては，統合やレビュー，再生成の回数が増加することから，運用上のコストが増大する．

以上のことから，要件文の分割には大規模言語モデルが整合性を保ちながら扱うことのできる分割単位を見極める必要がある．



\section{本研究の位置付け}

大規模言語モデルを用いたソフトウェア開発支援，自動化の研究は大きく分けて，要件文定義から実装・テストまでを工程ごとに分担し，複数の大規模言語モデルエージェントの協調によって開発プロセス全体を再現するアプローチと，複雑な要求文を小さな実装単位へ分割し，計画に基づいて段階的にソースコードの生成を行うアプローチに整理することが出来る．

本研究では，段階的に生成された成果物で入出力形式や，インタフェースなどの前提条件や，要求文のコンテキストを大規模言語モデルが誤解することにより発生する整合性が失われる事象を開発の断片化として定義する．

マルチエージェントでの開発プロセスを再現するアプローチの代表例であるChatDevでは，ウォーターフォールモデルの工程に役割を当てたエージェント同士が対話と開発途中のソースコードの共有を行いながら生成していく枠組みを提供する一方で，要求文を分割して段階的に開発を進める仕組みは想定されておらず，単一プロンプトに依存する為，複雑な応急では各工程のタスク粒度が過大になりやすい．
計画に基づくソースコード生成のアプローチは，分割によって一括で生成させる場合と比較して大規模言語モデルにかかる理解負荷を軽減する一方で，要件文間の断片化が発生し得る．

本研究では，要求文の分割による段階的開発をベースとしつつ，随時成果物の共有を行う工程ベースのChatDevを取り入れる．
加えて，各工程を担当する大規模言語モデルに対してその時点で生成された成果物(ソースコード)と分割前の要求文(全体概要)の提示に加え，一度分割された要件文から生成されたソースコードに基づき再度，要件文の粒度を再検討・再分割を行うプロセスを導入することで開発の断片化とを抑制したソースコード生成を可能にする．

\chapter{段階的開発と分割粒度の再検討}
\section{アプローチ概要}
ChatDev\cite{ChatDev}は，単一のプロンプトから設計，実装，コードレビュー，テストのようにウォーターフォールモデルの流れを実施し，ソースコードを生成している．
従来のChatDevにおいては，要求文を分割して，段階的に開発を進める仕組みを持たない．
それに対して本研究では，分割された要件文からそれに対応する開発が実施できるように構造を拡張し，ソフトウェア生成の精度向上を目指す．
具体的には，本手法は要求文を複数の要件文に細分化する「計画フェーズ」と，細分化された要件文を基にソースコードの生成を行う「実装フェーズ」, 実装フェーズで生成されたソースコードを基に要件文の統合と再分割を実施する「再計画フェーズ」の3フェーズで構成される．
図\ref{approach_abst}に，本手法の概略図を示す．

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{./Toyoshima_fig/approach_abst.pdf}
    \caption{アプローチ概要図}
    \label{approach_abst}
\end{figure}

計画フェーズでは，従来研究と同様に，ソフトウェアの要求文を大規模言語モデルに対してfew-shot学習を実施することで，要求文を要件文に細分化する．
従来研究\cite{TOSEM}で示されるように，思考のプロセスを大規模言語モデルに提示して学習させるChain-of-Thought(CoT)\cite{Chain_of_Thought}や，大量のラベルデータが必要となるファインチューニング\cite{LLM_fine_tuning, LLM_fine_tuning_2}は導入コストが高くなることから，少数のサンプルで要求文からの分割タスクに適応させられるfew-shot学習を本研究では使用する．

実装フェーズは，細分化された要件文をウォーターフォールモデルの流れで段階的にそれぞれ実装を進める．
各ステップで大規模言語モデルには3種類のデータを入力する．
(1)実装する要件文，(2)分割前の要求文，(3)開発済みの成果物．
但し，(3)はプロセス反復後の実装時に限る．
従来研究\cite{TOSEM}は，計画フェーズで得られた要件文に基づき逐次的にソースコードを生成するのに対して，本研究では(2)の分割前の要求文と(3)の開発済み成果物を各ステップで合わせて提示することで，要件文間でデータ構造や入出力形式，インターフェースなど共有すべき前提を維持する．
これらのデータに基づき，各要件文を大規模言語モデルにより実装する．

再計画フェーズでは，計画フェーズで要求文から分割された要件文の粒度が過大・過少にであることが原因で生成されるソースコードがテストを通過しないケースを考慮し，実装フェーズまでで生成したソースコードを基に，計画フェーズで要求文から分割された要件文の集合を統合する．
なお，再計画フェーズは生成されたソースコードの差分行数に基づいて要件文を統合し，要件文の粒度を均一化し，最適化を目指すために本研究で新たに定義するフェーズである．
要件文の統合して作成した要件文を大規模言語モデルに学習させることで要求文から要件文への再分割を実施する．
統合した要件文から生成されたソースコードに対しても同様に入出力テストを実施し，統合によるソースコードの劣化が発生するかを調査する．

そして，これらの3つのフェーズを反復することにより，要求文の分割粒度を最適化を図ることで，テスト通過率の高いソースコードを生成する．


\section{計画フェーズ}

要求文の分割は，異なる開発者が行うと分割粒度が異なることも少なくない\cite{Division_Size}．
大規模言語モデルも同様に，共通した粒度で要求文を要件文に分割することは容易でない．
また，分割粒度が不適切な場合，大規模言語モデルが解釈を誤ったり，2.2.2節で示したように推論を放棄してしまう恐れがある．
分割粒度が過大な場合には，1つの要件文に複数の機能や制約が混在することで複雑化し，重要な条件の取りこぼしが発生しやすくなり，過小な場合には要件文数が増加することにより要件文間の依存関係や，不明瞭な状態で局所的実装が進むため，全体の不整合が生じる．
これらを回避するために，本研究では大規模言語モデルに対して少数の正解例を提示し，膨大な教師データを用いることなくタスクに適応させるfew-shot学習を実施し，要求文の分割を実施することと，要件文の粒度の見直しプロセスを導入することで要件文の粒度の最適化を目指す．
また，本研究でfew-shot学習で提示する正解例は，著者が手動で要求文から要件文への分割を実施し，それらの要件文に基づいてソースコードを生成した結果，入出力テストを通過したものを提示するものとする．

Listing \ref{split_prompt}は，要求文を分割するプロンプトの一部を抜粋したものである．


\begin{lstlisting}[caption={要求文分割プロンプト（一部抜粋）},label={split_prompt}]
# Role
You are an expert in software requirements elicitation.

# Objective
From an AtCoder problem statement and its constraints, extract the requirements and split them into 10 or fewer subtasks.

# Requirements
- Identify the input format and state how it will be handled in the first requirement.
- Decide which function to pass the given arguments to, and name functions/variables wherever possible.
- Mention the output format in the last requirement.
- Think of this as converting a story-like text into a list of implementable events.
- Return only the subtask list (no extra commentary).
\end{lstlisting}

few-shot学習に用いるソフトウェア開発データは，分割後の要件文に基づき大規模言語モデルで生成したソースコードが入出力テストを全て通過しているものとする．
また，分割時に「重要な機能であればあるほど前方に配置する」という命令を与え，ソースコードの主要処理から実装するように実装する順番も大規模言語モデルが決定する．
実装する順に要件文には，$R_1，R_2，R_3... R_10$のようにラベルを付与する．

\section{実装フェーズ}
実装フェーズは，各要件文を満たすソースコードを大規模言語モデルを用いて生成する．
Jiangらは，分割した要件文に基づき，各要件文を実現するソースコードを並行して生成していた．
その場合，要件文間での断片化が発生し，生成されるソースコードの整合性が崩壊する課題が発生した\cite{TOSEM} ．
本研究は，個々の要件文に加え，要求文を大規模言語モデルに入力し，ソースコードを生成する．
Listing \ref{sample_prompt}は，実装を担当する大規模言語モデルへ与えるプロンプトの一部を抜粋したものである．

\begin{lstlisting}[caption={実装を行う大規模言語モデルへ与えるプロンプト例},label={sample_prompt}]
"Programmer_2": [
"You are Programmer_1 at ChatDev. Focus subtask: {subtask2}.",
"The overall outline of the project is as follows: {overall_task}",
"Strictly follow the current phase’s Output rules.",
"Constraints: single file 'main.py'; STDIN/STDOUT only; stdlib only; no extra logs.",
"Respect any required region markers (e.g., '# [SUBTASK 2 START]' / '# [SUBTASK 2 END]'); do NOT add '__main__' unless asked.",
"Output EXACTLY ONE file in the requested format: start with 'FILENAME: main.py' then a single code block."
]
\end{lstlisting}


ここで要件文$R_1$と要求文に基づいて生成されたソースコード一式をスナップショット1($S_1$)とする．次の要件文$R_2$は，要求文と前の要件文$R_1$で生成したスナップショット1($S_1$)を入力とし，ソースコードを生成する．
ここで生成されたソースコード一式をスナップショット2($S_2$)とする．
このように，本研究では従来研究のような要件文のみでソースコードを生成する場合とは異なり，要求文と前の要件文で生成したスナップショットも入力として用いる．

一方で，段階的に生成されたソースコード(成果物)が大きくなり，大規模言語モデルが参照すべき情報を取りこぼしたり，生成されたソースコードやコンテキストに対して誤った理解を行ってしまう場合がある．
また，段階的生成は直前の成果物への依存が強いため，初期段階で誤った実装や前提の取り違えが発生すると，その誤りが後々まで波及してしまう可能性がある．
それでも誤りが残存し，入出力テストが未通過となる場合には，再計画フェーズとプロセスの反復に移行し，差分行数に基づく要件文統合・再分割により要件文粒度を見直した上で更新後の要件文の集合から実装フェーズを再実行する．
但し，失敗の原因が問題文の前提や制約をはじめとするコンテキストの誤解に起因する場合には，改善しない可能性があり，この点は手法の限界として位置付けられる．

誤ったソースコードが生成された場合には，後に参照されるスナップショット自体が誤りを含むため，誤りが残存し，最終的に入出力テストが未通過になりうる．
この場合，本手法は再計画フェーズへ移行し，差分行数に基づいた要件文統合・再分割によって要件文粒度の見直した上で，更新後の要件文の集合から実装フェーズを再実行し，再度ソースコードを生成する．
但し，失敗の原因が分割粒度や問題文の前提の誤解などに起因する場合には，再分割のみでは改善しない可能性があり，この点は手法上の限界として位置付けられる．


\section{再計画フェーズ}
再計画フェーズでは，スナップショットの追加行数に基づく要件文の統合と，統合した結果を用いた再分割を実施する．

2.2節で示したように，要件文に対する実装量が過度に小さい場合，大規模言語モデルの注意資源や推論能力を必要以上に消費し，意図しない要件文を実装する可能性が存在する\cite{TOSEM}．
本研究では，各要件文に対して生成されたソースコード規模が小さい場合，ソースコード生成後に要件文の分割粒度を再検討し，要件文を統合して再生成する．
その後，要件文$R_i$を実装するステップで新たに作成された行数を，要件文が生成されるソースコードの変更規模として扱い，要件文統合の判断基準として用いる．
具体的には，問題毎の要求文から分割された要件文の総数をn，i番目の要件文$R_i$に基づき生成したソースコードのスナップショット$S_i$において，ソースコードの総行数を$LoC_i$とする．
連続する2つのスナップショット対を$S_{i-1}$から$S_i$までで追加及び修正された行数を $\Delta \mathbf{LoC}_i = \mathrm{LoC}_i − \mathrm{LoC}_{i-1}$ とする．

式 (1) で算出した差分行数$\Delta \mathrm{LoC}_i$が，本研究で決定した閾値を下回ると，要件文$R_i$は直前の要件文$R_{i−1}$と統合する．
なお，本閾値は探索的に採用した仮定であり，妥当性の厳密な検証は今後の課題である．

\begin{equation}
  \Delta \mathrm{LoC}_{i} \le \mathrm{LoC}_{n} / n
\end{equation}

統合後は，統合した要件文の集合を基にソースコードを生成し直すことで，要件文統合が生成結果に与える影響を調査する．
具体的には，統合後の要件文の集合に基づいて，実装フェーズを再実行し，得られた成果物に対して入出力テストを用いて，テスト通過率の変化を調査する．


\section{プロセス反復}

取得した統合後要件文の集合から無作為にサンプルを抽出し，計画フェーズと同様にfew-shot学習の学習例として与える．
これにより，要求文から要件文へ分割する際の粒度や分割方針を，テストを通過した分割例に基づいて更新すると共に，分割粒度を大規模言語モデルが学習しやすいレベルへと変化させることを狙う．
そして，以上の手順を繰り返すことで，要求文から分割・抽出される要件文の粒度最適化を図り，それにより，分割粒度の不適切さに起因する断片化や取りこぼしを軽減しながら，入出力テストの通過率の向上を目指す．



\chapter{評価実験}
\section{データセット}
本研究では，満たすべき要件文が自然言語で明確に記述され，生成したソースコードを検証可能なデータセットとして，競技プログラミングサイトであるAtCoderの問題を対象に評価実験を行う．
AtCoderはAから難易度が低い順に問題の難易度が設定されており，評価実験のためにC・D・E・F問題を各200問の計800問と，few-shot学習の学習用に各難易度で4問ずつを使用する．
難易度の低い問題では要求文の分割により，タスク粒度が過度に小さくなってしまう可能性を考慮して，A問題とB問題は，実験から除外する．

\section{評価手法}
各問題は2件から4件程度の入出力サンプルを備えており，C，D，E，F問題200問に備わっている入出力テストそれぞれ，526件，552件，546件，536件を使用する．
これを評価用テストとして活用し，生成したソースコードの評価に用いる．
また，大規模言語モデルの事前学習に用いられる学習用データの多くは英語が中心であり，他言語と比較して性能の差が挙げられる\cite{LLM_English}．
要件文の理解の一貫性や再現性を担保するために，問題文などの自然言語は全て英語の問題を対象とする．


\section{実験設定}
計画フェーズでは，著者が手動で要求文から要件文を作成し，それらを大規模言語モデルにfew-shot学習させ，AtCoderの問題800問の分割の自動化を行った．
大規模言語モデルへ入力するプロンプトには，要求文と要件文の集合の例以外に，「根幹となる機能ほど順番を前にすること」，「分割コストの観点から分割の上限数を10個に制限すること」の2点を指示した．Jiangらの研究\cite{TOSEM}で，要件文の分割を行う際にfew-shot学習で与える分割例の最適な数は4個から8個であると示している為，本研究では要求文の分割時に各難易度(C問題，D問題，E問題，F問題)毎に各4問ずつの例を提示した．

大規模言語モデルは実行ごとに生成結果にばらつきが生じるため，AtCoderの800問を対象に，分割した要件文を基にソースコード生成を各問題につき3回ずつ実行し，結果の一般化を図った．
生成したソースコードの評価は，問題ごとに提供される入出力サンプルを入出力テストとして扱い，テスト通過率を用いる．
AtCoderの問題の特性上，入出力は標準入力・出力が想定されているため，3.1節で拡張した段階的に開発を行う各大規模言語モデルエージェントに対して，アプリケーションのようなインタフェースは作成しないように命令を追加した．

本研究では要求文の分割やプログラマやソースコードレビュアなどの段階的ソースコード生成において，料金と性能を考慮し，大規模言語モデルとしてGPT-4o-mini\footnote{\url{https://openai.com/ja-JP/index/gpt-4o-mini-advancing-cost-efficient-intelligence/}}を使用した．


\section{Research Questions (RQs)}
\paragraph{RQ1: 計画フェーズ・実装フェーズに基づくソースコード生成は，従来手法と比較して有効であるか？}

大規模言語モデルに対して全体概要を学習することで，生成結果の断片化を抑制し整合性を担保する．
また，few-shot学習による要求文から要件文への分割により，ソースコードを生成できるか否かをテスト通過率により評価する．
RQ1では，要件文の分割を行わない従来のChatDevとの比較だけでなく，対照実験として従来研究\cite{TOSEM}と同様にfew-shot学習のみを行わなかった場合（zero-shot学習による要件文の細分化を実施し，各大規模言語モデルの入力に全体概要を含む）と，全体概要の提示のみを行わなかった場合（few-shot学習による要件文の細分化を実施し，各大規模言語モデルの入力に全体概要を含まない）の結果を比較する．
先行研究\cite{TOSEM}では，段階的開発における整合性の断片化により，全体整合を保った実装が困難であると述べられている．
その為，計画フェーズでのfew-shot学習による要求文分割と実装フェーズでの分割前要求文(全体概要)の共有がテスト通過率の改善に寄与するかを検証する．
一方で，評価がAtCoderに備わった入出力サンプルに依存する為，仕様網羅性に限界がある．

\paragraph{RQ2: 要件文の統合により，テスト通過率に変化は見られるか？}
再計画フェーズで実施した要件文の統合により，テスト通過率が低下した場合，要件文の統合のアプローチ又は，本研究で使用している閾値に問題があることが考えられる．
よって4.2節で述べたスナップショットの差分行数に基づく統合指標に基づき，過小な要件文を統合して生成するソースコードはテスト通過率に影響を与えるか否かを調査した．
統合することによりテスト通過率が低下する場合，統合後の要件文は統合前の要件文より大規模言語モデルにとって適切でないと判断できる．
RQ2では，RQ1と同様に，200問の問題に対して3回の分割とソースコード生成し，統合前のテスト通過率と比較し，評価する．
差分行数は要件文内容と無関係な変更にも影響される為．粒度の代理指標として誤差を含み得る．
また，統合判定の閾値が探索的である点は，結果の不確実性として残る．

\paragraph{RQ3: 要件文の再分割により，分割粒度の再検討が行われるか？}
統合後要件文を分割例として再利用することで，分割された要件文の粒度を更新し，大規模言語モデルが「学習・実装しやすい単位」へ再編されるかを明らかにする．
その為の具体的手法として，要件文数の増減や，1つの要件文に含まれる制約条件や出力形式などの仕様制約，1つあたりのテキスト量について目視で調査を行う．
粒度変化の評価は目視で実施する為，評価者の主観が混入する恐れがある．
また，分割例として用いる分割例は無作為に選択されるため，分割の方針が偏る可能性も考えられる．

\paragraph{RQ4: 要求文の再分割により，テスト通過率は向上するか？}
RQ4では，RQ3で再分割された要件文の集合が生成されるソースコードのテスト通過率に影響するかを確認する為，再分割前後でテスト通過率が向上するかを調査する．
具体的には，手動で作成した要件文に代わり，統合した要件文と分割前の要求文を大規模言語モデルの入力とし，再度few-shot学習による要件文の分割およびソースコード生成を行う．他のRQと同様に，テスト通過率で評価を実施する．

実験では，統合後要件文による生成結果が入出力テストを通過した問題を対象として，統合後要件文と分割前の要求文(全体概要)を大規模言語モデルへの入力として，再度few-shot学習による要求文の分割，及びソースコードを生成する．
この時，ソースコード生成の入力には分割後要件文と分割前要求文(全体概要)を用いて，生成途中のソースコードのみを与える，それ以前に生成したソースコードは入力に含めない．

他のRQと同様にテスト通過率を用いて評価を実施するが，再分割時にfew-shot学習で用いる分割例は固定せず，再分割時には変更されるため，観測される改善が要件文粒度の効果ではなく，分割例の差に起因する可能性がある．
さらに，統合後要件文と分割前要求文(全体概要)の併用により，どの要素が寄与したかが解釈上不明瞭になり得る．

\paragraph{RQ5: プロセスの反復により，テスト通過率に変化は見られるか？}
本研究の提案手法は，計画フェーズ・実装フェーズ・再計画フェーズ並びに，これら3プロセスの反復を行うことで要件文の粒度や構造を更新し，生成されるソースコードのテスト通過率の改善を狙う．
その為，反復回数の増加に伴い，入出力テストの通過率が向上するか，あるいは横ばいであるか劣化が生じるかを調査する．
RQ5では，初回のソースコード生成を基準とし，プロセスの反復を繰り返したテスト通過率を比較することで，反復が与える影響を評価する．

反復は改善だけでなく，誤った前提や不適切な要件文の統合を増幅させる可能性を持つ．
また，改善が頭打ちになる場合には，その要因が粒度ではなく，問題文のコンテキストの誤解等に起因する恐れある．




\chapter{結果}
\section{RQ1: 計画フェーズ・実装フェーズに基づくソースコード生成は，従来手法と比較して有効であるか？}
図\ref{RQ1}に，800問を対象に提案手法によって各3回ソースコード生成した結果のテスト通過率を示す．
横軸には全てのテストを基にしたテスト通過率を，縦軸には生成手法ごとに示す．

\begin{figure}[tb]
    \centering
    \includegraphics[width=0.7\linewidth]{./Toyoshima_fig/RQ1.pdf}
    \caption{few-shot 学習，全体概要の有無，統合によるテスト通過率比較}
    \label{RQ1}
\end{figure}

実験の結果，few-shot学習による要件文の細分化を実施し，各大規模言語モデルの入力に要求文(全体概要)を含む場合に，テスト通過率が最も高い42.86\%となった．zero-shotの場合は，テストで失敗したケースにおいても入出力でエラーが発生したケースは少なく，入出力のフォーマット部分は概ね正しく実装されているが，出力不一致などによる失敗が多く見られた．
これは要求文の学習で，関数の呼び出しやデータの入出力構造などをはじめとする全体の整合性が保たれる一方で，局所的推論の部分でテスト失敗となっていた．
これに対し，要求文の学習を行わず，few-shot学習のみの場合では，タイムアウトや関数呼び出しなど，実行時の構造的不整合に起因するエラーが相対的に多くみられた．
これは，局所的な構造自体は与えられているが，全体像が欠如していることによる開発の断片化により発生したものであると考えられる．


\section{RQ2: 要件文の統合により，テスト通過率に変化は見られるか？}
図\ref{RQ2_1}には，データセットに含まれるAtCoderの問題200問に備わった入出力テスト全体のテスト通過率を示す．
図の横軸には入出力テストの通過率，図の縦軸には各手法を示す．
縦軸は具体的には，要件文の分割を行わない従来手法，要件文統合を行う前(few-shot学習による要求文分割と要求文提示を行った場合)，要件文を閾値に沿って統合した後，の3つに分類を行った．
要件文の統合前ではテスト通過率が42.86\%であるのに対して，統合後には43.38\%とおおよそ横ばいの結果が確認された．

\begin{figure}[tb]
    \centering
    \includegraphics[width=0.7\linewidth]{./Toyoshima_fig/RQ2_1.pdf}
    \caption{RQ2: 全テストでのテスト通過率}
    \label{RQ2_1}
\end{figure}

また，図\ref{RQ2_2}にはデータセットの問題800問(C問題200問，D問題200問，E問題200問，F問題200問)において，各3回ずつソースコードを生成し，それに対するテスト通過数の分布を示す．
図の横軸にはテストを通過した問題数を，図の縦軸にはテストの通過可否を示す．
縦軸は具体的には，3回とも統合前後の両方でテストを通過した場合，3回とも統合前後の両方でテストを通過しなかった場合，統合前ではテストを通過せず統合後にテストを通過が1回以上通過するようになった場合，そしてそれ以外の場合で分類を行った．
なお，「テストを通過する」とは，問題に備わった入出力テストを全て通過したケースを指し，1つでもテストを通過しない入出力テストが存在する場合には，未通過として分類する．
その結果，全800問のうち716問が統合前後で入出力テストの結果に変化が発生しなかったことから，テスト通過率の顕著な変化は確認されなかった．

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{./Toyoshima_fig/RQ2_2.pdf}
    \caption{RQ2: 問題単位でのテスト通過数}
    \label{RQ2_2}
\end{figure}

\section{RQ3: 要件文の再分割により，分割粒度の再検討が行われるか？}
RQ2において，要件文を統合した場合においても，統合前後でテストを通過する問題数に明示的な差は確認されなかった為，RQ3では，再計画フェーズで生成された再分割後の要件文を目視で確認し，再分割が単なる表現の言い換えに留まらず，要件文の粒度を更新しているかをケーススタディ的に調査した．
few-shotで提示する分割例は，要件文の統合を行った際に入出力テストを通過したケースを無作為に各難易度ごとに4問ずつ(C問題4問，D問題4問，E問題4問，F問題4問)を取得し，データセット800問から，これら16問を除いた784問で要件文の統合を行った．

目視の結果，再分割後では，要件文の分割粒度が変化していることを確認した．
具体的には，再分割前（統合後）では，入力，操作の適用，合計，出力といった粗い単位で要件文がまとめられていたのに対し，再分割後では，入出力に関する処理と，要求文を満たすための機能の部分を明示した上で，データ構造，並べ替え，集計，出力といった各工程が独立した要件文として分割されていた．
また，計算量や整数型といった実装上の制約が要件文として明示され，実装時の解釈の揺れを抑える方向に再編されていることも確認できた．

なお，再分割前後の要件文は，付録\ref{req_before_split}及び付録\ref{req_after_split}に，生成されたソースコード例は\ref{code_before_split}及び付録\ref{code_after_split}掲載する．

以上により，再分割は要件文1つあたりの粒度を更新すると同時に，工程間の境界やコンテキストから読み出されるような暗黙の制約などを顕在化させることで，要件文の分割粒度を更新し得ることが示された．
このような粒度の更新は，後続の実装フェーズによる誤った実装の発生確率を低減し，生成されるソースコードの整合性向上に寄与する可能性がある．


\section{RQ4: 要求文の再分割により，テスト通過率は向上するか？}
RQ3で実施した統合後の要件文から要求文を再分割した要件文の集合を基に784問の問題からソースコードの生成を行い，その入出力テストを実施し，そのテスト通過の可否の結果を示す．

図\ref{RQ4_1}に，対象の784問のデータセットに備わった入出力テスト全体に対するテスト通過率を示す．
再分割前では43.38\%であったのに対して，再分割後は57.59\%とおよそ14\%のテスト通過率の向上が確認された．

\begin{figure}[tb]
    \centering
    \includegraphics[width=0.7\linewidth]{./Toyoshima_fig/RQ4_1.pdf}
    \caption{RQ4: 統合前・再分割前（統合後）・再分割後における全テスト通過率の比較}
    \label{RQ4_1}
\end{figure}


図\ref{RQ4_2}に，対象784問から各3回ずつソースコードを生成した際のテスト通過数の分布を示す．
図の横軸にはテストを通過した問題数を，図の縦軸にはテストの通過可否を示す．
具体的には，3回全てで再分割前後の両方でテストを通過した場合，3回全てで再分割によりテストを通過するようになった場合，3回のうち1回以上でテストを通過するようになった場合，そしてその他の4つに分類した．

その結果，3回全てで再分割によりテストを通過するようになったケースがC問題で57問，D問題で76問，E問題で23問，F問題で16問となっており，合計で784問のうち約22\%を占める結果となった．

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{./Toyoshima_fig/RQ4_2.pdf}
    \caption{RQ4: 再分割によるテスト通過状況の内訳（難易度別・問題単位）}
    \label{RQ4_2}
\end{figure}


\begin{figure}[b]
    \centering
    \includegraphics[width=0.7\linewidth]{./Toyoshima_fig/RQ5.pdf}
    \caption{RQ5: 反復回数に伴う完全通過問題数の推移（難易度別）}
    \label{RQ5}\end{figure}

\section{RQ5: プロセスの反復により，テスト通過率に変化は見られるか？}
RQ1からRQ4までで計画フェーズ・実装フェーズ・再計画フェーズ並びに要件文粒度の再検討が，生成されるソースコードのテスト通過率の向上に寄与し得ることが示唆される．
このことから，要件文粒度を再検討する反復プロセスを繰り返し行っていくことで更なるテスト通過率の向上の可能性を調査する．

具体的には，これまでのRQと同様にテスト通過数の変遷についてや，再計画フェーズ時の要件文数の変化について調査する．

図\ref{RQ5}に3回ずつソースコードを生成した際に3回すべてテストを通過した問題テスト通過数の変遷の結果を示す．




要件文粒度の再検討を繰り返した場合において，全ての難易度の問題において，反復回数とテストを通過する問題数における顕著な変化は確認されなかった．


\chapter{考察}
% \section{テスト通過率向上の要因分析}
本章では，第5章の結果を踏まえ，提案手法がテスト通過率の向上に寄与した要因を考察する．
本研究の結果から，計画フェーズにおけるfew-ashot学習による要求文分割と，実装フェーズにおける分割前要求文(全体概要)を併用した場合に，従来手法や片方のみを導入した場合と比較して高い通過率が得られることが確認された．
さらに，差分行数に基づく要件文統合は通過率を大きく悪化させず，統合後要件文を分割例として用いた再分割ではテスト通過率を向上させうることが示された．
一方で，反復を重ねても通過数に顕著な改善が見られないケースも確認された．

以下では，統合・再分割の前後でテストの結果が一貫したケースを対象に，要件文の区切り方と実装の対応関係に着目して考察を行う．
次に，再分割を実施することによりテストが通過するように転じたケースを対象に，要件文に含まれる意図の明治度の観点から考察する．
その後，反復による要件文粒度変化と改善が頭打ちになるケースについて議論する．


\section{統合前・統合後・再分割後の全てでテストを全て通過するケース}
統合前・統合後・再分割後のいずれにおいてもテストを通過したケースでは，生成されたソースコードの主要機能は一貫して満たされているため，差異は主に「要件文の区切られ方」に確認される．
統合前の要件文の集合は，変数・関数の宣言，値の代入，単一の条件分岐といった「作業単位」の細かい粒度で列挙する傾向が見られた．
この場合，ここの要件文は局所的に明示されている一方で，要件文間で前提や状態，データ構造の共有が複数回において必要となり，実装時に影響を及ぼす可能性が考えられる．
しかし，問題構造が比較的単純であったり，要件文間の依存関係が薄い場合においては，細かな粒度でも破綻が発生せずに通過し得る．

一方で，再分割後の要件文の集合では，宣言から初期化，関数呼び出しまでのように，意味的に連続した処理が1つの要件文として束ねられる傾向が確認された．
このような区切り方は実装時に参照すべき文脈をまとまりとして保持しやすく，整合性を持ったソースコードを生成しやすい．
即ち，機能を維持し，一貫性を保った状態で生成可能な最小単位へと要件文が再編成されたことが，全ての状態においてテストを通過したケースであることが考えられる．

また本研究の実装フェーズでは，各ステップでの分割前要求文(全体概要)と直前までの成果物を参照する．この設計により，要件文の粒度が細かな場合においても全体としての入出力形式や主要データの流れが参照可能となり，変数名・関数名の揺らぎやインタフェースの不整合を抑制可能となる．そのため，統合前後で要件文1つあたりの粒度が違っている場合でも，テストが通過した可能性が考えられる．


\section{再分割により改善が見られたケース}
再分割によって未通過から通過へ転じたケースでは，大きくく分けて「再分割前の要件文に意図が十分に明示されているか」と「要件文に沿ったソースコードが生成されているか」の2点に分けて考察を行う．

\subsection{再分割前の要件文に意図が明示されているか}
統合前・統合後の段階では，要件文が過度に細かい場合に大規模言語モデルは要件文間の接続を推測しながら実装を進める必要がある．
この時，変数に格納された値の更新手順や，分岐条件，境界値の扱い，例外処理などといった細やかな意図が要件文の集合の中に分散する．
その結果，各要件文を局所的に満たした場合においても，他の要件文の理解が不十分となることに起因する解釈の揺らぎが発生してしまう．
この揺らぎは入出力テストにおいて出力不一致や，条件分岐の漏れとして顕在化し，未通過の要因となり得る．

一方，再分割の過程では統合後要件文を分割例として参照することで，要件文1つあたりの粒度が問題の構造に合わせて再編成される．
その結果，宣言から更新，分岐，出力までのように，意味的に連続した処理が同一の要件文内にまとまりやすくなり，要件文間にまたがっていた工程上の繋ぎ目が減少したことが確認された．
また，要件文粒度の向上により，各要件文1つあたりに記述できる情報量の余地が発生し，これまで反映しきれていなかった意図を要件文内で提示することが可能となった．
実際に改善が見られた事例では，細かな値の更新や分岐制御，境界値の扱い，入出力形式，例外時処理の扱いなどが要件文内に含まれるようになったことが確認された．
このような意図の明示化により，前提や出力の揺らぎが抑制され，意図が一貫して実装に反映されるようになった可能性がある．


\subsection{要件文に沿ったソースコードが生成されているか}
再分割前に意図が部分的に記述されていた場合においても，要件文粒度が細かく分散している場合では，大規模言語モデルが要件文間の依存関係や変数の意味やデータ構造などの前提を正しく理解できない場合がある．
本研究の実装フェーズでは，分割後の要件文と同時に分割前の要求文を提示し，全体の前提条件を参照しながらソースコードを生成する工夫を実施しているが，要求文を明記した場合においても前提条件が要件文のどの箇所にどのように適応されるべきかのコンテキストを大規模言語モデルが十分に読み取ることができない場合があり，その結果として要求文を満たすソースコードを生成できないケースが発生している．

これに対し，再分割後は要件文が意味的まとまりとして提示され，各要件文内で入出力条件や，格納した値の更新，分岐などがまとまって記述される傾向が確認された．
その結果，1つあたりの要件文粒度が大きくなり，先行研究でも提示された大規模言語モデルが学習しやすい粒度へと変化し，コンテキストや前提条件の理解不足が抑制され，要件文に沿ったソースコードが生成されるようになったことが考えられる．


\section{プロセスの反復によるテスト通過の可否}
本節では再分割によって得られた「テストを通過した要件文の集合」を分割例として再利用し，計画・実装・再計画の3フェーズの反復がテスト通過率に与える影響について議論する．


先の節で示した通り，反復回数の増加に伴う通過数の一貫した増加は確認できず，特に高難易度問題においては未解決となった問題が多く残った．
反復による改善が頭打ちとなった要因として，要件文の区切られ方や粒度の調整ではなく，問題文の前提や制約の取り違えによるコンテキストの誤解が考えられる．

実際にプロセスの反復を実施した中で，テストが継続して通過しなかったケースを目視で確認したところ，境界条件や偶奇処理の誤解，配列インデックスの取り違えや，処理の順序誤りなどといった実装誤りが複数確認された．
その一部例を付録\ref{mistake_code}で示す．
加えて，処理に無関係な関数の定義などの過剰実装が行われ，重要な処理の検討が相対的に不十分となる例も観察された．

以上のことは，問題文の前提・制約をはじめとするコンテキストの誤解が，生成されるソースコード全体に波及し得ることを示している．
大規模言語モデルの出力は生成ごとに変動し得るものの，単に反復回数を増加させただけでは同一の誤解に基づく誤りが再生産される可能性がある．
従って，反復の効果を安定して得るためにはテスト失敗や，生成されるソースコードの差分などといった観測可能な情報を手がかりに，コンテキストの誤解の原因を特定し，修正するための明示的なアプローチが必要である．

これらは，データセットとして使用するAtCoderの問題が競技プログラミング用の問題であるため，状況説明などをはじめとするストーリー性を問題文が包含していることから，暗黙の制約や規則を読み取る必要がある，という性質が一因であることが考えられる．
即ち，反復プロセスが「要件文粒度の最適化」であるのに対しては有効に働く一方で，問題そのものの誤解に起因する失敗が原因となる場合には，反復だけでは継続的な改善が困難であることが考えられる．

以上により，反復によるテスト通過率向上を安定して得るには，要件文再分割の前段階として，問題文から制約条件，例外処理，入出力フォーマットなどを明示的に構造化して抽出し，大規模言語モデルが誤解しにくい形式へ変換する処理の導入が求められることが考えられる．


\chapter{妥当性の脅威}
本章では，本研究における結果の信頼性に影響を及ぼす可能性のある要因を，内的妥当性および外的妥当性の観点から述べる．

\section{内的妥当性}
本研究では，生成したソースコードの正しさを入出力テストの通過可否を用いて評価する．
しかし，競技プログラミングであるAtCoderが公開する入出力サンプルは，仕様全体を網羅するテストの集合ではないため，テストを通過しても未検出の欠陥を見逃してしまう可能性がある．
その結果，提案手法間の差が，要求文よりも，公開されたサンプルに過度に適応してしまう恐れがある．
この脅威を低減するためには，要件文ごとの入出力テストが備わったデータセットを基に実験を再度行うなどが望まれる．

また，本研究では要件文統合の際に，ソースコードのスナップショット間の差分行数を用いる．
しかし，差分行数はコメントや空白の調整，軽微な変更などといった要件文に直接対応しないような変更からも影響を受けるため，要件文の重要度や粒度を必ずしも正確に反映するものではない．
その結果，統合の閾値や差分の抽出方法により，統合対象となる要件文や再分割の入力が変化し，通過率の差として観測される恐れがある．
この脅威を低減するには，差分行数のみに依存せず，変更箇所の種類を区別する指標や，要件文との対応付けに基づく統合基準を併用することが望ましい．

そして，本研究には大規模言語モデルを使用しており，その特徴として「同一入力に対しても生成結果が変動し得る」という点が挙げられる．
本研究では各問題につき複数回実行することでその大規模言語モデル特有の「揺らぎ」を低減している一方で，モデルの更新や実行環境の差により再現性が損なわれる可能性がある．
この脅威を低減するためには，要件文ごとの入出力テストが備わったデータセットを基に実験を再度行うなどが望まれる．
加えて，近年は大規模言語モデルを用いて特定の条件分岐や境界条件の検査を目的としたテストを生成し，テストを拡張する試みが行われている\cite{Expand_Test}．
本研究では公開サンプルのみにより通過判定を行うが，将来的にはこの種の手法を併用して追加のテスト入力を生成し，再評価することで未検出欠陥の見逃しやサンプルへの過剰な適応の脅威を低減できる．

\section{外的妥当性}
本研究の評価対象は競技プログラミングサイトのAtCoderの問題であり，標準入力・出力によってテストが判定される形式である．
この形式では，入出力仕様や制約が比較的明確である一方で，実システムの開発で扱う非機能要件文や外部APIの使用，運用制約などは含まれにくい．
そのため，本研究で得られた有効性が実務的な開発業務へ同程度に一般化可能であるかは未知数であるため，今後はSWE-bench\cite{SWE_bench}のような実リポジトリ上のIssueの解決を対象としたファイル編集・ビルド・テストを含む開発プロセスを評価可能なベンチマークへデータセットを拡張する必要がある．

また，実験は単一ファイル・標準入出力を前提としたソースコード生成であり，複数モジュール構成や依存関係管理，統合時のインタフェース整合性など，実システムで重要となる要素を十分に反映できていない．
よって，本研究で確認されたソースコードの品質向上の効果が，複数ファイル構成の開発で同様に得られるかについても未検証である．

本研究では，要求文理解の一貫性や，大規模言語モデルの学習データ量をベースに英語の問題文を対象としている．
そのため，日本語要求文や箇条書き形式の仕様書などの要求文形式が異なる場合に提案手法が同様に機能するかは不明であり，言語・形式の違いに対する一般化は今後の検証が必要となる．


\chapter{おわりに}
本研究では，大規模言語モデル(LLM)を用いたマルチエージェント型ソースコード生成において，複数の要件文同士が相互に依存する要求文に対して，要求文の取りこぼしや生成結果の断片化により，要求文を満たすソースコードの生成が困難になる問題に着目した．
この問題に対して，本研究では要求文の分割と段階的実装を用いた反復的なソースコード生成プロセスを提案した．
提案手法では，計画フェーズでは大規模言語モデルを用いたfew-shot学習を用いて要求文から要件文の集合へと分割し，実装フェーズでは分割された要件文に基づいて段階的に実装を進め，再計画フェーズではスナップショット間の差分行数に基づく要件文統合を実施した．
さらに，これら3プロセスの反復による要件文粒度の再検討を実施した．

評価では，競技プログラミングサイトであるAtCoder \footnote{\url{https://atcoder.jp/}}の問題文を要求文として扱い，標準入出力を用いた入出力テストの通過可否を指標として提案プロセスの有効性を調査した．
その結果，従来の要件文分割を伴わない生成と比較して，実装フェーズで分割前要求文(全体概要)を提示した場合では，入出力テストの通過率が42.86\%となり，分割を伴わない従来手法(9.30\%)と比較して，およそ35ポイントの改善が確認された．

再計画フェーズにおける要件文統合では，統合前で42.86\%となり，要件文を統合した後は43.48\%とほぼ横ばいであり，データセット800問の内716問で統合前後のテスト結果に変化が生じなかったことから，統合によるテスト通過率の顕著な劣化は観測されなかった．
さらに，統合後要件文を分割例として再度要求文を分割した場合には，データセット784問の内，43.38\%から，57.59\%がテストを通過するようになり，およそ15ポイントの改善が見られた．

一方で，段階的実装により局所的な要件文実装を進めやすくなる一方で，要件文間のコンテキストや依存関係の誤解が発生すると，要求文に沿わない誤ったソースコードが生成されることも確認した．
加えて，プロセスの反復によるテスト通過の可否については，2度目以降の反復においては改善が頭打ちになることも示されている．

そして，本研究の手法には課題も残る．
差分行数に基づく統合は，要件文の重要度そのものを直接表すものではなく，軽微な変更の影響も受ける．
また，複雑な依存関係やコンテキストを含む要求文では，大規模言語モデルが要求文のコンテキストを十分に理解できず，部分的な実装の整合性が崩壊する場合がある．
これらは，本研究の妥当性に関係する重要な論点である．

今後の課題として，要件文統合の判断基準として，テスト失敗となる原因などの観点の導入や，実際の開発環境で利用される仕様書や要求文を用いた開発とその評価指標の確立などが挙げられる．

以上により本研究は，要件文分割と段階的実装をベースとし，再計画による要件文の粒度調節を組み込んだ反復プロセスを提示し，大規模言語モデルによるマルチエージェント型ソースコード生成における断片化やコンテキスト理解の失敗に対して，一定の改善が確認された．
今後，統合・再分割の指標の強化や，依存関係の明確化によって，より複雑な要求文に対しても一貫したソースコード生成の可能性を模索する．


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%
% 謝辞
%
\begin{acknowledgements}
本研究を進めるにあたって，多くの方々にご指導，ご協力，ご支援を賜りました．
ここにお世話になった方々への感謝の意を記させていただきます．

はじめに，指導教員である和歌山大学システム工学部伊原彰紀准教授に対し，厚く御礼申し上げます．
研究室配属以来，研究の方針や，論文の執筆，発表資料制作などにおいて多くの時間を割いてご指導をいただきました．
また，対外発表の機会も設けていただいたことで，研究の面白さややりがいを知ることができたと共に，多くの研究者と交流することで自信の研究に対する知見を深めることができました．
先生の御尽力に敬意を表し，心より深く感謝いたします．

次に，和歌山大学システム工学研究科の川\UTF{FA11}晴斗氏，野口朋弥氏並びに，和歌山大学システム工学部田井聖凪氏に対し，暑く御礼を申し上げます．
研究に関して，ご協力，ご助言をいただくと共に，精神面での支えになりました．

また，和歌山大学ソーシャルソフトウェア工学研究室の方々には，普段から多大な御協力，御助言をいただきました．特に，ソーシャルソフトウェア工学研究室の同期には，研究のことだけでなく大学生活でも大変お世話になりました．おかげで充実した研究室生活，大学生活を送ることができました．心より感謝いたします．

最後に，日頃から暖かく見守っていただきました家族に対し，心より深く感謝いたします．

\end{acknowledgements}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% 参考文献
%%
\bibliographystyle{junsrt}
\bibliography{@Bachelor2025_Toyoshima/references}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
% 付録
%%
\appendix

% =========================
% Appendix numbering fix
% =========================
\setcounter{section}{0}
\setcounter{subsection}{0}
\renewcommand{\thesection}{A.\arabic{section}}
\renewcommand{\thesubsection}{\thesection.\arabic{subsection}}

\section{再分割前（統合後）要件文例}
\label{req_before_split}
\begin{description}
  \item[\texttt{要件文1}]\par\noindent
\begin{Verbatim}[breaklines=true,breakanywhere=true]
Read integers N and M from standard input, followed by an array A of length N representing the integers on the cards.
\end{Verbatim}

  \item[\texttt{要件文2}]\par\noindent
\begin{Verbatim}[breaklines=true,breakanywhere=true]
Read M pairs of integers (B_j, C_j) from standard input, where B_j is the maximum number of cards that can be replaced and C_j is the value to replace with.
\end{Verbatim}

  \item[\texttt{要件文3}]\par\noindent
\begin{Verbatim}[breaklines=true,breakanywhere=true]
Sort the operations based on C_j in descending order to prioritize higher replacement values.
\end{Verbatim}

  \item[\texttt{要件文4}]\par\noindent
\begin{Verbatim}[breaklines=true,breakanywhere=true]
Initialize a max-heap (or priority queue) to efficiently manage the smallest values in array A.
\end{Verbatim}

  \item[\texttt{要件文5}]\par\noindent
\begin{Verbatim}[breaklines=true,breakanywhere=true]
For each operation (B_j, C_j):
  - If B_j is greater than 0, replace up to B_j smallest values in A with C_j using the max-heap.
\end{Verbatim}

  \item[\texttt{要件文6}]\par\noindent
\begin{Verbatim}[breaklines=true,breakanywhere=true]
After processing all operations, compute the sum of the modified array A.
\end{Verbatim}

  \item[\texttt{要件文7}]\par\noindent
\begin{Verbatim}[breaklines=true,breakanywhere=true]
Print the maximum possible sum of the integers written on the N cards after all operations.
\end{Verbatim}
\end{description}


\section{再分割後要件文例}
\label{req_after_split}
\begin{description}[style=nextline]
  \item[\texttt{要件文1}]\par\noindent
\begin{Verbatim}[breaklines=true,breakanywhere=true,xleftmargin=\leftmargin]
Input: - Read integers N and M. - Read list A of length N: A[0..N-1]. - For j in 1..M, read integers B_j and C_j and store as tuples in a list offers = [(B_1, C_1), ..., (B_M, C_M)]. - Handle with a function solve() that reads stdin, then passes arguments to compute_max_sum(A, offers, N).
\end{Verbatim}

  \item[\texttt{要件文2}]\par\noindent
\begin{Verbatim}[breaklines=true,breakanywhere=true,xleftmargin=\leftmargin]
Define the core function compute_max_sum(A: List[int], offers: List[Tuple[int, int]], N: int) -> int that returns the maximum possible sum after all operations.
\end{Verbatim}

  \item[\texttt{要件文3}]\par\noindent
\begin{Verbatim}[breaklines=true,breakanywhere=true,xleftmargin=\leftmargin]
Build the candidate multiset in compressed form: - Initialize a list candidates: List[Tuple[int, int]]. - For each a in A, append (a, 1) to candidates. - For each (B_j, C_j) in offers, append (C_j, B_j) to candidates.
\end{Verbatim}

  \item[\texttt{要件文4}]\par\noindent
\begin{Verbatim}[breaklines=true,breakanywhere=true,xleftmargin=\leftmargin]
Sort by value descending: - Sort candidates with key on value, descending: candidates.sort(key=lambda x: x[0], reverse=True).
\end{Verbatim}

  \item[\texttt{要件文5}]\par\noindent
\begin{Verbatim}[breaklines=true,breakanywhere=true,xleftmargin=\leftmargin]
Take the top N values without expanding counts: - Initialize remain = N and total_sum = 0 (use 64-bit integer). - For (value, count) in candidates in order: - take = min(count, remain). - total_sum += value * take. - remain -= take. - If remain == 0: break.
\end{Verbatim}

  \item[\texttt{要件文6}]\par\noindent
\begin{Verbatim}[breaklines=true,breakanywhere=true]
Return the result: - compute_max_sum returns total_sum to the caller.
\end{Verbatim}

  \item[\texttt{要件文7}]\par\noindent
\begin{Verbatim}[breaklines=true,breakanywhere=true]
Wire up solve(): - After parsing input in solve(), call ans = compute_max_sum(A, offers, N). - Print ans.
\end{Verbatim}

  \item[\texttt{要件文8}]\par\noindent
\begin{Verbatim}[breaklines=true,breakanywhere=true]
Complexity and types (implementation constraint): - Ensure O((N + M) log(N + M)) time due to sorting, and O(N + M) memory. - Use 64-bit integers for sums (e.g., Python int, or long long in C++).
\end{Verbatim}

  \item[\texttt{要件文9}]\par\noindent
\begin{Verbatim}[breaklines=true,breakanywhere=true]
Function and variable names to use: - Functions: solve(), compute_max_sum(A, offers, N). - Variables: N, M, A, offers, candidates, total_sum, remain, value, count, take.
\end{Verbatim}

  \item[\texttt{要件文10}]\par\noindent
\begin{Verbatim}[breaklines=true,breakanywhere=true]
Output format: - Print a single integer (the maximum possible sum) followed by a newline to standard output.
\end{Verbatim}
\end{description}


\section{再分割前(統合後)要件文から生成されたソースコード例}
\label{code_before_split}
\begin{Verbatim}[breaklines=true,breakanywhere=true]
def solve():
    import sys
    input = sys.stdin.read
    data = input().split()

    N = int(data[0])
    M = int(data[1])
    A = list(map(int, data[2:2 + N]))

    offers = []
    index = 2 + N
    for j in range(M):
        B_j = int(data[index])
        C_j = int(data[index + 1])
        offers.append((B_j, C_j))
        index += 2

    ans = compute_max_sum(A, offers, N)
    print(ans)

def compute_max_sum(A, offers, N):
    candidates = []

    for a in A:
        candidates.append((a, 1))

    for B_j, C_j in offers:
        candidates.append((C_j, B_j))

    candidates.sort(key=lambda x: x[0], reverse=True)

    remain = N
    total_sum = 0

    for value, count in candidates:
        take = min(count, remain)
        total_sum += value * take
        remain -= take
        if remain == 0:
            break

    return total_sum

if __name__ == "__main__":
    solve()
\end{Verbatim}



\section{再分割後要件文から生成されたソースコード例}
\label{code_after_split}
\begin{Verbatim}[breaklines=true,breakanywhere=true]
from typing import List, Tuple

def maximize_sum(N: int, A: List[int], offers: List[Tuple[int, int]]) -> int:
    sorted_A = sorted(A)
    offers_sorted = sorted(offers, key=lambda x: x[0], reverse=True)

    idx = 0
    for c, b in offers_sorted:
        while idx < N and b > 0 and sorted_A[idx] < c:
            sorted_A[idx] = c
            idx += 1
            b -= 1
            if idx == N:
                break

    total_sum = sum(sorted_A)
    return total_sum

def main():
    import sys
    input = sys.stdin.read
    data = input().splitlines()

    N, M = map(int, data[0].split())
    A = list(map(int, data[1].split()))
    offers = [tuple(map(int, line.split())) for line in data[2:M+2]]

    ans = maximize_sum(N, A, offers)
    print(ans)

if __name__ == "__main__":
    main()
\end{Verbatim}

\section{コンテキストの誤解により生成された誤ったソースコード例}
\label{mistake_code}
\begin{Verbatim}[breaklines=true,breakanywhere=true]
def main():
    import sys
    from collections import deque

    input = sys.stdin.read
    data = input().split()
    
    N = int(data[0])
    edges_input = [(int(data[i]), int(data[i + 1])) for i in range(1, len(data), 2)]

    def solve(N, edges_input):
        def build_adj(N, edges_input):
            graph = [[] for _ in range(N + 1)]
            deg = [0] * (N + 1)
            for eid, (a, b) in enumerate(edges_input):
                graph[a].append((b, eid))
                graph[b].append((a, eid))
                deg[a] += 1
                deg[b] += 1
            return graph, deg

        graph, deg = build_adj(N, edges_input)
        K = max(deg)

        def color_tree_bfs(N, graph, K, root=1):
            edge_color = [-1] * (N - 1)
            visited = [False] * (N + 1)
            parent_color = [0] * (N + 1)
            queue = deque([root])
            visited[root] = True

            while queue:
                u = queue.popleft()
                c = 1
                for v, eid in graph[u]:
                    if visited[v]:
                        continue
                    if c == parent_color[u]:
                        c += 1
                    edge_color[eid] = c
                    parent_color[v] = c
                    visited[v] = True
                    queue.append(v)
                    c += 1

            return edge_color

        edge_color = color_tree_bfs(N, graph, K, root=1)

        print(K)
        for eid in range(N - 1):
            print(edge_color[eid])

    solve(N, edges_input)

if __name__ == "__main__":
    main()
\end{Verbatim}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
