%
% 卒論レジュメフォーマット Ver.2.0 pLaTeX版
%
\documentclass[twocolumn]{jarticle} % 2段組のスタイルを用いている

\usepackage{wuse_resume}
\usepackage{url}	% \url{}コマンド用．URLを表示する際に便利
\usepackage[dvipdfmx]{graphicx}  % ←graphicx.styを用いてEPSを取り込む場合有効にする
			% 他のパッケージ・スタイルを使う場合には適宜追加

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% タイトル，学生番号，氏名などを設定する
%%

\タイトル{反復的要求文分割に基づくマルチエージェント段階的ソースコード生成}
\研究室{ソーシャルソフトウェア工学}
\学生番号{60276157}
\氏名{豊嶋 浩基}

\概要{%
この文章は，和歌山大学システム工学部システム工学科社会情報学メジャーの卒業研究発表会に
おいて配布されるレジュメをp\LaTeX を用いて作成するための方法を記述したものである．
この文章もまた，統一されたレジュメの体裁に沿って作成されており，レジュメ作成の際の参考にされたい．
}

\キーワード{大規模言語モデル}
\キーワード{ソースコード自動生成}
\キーワード{マルチエージェント開発}
\キーワード{要求文分割}
\キーワード{few-shot学習}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% 以下の3行は変更しない

\begin{document}
\maketitle
\thispagestyle{empty} % タイトルを出力したページにもページ番号を付けない

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% 本文 - ここから
%%

\section{はじめに}
大規模言語モデル（LLM）を用いたソースコード生成は，コードレビュー支援やテスト生成など，多様な開発支援に適用が進んでいる．
一方で，要求が複数の要件や制約を同時に含み，それらが相互に依存する場合，LLMは必要な条件の取りこぼしや，部分実装同士の不整合（断片化）を起こしやすい．
特に，要求文の前提（データ構造の意味，境界条件，制約の整合性）を一貫して保持できないと，局所的には正しそうに見える実装でも，全体としてテストを通過しない事例が増える．

本研究では，マルチエージェント型開発(ChatDev)\cite{ChatDev}を前提に，(1) few-shot学習による要求文の要件分割，(2) 全体概要を共有した段階的実装，(3) 分割粒度の再検討（統合・再分割），を組み合わせ，これらのプロセスを反復することでテスト通過率の向上を目指す．
従来研究\cite{TOSEM}で議論される計画・実装の枠組みに加えて，実装途中の差分情報を利用して分割の失敗を検出し，次の分割へ反映する点に特徴がある．

\section{提案手法}
本研究の提案プロセスは従来研究\cite{TOSEM}に基づく3フェーズ（計画・実装・再計画）で構成され，これらのフェーズの反復を実施する．
図\ref{approach_abst}に全体概要を示す．本プロセスの狙いは，(i) 要件の取りこぼしを抑えること，(ii) 実装の断片化を抑え，全体整合を保つこと，(iii) 不適切な分割粒度を後段の情報から修正すること，の3点である．

\subsection{計画フェーズ}
few-shot学習\cite{LLM_few_shot}を用いて，要求文を実装すべき要件文の集合へ分割する．
ここでの要件文は「何を満たすべきか」を短い単位で列挙したものであり，後続の実装フェーズにおける作業単位となる．
分割粒度が不適切であると，(1) 重要な前提が分散して依存関係が見えにくくなる，(2) 各要件が小さすぎてLLMが文脈を再構成できない，(3) 逆に大きすぎて実装が一度に破綻する，といった問題が生じ，最終的に要求文を満たさないソースコードが生成されやすくなる．

\subsection{実装フェーズ}
計画フェーズで得られた要件文に基づいて段階的に実装を進める．
このとき，各要件文だけでなく分割前の要求文（全体概要）を前提条件として提示し，さらにそれまでに生成されたソースコード（既存の実装）を参照しながら実装を行う．
これにより，要件単位で作業を進めつつも，要求文全体に含まれる制約やデータの意味を失わずに実装できる状態を維持することを狙う．
ただし，要件間の依存（例：同じ配列・変数の意味の共有，処理順序の整合）を誤ると，局所的な追加実装が全体仕様と衝突し，テスト不通過に繋がるため，後述の再計画フェーズで粒度や依存の見直しを行う．


\subsection{再計画フェーズ}
実装フェーズでは，分割された要件文から段階的にソースコードが生成される．
この時，生成途中のソースコードをスナップショットと定義し，それらの差分行数に基づき，実装量が過小な要件文同士を統合する．
これにより，要件1つあたりの粒度を大規模言語モデルが学習を行い易い粒度へと変化させることが目的である．

\subsection{プロセス反復}
これら3つのフェーズで構成されたプロセスを反復することで，生成されるソースコードの入出力テストの通過率を向上させることを目指す．
具体的には，再計画フェーズに基づいた要件文の集合をfew-shot学習の分割例として提示し，再度要求文の分割を実施する．
そして，分割された要件文の集合に基づくソースコードの生成，要件粒度の再検討を実施する．

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{./Toyoshima_fig/approach_abst.pdf}
    \caption{アプローチ概要図}
    \label{approach_abst}
\end{figure}

\section{評価実験}
\subsection{データセットと評価指標}
競技プログラミングサイトであるAtCoder\footnote{\url{https://atcoder.jp/}}の問題文を要求文として扱い，標準入出力形式でのテストの通過可否で評価を実施する．
問題文としては，C・D・E・F問題を各200問(計800問)と，few-shot学習の例として各難易度4問を別途利用する．


\subsection{比較対象}
few-shot学習を用いた要件分割の有無，要求文(全体概要)提示の有無，及び要件粒度の再検討(統合・再分割)の有無を比較し，提案プロセスの有効性を調査する． 


\section{結果と考察}
主要な結果を以下と図\ref{result1}，図\ref{result2}，図\ref{result3}にまとめる．

few-shot学習を用いた要求文の分割と，全体概要の共有は，分割無し(従来手法)の場合に入出力テストの通過率は9.30\%であるのに対して，42.86\%まで通過率が改善された．

要件文を統合した場合のテスト通過率は，統合前で42.86\%であるのに対して，統合後では43.38\%と横ばいであり，800問中，716問で統合前後の結果が不変であった．

再分割を行なった場合では，43.38\%から57.59\%と約15\%の改善が見られた．

一方で，要件間の依存関係や前提の誤解があると，段階的実装でも要求文に沿わない誤りが生じる．
また，プロセスの反復は2回目以降で改善が頭打ちになる傾向が見られた．

\begin{figure}[tb]
    \centering
    \includegraphics[width=0.7\linewidth]{./Toyoshima_fig/RQ2_1.pdf}
    \caption{結果1}
    \label{result1}
\end{figure}

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{./Toyoshima_fig/RQ4_2.pdf}
    \caption{結果2}
    \label{result2}
\end{figure}

\begin{figure}[tb]
    \centering
    \includegraphics[width=0.7\linewidth]{./Toyoshima_fig/RQ5.pdf}
    \caption{結果3}
    \label{result3}
\end{figure}

\section{おわりに}
本研究は，ChatDev を拡張し，要件分割と段階的実装に加えて，再計画（統合・再分割）を反復するプロセスを提案した．
AtCoder を用いた評価により，分割と全体概要共有の組み合わせが通過率を大きく改善し，再分割により追加の改善が得られることを示した．
今後は，差分行数以外の失敗要因を統合指標へ取り入れること，および実リポジトリ課題のような複数ファイル・外部依存を含む設定への拡張\cite{SWE-bench}が課題である．

\begin{thebibliography}{9}
\bibitem{ChatDev}
C. Qian et al.:
ChatDev: Communicative Agents for Software Development,
Proc. ACL (Long Papers), pp.15174--15186 (2024).

\bibitem{TOSEM}
X. Jiang et al.:
Self-planning Code Generation with Large Language Models,
ACM Trans. Softw. Eng. Methodol., Vol.33, No.7 (2024).

\bibitem{LLM_few_shot}
T. B. Brown et al.:
Language Models are Few-Shot Learners,
Advances in Neural Information Processing Systems (NeurIPS), Vol.33, pp.1877--1901 (2020).

\bibitem{SWE-bench}
J. Jimenez et al.:
SWE-bench: Can Language Models Resolve Real-World GitHub Issues?,
(参考：実課題ベンチマークとして言及).
\end{thebibliography}

\end{document}
