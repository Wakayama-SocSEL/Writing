@article{static-analysis,
author = {Haas, Roman and Niedermayr, Rainer and Roehm, Tobias and Apel, Sven},
title = {Is Static Analysis Able to Identify Unnecessary Source Code?},
year = {2020},
issue_date = {January 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3368267},
doi = {10.1145/3368267},
abstract = {Grown software systems often contain code that is not necessary anymore. Such unnecessary code wastes resources during development and maintenance, for example, when preparing code for migration or certification. Running a profiler may reveal code that is not used in production, but it is often time-consuming to obtain representative data in this way.We investigate to what extent a static analysis approach, which is based on code stability and code centrality, is able to identify unnecessary code and whether its recommendations are relevant in practice. To study the feasibility and usefulness of our approach, we conducted a study involving 14 open-source and closed-source software systems. As there is no perfect oracle for unnecessary code, we compared recommendations for unnecessary code with historical cleanups, runtime usage data, and feedback from 25 developers of five software projects. Our study shows that recommendations generated from stability and centrality information point to unnecessary code that cannot be identified by dead code detectors. Developers confirmed that 34\% of recommendations were indeed unnecessary and deleted 20\% of the recommendations shortly after our interviews. Overall, our results suggest that static analysis can provide quick feedback on unnecessary code and is useful in practice.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jan,
articleno = {6},
numpages = {23},
keywords = {Unnecessary code, code centrality, code stability}
}

@inproceedings{dynamic-analysis,
author = {Shackleton, Will and Cohn-Gordon, Katriel and Rigby, Peter C. and Abreu, Rui and Gill, James and Nagappan, Nachiappan and Nakad, Karim and Papagiannis, Ioannis and Petre, Luke and Megreli, Giorgi and Riggs, Patrick and Saindon, James},
title = {Dead Code Removal at Meta: Automatically Deleting Millions of Lines of Code and Petabytes of Deprecated Data},
year = {2023},
isbn = {9798400703270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611643.3613871},
doi = {10.1145/3611643.3613871},
abstract = {Software constantly evolves in response to user needs: new features are built, deployed, mature and grow old, and eventually their usage drops enough to merit switching them off. In any large codebase, this feature lifecycle can naturally lead to retaining unnecessary code and data. Removing these respects users’ privacy expectations, as well as helping engineers to work efficiently. In prior software engineering research, we have found little evidence of code deprecation or dead-code removal at industrial scale. We describe Systematic Code and Asset Removal Framework (SCARF), a product deprecation system to assist engineers working in large codebases. SCARF identifies unused code and data assets and safely removes them. It operates fully automatically, including committing code and dropping database tables. It also gathers developer input where it cannot take automated actions, leading to further removals. Dead code removal increases the quality and consistency of large codebases, aids with knowledge management and improves reliability. SCARF has had an important impact at Meta. In the last year alone, it has removed petabytes of data across 12.8 million distinct assets, and deleted over 104 million lines of code.},
booktitle = {Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {1705–1715},
numpages = {11},
keywords = {Automated refactoring, Code transformation, Data cleanup, Data purging},
location = {San Francisco, CA, USA},
series = {ESEC/FSE 2023}
}

@inproceedings{NIL,
author = {Nakagawa, Tasuku and Higo, Yoshiki and Kusumoto, Shinji},
title = {NIL: large-scale detection of large-variance clones},
year = {2021},
isbn = {9781450385626},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468264.3468564},
doi = {10.1145/3468264.3468564},
abstract = {A code clone (in short, clone) is a code fragment that is identical or similar to other code fragments in source code. Clones generated by a large number of changes to copy-and-pasted code fragments are called large-variance (modifications are scattered) or large-gap (modifications are in one place) clones. It is difficult for general clone detection techniques to detect such clones and thus specialized techniques are necessary. In addition, with the rapid growth of software development, scalable clone detectors that can detect clones in large codebases are required. However, there are no existing techniques for quickly detecting large-variance or large-gap clones in large codebases. In this paper, we propose a scalable clone detection technique that can detect large-variance clones from large codebases and describe its implementation, called NIL. NIL is a token-based clone detector that efficiently identifies clone candidates using an N-gram representation of token sequences and an inverted index. Then, NIL verifies the clone candidates by measuring their similarity based on the longest common subsequence between their token sequences. We evaluate NIL in terms of large- variance clone detection accuracy, general Type-1, Type-2, and Type- 3 clone detection accuracy, and scalability. Our experimental results show that NIL has higher accuracy in terms of large-variance clone detection, equivalent accuracy in terms of general clone detection, and the shortest execution time for inputs of various sizes (1–250 MLOC) compared to existing state-of-the-art tools.},
booktitle = {Proceedings of the 29th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
pages = {830–841},
numpages = {12},
keywords = {Scalability, Large-Variance Clone, Clone Detection},
location = {Athens, Greece},
series = {ESEC/FSE 2021}
}

@article{Lacuna,title={JavaScript Dead Code Identification, Elimination, and Empirical Assessment},author={I. Malavolta and Kishan Nirghin and Gian Luca Scoccia and Simone Romano and Salvatore Lombardi and G. Scanniello and Patricia Lago},journal={IEEE Transactions on Software Engineering},year={2023},volume={49},pages={3692-3714},doi={10.1109/tse.2023.3267848}}

@INPROCEEDINGS{increase-maintainability,
  author={Eder, Sebastian and Junker, Maximilian and Jürgens, Elmar and Hauptmann, Benedikt and Vaas, Rudolf and Prommer, Karl-Heinz},
  booktitle={2012 34th International Conference on Software Engineering (ICSE)}, 
  title={How much does unused code matter for maintenance?}, 
  year={2012},
  volume={},
  number={},
  pages={1102-1111},
  keywords={Maintenance engineering;Assembly;Software systems;Business;Information systems;Production;Software maintenance;dynamic analysis;unnecessary code;unused code},
  doi={10.1109/ICSE.2012.6227109}}

@ARTICLE{decrease-readability,
  author={Romano, Simone and Vendome, Christopher and Scanniello, Giuseppe and Poshyvanyk, Denys},
  journal={IEEE Transactions on Software Engineering}, 
  title={A Multi-Study Investigation into Dead Code}, 
  year={2020},
  volume={46},
  number={1},
  pages={71-99},
  keywords={Software systems;Maintenance engineering;Software engineering;Interviews;Tools;Open source software;Dead code;unreachable code;unused code;bad smell;empirical investigation;multi-study},
  doi={10.1109/TSE.2018.2842781}}

