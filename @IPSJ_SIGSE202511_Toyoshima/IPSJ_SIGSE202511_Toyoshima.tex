%%
%% 研究報告用スイッチ
%% [techrep]
%%
%% 欧文表記無しのスイッチ(etitle,eabstractは任意)
%% [noauthor]
%%

%\documentclass[submit,techrep]{ipsj}
\documentclass[submit,techrep,noauthor]{ipsj}

\usepackage[dvips]{graphicx}
\usepackage{latexsym}

\newcommand{\todo}[1]{\colorbox{yellow}{{\bf TODO}:}{\color{red} {\textbf{[#1]}}}}
\newcommand{\ihara}[1]{\colorbox{green}{{\bf IHARA}:}{\color{blue} {\textbf{[#1]}}}}

\def\Underline{\setbox0\hbox\bgroup\let\\\endUnderline}
\def\endUnderline{\vphantom{y}\egroup\smash{\underline{\box0}}\\}
\def\|{\verb|}
%

%\setcounter{巻数}{59}%vol59=2018
%\setcounter{号数}{10}
%\setcounter{page}{1}


\begin{document}


\title{大規模言語モデルによるコード生成のための反復的な要件統合と最適化プロセス\\}

\affiliate{IPSJ}{情報処理学会\\
IPSJ, Chiyoda, Tokyo 101--0062, Japan}


\paffiliate{JU}{情報処理大学\\
Johoshori Uniersity}

\author{豊嶋 浩基}{Toyoshima Hiroki}{IPSJ}[s276157@wakayama-u.ac.jp]
\author{伊原 彰紀}{Ihara Akinori}{IPSJ}[ihara@wakayama-u.ac.jp]
\author{田井 聖凪}{Tai Sena}{IPSJ,JU ???????}[s2310137@wakayama-u.ac.jp]

\begin{abstract}
大規模言語モデル（LLM）はソフトウェア開発の効率化に大きく貢献するが，複雑な要件への対応は依然として重要な課題である．我々はこれまで自然言語からコードを自動生成するマルチエージェント型フレームワークであるChatDevに対して，few-shotを用いた要件の細分化と段階的開発を実施した．これにより，入出力テストに基づいた性能の向上が確認できた一方で，局所的な最適化に留まり，システム全体の品質に課題を残す．
そのため本研究では，分割された要件の統合と反復的改善の概念を組み合わせた新たな開発プロセスを提案する．具体的には，分割・生成されたコード群を対象に，全体の整合性を評価し，再統合と洗練を行うイテレーションを導入する．この反復的な最適化プロセスは，複雑なソフトウェア要件に対するコード生成品質を一段階引き上げるための，新たな開発指針となることを目指す．

\end{abstract}


\maketitle

%1
\section{はじめに}
昨今の大規模言語モデル(LLM)の急速な発達に伴い，LLMはこれまで人間が時間や労力などのコストをかけて行なっていたタスクを自動・効率化する可能性を持つことから，幅広い分野において関心を集めている．ソフトウェア開発においても同様で，期待する要件の自然言語をプロンプトとして与えることでプログラムコードを自動生成するコード自動生成についても高い期待が高まっている．
 
一方で，複数の要求を内包した複雑な要件からコードの生成を実施する場合，使用漏れや依存関係の不整合などにより，要件を満たさない不完全なコードが生成されやすいという課題が挙げられる．それに対して， プロンプトに最終的な結論に至るまでの考え方を含めることでLLMの推論能力を高めるChain of Thoughtや，少量の例を学習させることで期待した内容を生成させるfew-shot学習などと言った従来のプロンプト技術は，実装方法や記述方法など，同様の要件に対して等価な解が存在しており，コードの例を提示したとしてもLLMは十分な理解を示さない．
\todo{キーアイディア: 複雑な要件の細分化による局所最適化，全体概要を学習させることによる全体整合，統合と再分割}

本論文では，〜〜〜を提案する．

%2
\section{関連研究}
\label{sec:format}

%2.1
\subsection{ChatDev: マルチエージェントによる段階的開発フレームワーク}
本研究では，設計・実装・レビュー・テストと言ったウォーターフォールモデルに則り，各フェーズを役割を学習させたLLMに開発を行わせるChatDev\todo{参考文献: https://arxiv.org/pdf/2307.07924}をベースラインとして使用する．本フレームワークでは，各フェーズにおいてチャットを介して，要件と生成された成果物の引き渡し，それらを基にLLMエージェント同士が対話を行い，合意形成と生成を実施していく．一方で，与えられた全ての要件を一度に生成する使用上，複数機能を内包する要件に対しては不完全なコードが生成されてしまう．\todo{各フェーズにおけるタスクの粒度が大きい，みたいな話が伝わるように推敲 and はじめにの部分と同じこと言ってる}
\todo{どの章で何について話すか}

%2.2
\subsection{要件の複雑度が一定を上回ると，急にLLMの精度が落ちる(apple learning research)}


%2.3
\subsection{TOSEM}
\todo{これを参考文献に出すとfew-shotで分割したら性能上がった！って話がこれで済んじゃうから書き方どうしよう...}
\bibliographystyle{ipsjunsrt}
\bibliography{bibsample}


\end{document}
