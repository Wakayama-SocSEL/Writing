%%
%% 修士論文
%%
%% USE 機能的に等しい
%% not 外的振る舞いが等しい
%%
%% USE 大規模言語モデル
%% not LLM
%%
%% USE 低下させる
%% not 下げる
%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% 利用するコマンドの準備
%%

%% 必須パッケージ
\documentclass[11pt]{jreport}
\usepackage{wuse_thesis}
\usepackage{indentfirst}

%% 追加パッケージ
%\usepackage{graphicx}
\usepackage{comment}
\usepackage[dvipdfmx]{graphicx}
\usepackage{url}

\usepackage{latexsym}

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{listings}
\usepackage{makecell}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{tabularx}
\usepackage{tcolorbox}
\usepackage{tascmac}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\newcommand{\todo}[1]{\colorbox{yellow}{{\bf TODO}:}{\color{red} {\textbf{[#1]}}}}


% \lstset{
% basicstyle=\small\ttfamily,
% abovecaptionskip=0pt,
% captionpos=b,
% frame=tb,
% framexleftmargin=2em,
% numbers=left,
% numberstyle={\scriptsize},
% xleftmargin=\parindent
% }

\lstset{
    basicstyle=\ttfamily\small,
    frame=single,
    breaklines=true,
    backgroundcolor=\color{gray!10},
    columns=fullflexible,
}

%ListingのキャプションがFigureになってしまうのをListingに直すコマンド
\usepackage{caption}
\makeatletter
\let\MYcaption\@makecaption
\makeatother
\usepackage{caption}
\makeatletter
\let\@makecaption\MYcaption
\makeatother

\def\Underline{\setbox0\hbox\bgroup\let\\\endUnderline}
\def\endUnderline{\vphantom{y}\egroup\smash{\underline{\box0}}\\}
\def\|{\verb|}
%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% 主に表紙を作成するための情報
%%

%% タイトル(修論の場合は英語表記も指定)
\title{複数ソフトウェアの修正履歴の混合による\\コーディング規約違反の修正予測手法}
\etitle{Prediction Approach of Coding Standard Violation Fixes by Using Combined Change Histories from Multiple Projects}

%% 著者名(修論の場合は英語表記も指定)
\author{亀岡 令}
\eauthor{Ryo Kameoka}

%% 修士論文(M2用)
\master

%% 学科・クラスタ
\department{システム工}

%% 学生番号
\studentid{S2420033}

%% 卒業年度
\gyear{2025}

%% 論文提出日(修士の場合は月まで)
\date{2026年2月}
\edate{February 2026}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% 表紙・概要・目次
%%

\begin{document}

%% 表紙
\maketitle

%% 概要
\begin{abstract}
ソフトウェア開発プロジェクトが，コーディングスタイルを共通化するために，独自で設定したコーディング規約に違反するソースコードを自動検出する静的解析ツールが頻繁に使用される．しかし，コーディング規約違反コードを大量に検出するため，一部の規約違反コードのみが修正されることが多い．従来研究では，プロジェクトの修正履歴に基づき，機械学習を用いて修正すべき規約違反コードを推薦するモデル（\todo{規約違反コードの修正要否判定モデル？}）を開発しているが，修正履歴に正例数（修正された違反コード）が少ない場合に予測精度が低いという課題があった．本研究では，他のプロジェクトの修正履歴も学習データに含める違反修正要否判定モデルを提案する．170のオープンソースプロジェクトを対象にケーススタディを実施した結果，\todo{どうだった？}

\end{abstract}

%% 目次
\tableofcontents

%% 図目次
%\listoffigures

%% 表目次
%\listoftables

\newpage
\pagenumbering{arabic}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{はじめに}

コーディング規約は，ソースコードの記述方法に関する禁止事項や推奨事項を定め, 可読性や保守性を高めるためのコーディングスタイルの取り決めである．
ソフトウェア開発プロジェクトは，実装に参加する開発者にコーディングスタイルの共通化や, ソースコードの最適化のためにコーディング規約の遵守を促すことで, 可読性や保守性の高いソースコードを共有することができる\cite{EffectsSAT}. 
コーディング規約は，プログラミング言語ごとに規約のテンプレートが存在し，開発者はテンプレートを参考にプロジェクトに適した規約の選定やカスタマイズを行っている．
具体的には，開発者にとってのソースコードの理解容易性や，バグの早期発見に貢献している\cite{Beller2}\cite{Johnson}\cite{Beller}.

コーディング規約に違反しているコード断片（以降，規約違反コード）を機械的に検出するために，多くのプロジェクトは静的解析ツールを使用している．
静的解析ツールは, ソースコード中の規約違反コードを正規表現などによりソースコードを実行することなく検出できるため, 継続的インテグレーションのプロセスの1つとして使用されることも多い．
プログラミング言語別に提供される規約違反のリストには，規約違反の種類を多数定義しているため，一部の違反のみ有効にしているプロジェクトも存在する\todo{引用？}しかし，開発者が有効に設定されたすべての規約違反を修正しておらず，従来研究による実証実験によると35\%から91\%の規約違反コードは修正されていない\cite{静的解析ツールの修正率}．
静的解析ツールが検出する膨大な規約違反コードの中から，修正を要する規約違反コードを特定するために，手動で分類を行うことが開発効率の低下につながるため，修正が必要な規約違反コードを分類するための研究が行われている\cite{Nguyen}.


従来研究では，大量に検出される規約違反コードを，修正すべき違反とそうでない違反に自動分類する手法が提案されている\cite{JyuraiPre}．
また，静的解析ツールの検出結果を修正すべき順番にランキングづけをする研究も数多く行われている．

従来研究では，特定のプロジェクトにおいて，過去の規約違反コードの修正履歴を学習しモデルを構築する手法を提案している．
当該手法は，学習データの総数は多くても正例が少ないプロジェクトで予測精度が低くなる課題を有する．
特定プロジェクトの修正履歴のみに依存する手法では，，開発初期段階や小規模なプロジェクトにおいて，モデルの学習に必要な修正履歴が十分に確保できないデータ不足の問題（\textbf{コールドスタート問題}）が発生する．

Tabassumらは，不具合予測やソースコード自動修正の分野で，データ不足やコールドスタート問題に対応するため，異なるプロジェクトの修正履歴を利用して学習データを補う手法を提案している\cite{Tabassum}．
規約違反コードの検出においても，異なるプロジェクトのデータを利用すれることでコールドスタート問題の解消が期待できる
% 一方で，実装方針の異なるプロジェクトのデータを学習することで精度が低下する課題も考えられる．
一方で，単に他プロジェクトのデータを混合するだけでは，実装方針やコーディングスタイルの差異がノイズとなり，却って精度を低下させる懸念も存在する．

本研究では，複数プロジェクトの修正履歴を予測モデルの学習に用いることによる規約違反コードの修正予測精度を明らかにする．提案手法として，2種類の予測モデルを構築する．1つは，複数プロジェクトの修正履歴を単純に結合して学習する手法である（全学習手法）．もう1つは，%\todo{XX}
規約違反の修正傾向が類似する複数プロジェクトの修正履歴を結合して学習する手法である（選定学習）．本研究の提案は，著者らが以前に提案した手法\cite{mine}\cite{mine_live}を拡張し，類似プロジェクトのみを混合する選定学習を新たに導入した点にある．評価の結果，一部のプロジェクトにおいて適合率に改善が見られた．%\todo{一部のように弱気に書くか悩みどころ．}

% \todo{データセット拡張した結果に書き換える}
近年では大規模言語モデルによる自動修正も期待されるが，過剰修正の問題がある\cite{LLMで自動修正}．
本研究の貢献として，本研究のような修正要否判定は，大規模言語モデルが修正すべき対象を限定するための前処理としても極めて重要である．

続く\ref{chap:background}章では, コーディング規約違反の検出と, 従来研究について述べる. \ref{chap:approach}章では本研究における実験の全体像と提案手法について述べる. \ref{chap:rq1}，\ref{chap:rq2}，\ref{chap:rq3}章では評価結果を示し, \ref{chap:consideration}章では考察を述べる. \ref{chap:heuristic}章では本研究の妥当性への脅威について述べ, \ref{chap:end}章でまとめる.

\chapter{背景と関連研究}\label{chap:background}



\section{可読性を担保するコーディング規約}

ソースコードの可読性や保守性といった品質を高水準で維持することは重要である．
可読性の高いソースコードを書くことで，ソースコードの理解の促進やバグの混入の予防などの効果が期待できる．
また，品質の劣るコードには，良質なコードの約15倍の欠陥が含まれる可能性があることが報告されている\cite{コード品質の重要性}．

特に大規模なソフトウェア開発では，ソースコードを実装した後に，実装者とは異なる開発者が，新規実装されたソースコードにバグなどの問題が含まれていないかを確認するレビュー作業が発生する．
可読性の高いコードはレビューコストの削減や技術的負債の抑制につながる\todo{参考}．
つまり，可読性の高いソースコードを書くことは，ソフトウェア開発サイクル全体の促進につながる．

そこで，開発者はソフトウェア開発にコーディング規約を導入する．
コーディング規約は，複数人によるソフトウェア開発においてソースコードの記述方法を共通化するための指針である．
コーディング規約には，変数やクラスの命名規則，関数の長さや複雑度の上限といった可読性に関するルール，エラーの原因となる記述の検出，禁止事項，制限事項，推奨事項などが含まれる．

コーディング規約は，プログラミング言語ごとに異なる内容や基準を持ち，多くの種類の規約が存在する．
例えば，Python言語にはPEP8，Java言語にはCode Conventions for the Java Programming LanguageやGoogle Java Style Guide，JavaScript言語にはGoogle JavaScript Style GuideやAirbnb JavaScript Style Guideなどが代表的な例ある．
本研究で対象とするPython言語のPEP8では，「コードは書かれる回数よりも読まれる回数のほうが多い」という原理に基づいて定められたスタイルガイドである．

開発者はコーディング規約を遵守したコーディングを行うことによって，一定のコードの品質を保つことができる．
実装したコードはレビュアーが見る際には，可読性が担保されたコードを見ることが可能となる．
実装されたソースコードが，コーディング規約に従っているかどうかを開発者が手動で確認することには多くの時間的コストを要する．
そのため，ソースコードのコーディング規約に従っていない個所を自動的に特定するために静的解析ツールが用いられる．


\section{静的解析ツール}

ソースコードがコーディング規約に従っているかや，違反しているコードがどこに存在するのかを特定するために静的解析ツールが利用される．
コーディング規約に従っていないコードを検出する静的解析ツールも各プログラミング言語ごとに存在する．
代表的な例としては，PythonのFlake8やJavaScriptのESLint，JavaのCheckstyleが挙げられる．
また，これらの静的解析ツールは存在する，規約の中から，どの規約への違反を検出対象とするかを任意で決定することができる．
検出する違反の種類を制御するためには，それぞれの静的解析ツールごとに定められたディレクトリに決められたファイル名のテキストファイルを配置し，設定を記述することで制御ができる．

ソフトウェア開発者は，各プロジェクトが参照する規約，違反検出時の出力形式を調整を加えながら，静的解析ツールを用いて規約違反コードを検出している．
プロジェクトの中には，継続的インテグレーション (CI) 環境に組み込むことで開発初期段階での不具合修正により，開発小売りの向上を実現している\cite{ci/cd}．
静的解析ツールは，ソースコード中の規約違反コードを網羅的に検出するが，その数は膨大であることが多く，開発者がそのすべてを確認，修正，保守するには多大なコストと労力を要する\cite{UsingStaticAnalysisTools2}．さらに，優先的に修正すべき違反を区別するためには，経験やソースコードへの深い理解が求められる\cite{shuseisarenai}．

本研究で使用するPythonの静的解析ツールである，Flake8について簡単に説明する．
Flake8はPython言語を対象に，静的解析を行うツールで以下の3種類のツールのラッパーである．

\begin{itemize}
    \item PyFlakes: 論理エラーのチェック
    \item pycodestyle: PEP8準拠のチェック
    \item McCabe: コードの複雑度（Cyclomatic Complexity）のチェック
\end{itemize}

Flake8は実行時エラーになるコード以外にも，可読性を低下させているコードについても検出可能である．
また，McCabeでは複雑度を測定することが可能であり，コードの複雑度は本研究で構築する機械学習モデルの説明変数にも利用する．
これらのツール以外にも，プラグインとして様々なデバッグツールをカスタムで利用可能である．

\section{従来研究}\label{sec:zyuuraikennkyuu}


従来研究では，静的解析ツールによる大量に検出した規約違反コードの中から，機械学習を用いて修正すべき規約違反コードを分類する手法が提案されている\cite{JyuraiPre}\cite{beizu}．
Kimらは，静的解析ツールの出力をベイジアンネットワークに基づいて解析し，修正すべき規約違反コードを分類する手法を提案している\cite{beizu}．また，検出された違反に対する修正優先度付けする研究も数多く行われている\cite{Wang}\cite{Qing}\cite{HowFar}．これらの研究では，予測対象プロジェクトにおける規約違反の修正履歴を学習データとして用い，新たに検出された違反を評価対象とする機械学習モデル（規約違反コードの修正要否判定モデル）の構築と評価が行われている．

近年では大規模言語モデルを用いた，静的解析ツールの検出結果の分類手法が提案されている．
Mohajerらは，静的解析ツールによる検出結果のうち，真の警告か否かを大規模言語モデルであるGPT-4を利用して分類する手法を提案している\cite{LLMで分類}．
また，静的解析ツールを用いずに，ソースコード自体をGPTに渡し，ソースコード中の警告の検出を行い，静的解析ツールより優れた検出が可能かどうかの検証を行っている．
結果として，従来手法より高い精度で静的解析ツールの検出結果の分類が可能である．
静的解析ツールが検出可能なコード品質を低下させているコードと，大規模言語モデルが検出可能なコード品質を低下させているコードでは．検出可能な種類が異なるという結果が明らかにされている．

従来研究では，評価対象プロジェクトの修正履歴を学習データとして用いてモデルを構築している．これは各プロジェクトでコーディングスタイルや開発体制が異なり，評価対象と同一プロジェクトの修正履歴を学習することで高い精度が得られることが示されている．
% 従来研究では，一般に，評価対象プロジェクトの修正履歴を学習データとして用いて予測モデルを構築する．プロジェクトごとにコーディングスタイルや開発体制が異なるため，対象と同一プロジェクトの履歴を学習する方が，他プロジェクトの履歴を用いるよりも高い精度が得られると考えられている．
しかし，同一プロジェクトの学習データには，出現する違反の種類や修正率に偏りが生じることがある\cite{Panichella}
%\todo{この論文では予測まで行っていない？そのため，次の文であるように予測精度が低下する可能性，という表現になっているう？}
．
この結果，修正された違反（正例）と修正されなかった違反（負例）の数に不均衡が生じ，予測精度の低下を招く可能性がある．また，予測対象プロジェクトの違反修正履歴が小規模の場合，学習データが小規模になり十分な学習ができない可能性がある．

% 本研究では，評価対象以外のプロジェクトの修正履歴を学習データに含めることで，規約違反コードの修正予測精度の向上を目的とする．

従来研究では，名倉らが複数プロジェクトのデータを用いて規約違反の発生件数の増減を予測している．一方で，個々の規約違反コードの修正有無の予測は対象としていないため，本研究とは異なるが，研究動機は類似している\cite{nagura}．
異なるプロジェクトの修正履歴を用いることで，学習データの拡張による予測精度の向上が期待されるが，異なるコーディングスタイルを有するプロジェクトの修正履歴は予測精度を低下することも考えられる．
% すべての他プロジェクトのデータが有益とは限らない．すなわち，修正傾向が異なるプロジェクトのデータは，予測に対してノイズとなる可能性がある．

そこで本研究では，評価対象プロジェクトと修正傾向が類似するプロジェクト選定し，修正履歴を混合することで学習データの拡張し，予測モデルの精度向上を目指す．
アプローチをとして，コールドスタート問題を解決するために，他プロジェクトの履歴を単に混合するだけでなく，修正傾向の類似性に基づいた選定を行うことで，ノイズの混入を抑制しつつ学習データを拡張するアプローチをとる．

\section{大規模言語モデルを利用した静的解析ツール検出結果の自動修正}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\linewidth]{@Master2025_Kameoka/fig/LLM_zyuurai.pdf}
    \caption{大規模言語モデルを活用したコード品質を低下させているコードの分類と自動修正の関連研究}
    \label{fig:LLM_zyuurai}
\end{figure}

近年の大規模言語モデルをの発展に伴い，生成AIを用いた静的解析ツールの解析結果からパッチの自動生成する研究が複数行われている\cite{LLMで自動修正}\cite{codecureagent}．
Wadhwaらは，プログラム中に存在する，コーディング規約に違反しているコードと静的解析ツールの結果から，修正パッチの自動作成をする研究を行っている\cite{LLMで自動修正}．
図\ref{fig:LLM_zyuurai}に実験の大まかの流れを示す．
提案されている手法では，パッチの自動作成に二段階に大規模言語モデルを利用している．
一つ目の大規模言語モデル（Proposer LLM）では，静的解析ツールによる検出箇所に対するパッチを複数生成する．
二つ目の大規模言語モデル（Ranker LLM）では，生成されたパッチの中から，コンパイル可能で，検出された問題が解消されているパッチから，開発しに受け入れられやすいパッチを順位づけする．

結果として，既存の深層学習を用いた自動パッチ生成の手法より高い精度でパッチの作成が可能であった．
しかし，大規模言語モデルに修正パッチの生成を行わせるタスクでは，どれだけプロンプトで制限を行った場合であっても，関係のないコードまで修正を行ってしまうというデメリットも報告されている．
% Wadhwaらの研究では，静的解析ツールと生成AIでは，コード品質を低下させている個所の検出可能な種類が異なるため，静的解析ツールと生成AIの併用を勧めている．

この関連研究にいてパッチの作成元となるコードは，静的解析ツールによって検出されたコードを対象としている．
そのため，静的解析ツールの検出結果が真の問題点であるかの判定をしていないため，レビューに関するコストは抑制できていない．
本研究では，静的解析ツールの検出結果を，真の検出結果か否かを分類するため，自動パッチ生成を実行する前に，規約違反の分類を行うことで，パッチを作成する問題を絞り込むことで，レビューコストを小さくすることが可能である．

% \section{目的}

% 本研究では，\ref{sec:zyuuraikennkyuu}節で示した従来研究と同様に，予測対象のプロジェクトの修正履歴を学習に使用するため，プロジェクトごとの修正の特徴をとらえた学習が可能である．
% Wadhwaらの研究では，大規模言語モデルにソースコードと静的解析ツールの結果を渡しているのみなので，プロジェクトごとに最適化はされていない．
% 本研究では，修正履歴の学習を行うためプロジェクトごとに最適化を行うことができるという点で異なる．

\section{RQs}

本研究では静的解析ツールによって検出されたコーディング規約違反の修正要否を予測するにあたり，予測対象以外の複数プロジェクトの開発データを学習に使用することによる修正要否予測精度の向上を目的とする．
本分野において，先行研究は多く行われている．
しかし，一般的に予測対象のプロジェクトの過去の開発データのみを学習に使用しており，検証対象のプロジェクトには十分な修正履歴のあるプロジェクトを選択している．

そこで，本研究では予測対象以外の複数プロジェクトの学習データを機械学習モデルに学習させることによる，コーディング規約違反の修正要否予測の予測精度への影響を明らかにするために，以下のRQsを設定する．

\begin{itemize}
    \item RQ1: 複数プロジェクトを学習に用いることによって，修正予測精度は向上するか
    \item RQ2: 予測精度改善に寄与するプロジェクトの属性およびデータ構造の特定
    \item RQ3: 提案手法によりコーディング規約違反の種類ごとに予測精度は変化するか
\end{itemize}

RQ1では，提案手法である，複数プロジェクトのデータを学習に使用することによる，コーディング規約違反の修正要否予測精度への影響を明らかにする．
また，アプローチの一つである予測対象プロジェクトと類似したプロジェクトを収集する手法の妥当性を検証する．

RQ2では，従来手法の課題として挙げた，予測対象プロジェクトの過去の開発データに正例が少ない場合に．提案手法によって予測精度が向上するのかについて分析を行う．
また，予測精度が向上しやすい，つまり提案手法が有効に働くプロジェクトに特徴があるのかについて分析を行う．

RQ3では，コーディング規約の種類ごとに予測結果の分析を行い，提案手法である，複数プロジェクトのデータを学習に使用するべき条件の分析を行う．

\chapter{規約違反コードの修正要否判定方法とモデルの構築方法}\label{chap:approach}

\section{モデル構築方法の概要}

\begin{figure}[ht]
    \centering
    \includegraphics[width=1.05\linewidth]{@IPSJjournal2025_Kameoka/fig/syuhou.pdf}
    \caption{提案手法の全体像}
    \label{fig:Teiannsyuhou}
\end{figure}

図\ref{fig:Teiannsyuhou}に，本研究で検討する予測モデルの構築方法の全体像を示す．
本研究では，予測対象プロジェクトにおける規約違反の修正履歴に加え，他プロジェクトの修正履歴を効果的に混合することで，修正の必要性を高精度に判定するモデルを構築する．
具体的には，学習データの決定方法の違いに基づき，以下の4種類のモデルを構築し，その予測性能を評価・比較する．
なお，1は従来研究に基づく比較手法，2から4は本研究で提案・検討する手法である．

\begin{enumerate}
    \item \textbf{単一学習モデル（従来手法）} \\
    予測対象プロジェクトの過去の修正履歴のみを学習データとして利用する手法である．プロジェクト固有の修正傾向を反映できる一方で，開発初期段階などのデータ不足時におけるコールドスタート問題が課題となる．
    
    \item \textbf{全学習モデル（提案手法）} \\
    予測対象を含む全プロジェクトの修正履歴を無差別に統合して学習に用いる手法である．学習データ量を最大化できる反面，プロジェクト間で修正傾向が異なる場合に，他プロジェクトのデータがノイズとなる可能性がある．
    
    \item \textbf{選定学習モデル1：欠損値補完なし（提案手法）} \\
    予測対象プロジェクトと「発生している規約違反の種類」や「修正率」が類似するプロジェクトを動的に選定し，その履歴を学習に加える手法である．ただし，類似度算出の際，比較プロジェクト間で共通して存在する規約のみを評価対象とする．
    
    \item \textbf{選定学習モデル2：欠損値補完あり（提案手法）} \\
    選定学習モデル1と同様に類似プロジェクトを選定するが，欠損している（一方のプロジェクトに存在しない）規約の修正率を平均値で補完した上で類似度を算出する手法である．より厳密な類似性評価に基づく学習データの最適化を目的とする．
\end{enumerate}

これらの各モデルの具体的な構築手順および特徴の詳細については，\ref{sec:model_koutiku}節にて詳述する．


\section{目的変数の計測}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.8\linewidth]{@IPSJjournal2025_Kameoka/fig/target_valiable.pdf}
    \caption{説明変数と目的変数の計測位置}
    \label{fig:mokutekihensu}
\end{figure}

\begin{table}[ht]
    \centering
    \caption{目的変数の正例と負例の分類}
    \label{tab:pos_neg}
    \scalebox{0.85}{
    \begin{tabular}{l|l}
        \hline
        分類 & 説明 \\ \hline
        負例（ケース1） & 規約違反がそのまま残存しているコード断片 \\
        正例（ケース2） & 違反コードが削除された断片 \\
        正例（ケース3） & 規約違反が修正されたコード断片 \\ \hline
    \end{tabular}
    }
\end{table}

図\ref{fig:mokutekihensu}は，本研究で構築するモデルの説明変数および目的変数の計測位置を示す．
目的変数は，分析期間内に検出した規約違反コードが，分析期間の最終リビジョンまでに修正される（正例）か否か（負例），言い換えると静的解析ツールにより規約違反として検出されるか否かと定義する．
表\ref{tab:pos_neg}は，図\ref{fig:mokutekihensu}に示す3つのケースを例として，目的変数の分類を示す．ケース1は負例，ケース2およびケース3は正例とする．

具体的な目的変数の計測方法について図\ref{fig:mokutekihensu}を用いて説明する．
\begin{enumerate}
 \item プロジェクトの修正履歴であるGithubリポジトリを取得する
 \item 取得したリポジトリ内で，分析開始点までバージョンを戻す
 \item 静的解析ツールをすべてのPythonファイルに対して実行する
 \item コーディング規約違反の場所と種類を記録する（図\ref{fig:mokutekihensu}のケース1とケース2の発生が記録される）
 \item リポジトリを1つ次のコミットにチェックアウトする\label{mokuteki_start}
 \item 再度静的解析ツールを実行する\label{execute_sat}
 \item 新規コーディング規約違反があれば，追加記録する（図\ref{fig:mokutekihensu}のケース3の発生が記録される）
 \item 以前記録したものが消えていれば，正例として記録する（図\ref{fig:mokutekihensu}のケース2,3が正例として記録される）\label{mokuteki_end}
 \item 分析終了地点まで\ref{mokuteki_start}から\ref{mokuteki_end}を繰り返し，残存している違反を負例とする
\end{enumerate}

\ref{execute_sat}において，コードの移動があった場合，gitではコードの削除と追加のように記録される．
そこで本研究では，静的解析ツールによって検出されたコーディング規約違反のコンテキストを比較し，一致するものがあれば同定し，コーディング規約違反を追跡することで，同じ違反に対して複数の修正履歴が計測されることを防ぐ．

\section{説明変数の定義}

本研究で使用する説明変数の一覧を表\ref{tab:variables}に示す．
説明変数は，規約違反が初めて検出されたリビジョンのソースコードから計測した特徴量28種類（行数，コメント行数，循環的複雑度など）を使用する．
加えて，規約違反IDをOne-hotベクトルとしてを加えたものを説明変数とする．
使用する説明変数は，Wangらの研究において，静的解析ツールの誤検知分類タスクにおける重要な説明変数に関する研究が行われているため，その内容に基づき決定した\cite{Wang}．

従来研究では研究対象言語として，Javaを主要な開発言語としているプロジェクトを利用している．
本研究では研究対象言語にPythonを採用している．
そのため，従来研究で取得していたコードメトリクスの中で，対象言語の違いにより一部取得できないものがあったため，従来研究に基づいた説明変数ではあるが，完全一致はしていない．
例えばインデントレベルは，Javaでは可読性を高めることが主要な目的であるが，Pythonにおいては制御構造を扱う重要な値となるため追加採用している．


\subsection{コーディング規約違反の修正要否予測の評価方法}

本研究では，コーディング規約違反の発生地点でのデータから，修正要否の予測を行う．
各プロジェクトの規約違反修正履歴の評価用データを用い，機械学習モデルで予測を行い，その結果の評価を行う．
評価には，適合率（式\ref{eq:precision}），再現率（式\ref{eq:recall}），F1値（式\ref{eq:f1}）を利用する．
本研究において適合率が高いことは，静的解析ツールが現出したコーディング規約違反のうち，修正の必要のない違反を効果的に削減できていることを意味する．
また，再現率が高いことは，検出された違反のうち，真に修正すべき違反の網羅性が高いことを意味する．

各手法による予測結果における適合率，再現率，F1値を比較することで，提案手法による静的解析ツールの検出結果の修正要否予測への有効性を明らかにする．

\begin{equation}
\label{eq:precision}
\text{適合率} = \frac{\text{修正が必要と予想できた違反数}}{\text{修正が必要と予想した違反数}}
\vspace{10pt}
\end{equation}

\begin{equation}
\label{eq:recall}
\text{再現率} = \frac{\text{修正が必要と予想できた違反数}}{\text{修正された違反数}}
\vspace{10pt}
\end{equation}

\begin{equation}
\label{eq:f1}
\text{F1値} = \frac{2 \cdot \text{適合率} \cdot \text{再現率}}{\text{適合率} + \text{再現率}}
\vspace{10pt}
\end{equation}


\section{予測モデルの構築方法と特徴}\label{sec:model_koutiku}

本節では，コーディング規約違反に対する修正要否を予測するために構築する4種類の学習モデルの構築方法および特徴を解説する．
具体的には，学習データに利用するプロジェクトの決定方法に基づき，「単一学習モデル」，「全学習モデル」，「選定学習モデル（欠損値補完なし）」，および「選定学習モデル（欠損値補完あり）」の4手法を定義する．
各モデルは，学習データの不足に起因するコールドスタート問題の解消と，プロジェクト固有の修正傾向の保持という，予測精度の向上における課題点と懸念点を考慮して設計している．

\subsection{単一学習モデル}

% 予測対象のプロジェクトの修正履歴のみを学習データとして用いるモデル\cite{JyuraiPre}．
% 図\ref{fig:Teiannsyuhou}の単一学習に示すように，従来研究の手法と同様に，予測対象プロジェクトの過去の開発データのみを学習データとする．
% 例えば，プロジェクトAの修正要否を予測するにあたり，プロジェクトAの過去の開発データのみを学習に利用する．
% つまり予測対象のプロジェクトごとに予測モデルが異なる．
% ただし，従来手法が対象とする静的解析ツールの警告は，セキュリティバグやエラーを引き起こすバグに絞った予測であり，本研究では，エラーにはならないコーディングスタイルに関する静的解析ツールの警告に予測まで拡張している．
% 従来手法は，予測対象プロジェクトの過去の開発データのみを学習に利用しているため，プロジェクトごとに存在するコーディングスタイルをとらえたモデルを構築することが可能である．
% しかし，予測対象プロジェクトが開発初期段階などの要因により修正履歴が不十分な場合，予測モデルの学習が十分にできないコールドスタートの問題がある．

本節で述べる単一学習モデルとは，予測対象となるプロジェクトの過去の修正履歴のみを学習データとして用いるモデルを指す\cite{JyuraiPre}．
図\ref{fig:Teiannsyuhou}の単一学習に示すように，本モデルは従来研究の手法と同様，予測対象プロジェクトの過去の開発データのみを学習に利用する．
具体的には，プロジェクトAの修正要否を予測する場合，プロジェクトA自身の過去の修正履歴のみを学習に用いる．
したがって，予測モデルはプロジェクトごとに個別に構築される．

ここで，従来手法と本研究の差異について述べる．
従来手法は，セキュリティバグや致命的なエラーを引き起こすバグに関する静的解析ツールの警告を対象としていた．
これに対し，本研究では，実行時エラーには直結しないコーディングスタイルに関する警告まで予測対象を拡張している．

メリットとして，単一学習モデルは，当該プロジェクトの過去の修正履歴のみを用いるため，プロジェクト固有のコーディングスタイルを捉えたモデルの構築が可能である．
その一方で，プロジェクトの開発初期段階などの要因により蓄積された修正履歴が不十分な場合には，予測モデルの学習が十分に行えないコールドスタート問題が存在する．


\subsection{全学習モデル}

% 本研究で評価対象とする全てのプロジェクトの修正履歴を学習データとして用いるモデル．
% 図\ref{fig:Teiannsyuhou}の全学習に示すように，学習データ内に存在するすべてのプロジェクトの学習データをすべて学習に使用する予測モデルである．
% 予測対象プロジェクトによらず，一つの予測モデルですべての修正要否を予測する．
% 具体的には，プロジェクトAの修正要否を行う際も，プロジェクトBの修正要否予測を行う際にも，修正要否予測に使用するモデルは同一のモデルが用いられる．

全学習モデルとは，本研究の評価対象とする全てのプロジェクトの修正履歴を学習データとして用いるモデルを指す．
図\ref{fig:Teiannsyuhou}の全学習に示すように，本モデルは特定のプロジェクトに限定せず，学習データ内に存在する全プロジェクトのデータを混合して学習に使用する予測モデルである．
したがって，予測対象となるプロジェクトに関わらず，単一の予測モデルを用いて修正要否を予測する．
具体的には，プロジェクトAおよびプロジェクトBのいずれを予測対象とする場合であっても，修正要否の判定に用いられる予測モデルは同一のものとなる．

本モデルは，学習に大量の修正履歴を用いることが可能であるため，前述の「コールドスタート問題」に対して頑健であるという利点を持つ．
しかし，プロジェクトごとの固有のコーディングスタイルや修正傾向は考慮されない．
例えば，プロジェクトAでは修正傾向にある規約が，プロジェクトBでは修正されない傾向にある場合，これらのデータが混在することで互いのノイズとなる懸念がある．
プロジェクト間で修正傾向が異なる規約が学習データに含まれる場合，予測対象プロジェクトにおいて十分な修正履歴があるプロジェクトでは，予測精度の低下を招く恐れがある．


\subsection{選定学習モデル（欠損値補完なし）}

% 予測対象プロジェクトの修正履歴に加え，当該プロジェクトが設定する規約，およびその修正率が類似するプロジェクトを選定し，その修正履歴も学習データとして用いるモデル．ただし，プロジェクト間で一方のみが設定する規約の場合，他方の修正率は欠損値であり，本モデルでは，そのIDは類似度算出に使わないものとする．（選定方法の詳細は\ref{subsec:選定方法}節参照）

選定学習モデル（欠損値補完なし）とは，予測対象プロジェクトの修正履歴に加え，当該プロジェクトと発生している規約違反の種類と，規約違反に対する修正率が類似するプロジェクトを選定し，それらの修正履歴を統合して学習データとして用いるモデルを指す．
本モデルでは，プロジェクト間での類似度算出に基づき学習データを選定するが，その際の欠損値の扱いには特別な処理を要する．
具体的には，比較するプロジェクト間で一方のみが発生している規約違反が存在する場合，他方のプロジェクトにおける当該規約の修正率は欠損値となる．
本モデルでは，このような欠損値を含む規約IDについては類似度算出の対象から除外するものとする（選定方法の詳細は\ref{subsec:選定方法}節参照）．

本モデルは，予測対象プロジェクトと類似度の高いプロジェクトのみを選定して学習データに加えるため，全学習モデルの懸念点である「修正傾向の異なるプロジェクトの混在によるノイズ」を抑制しつつ，学習データを拡充することが可能である．
しかし，類似するプロジェクトが十分に存在しない場合には，追加の学習データを十分に確保できず，単一学習モデルと同様にコールドスタート問題が発生する恐れがある．

\subsection{選定学習モデル（欠損値補完あり）}

% 選定学習モデル（欠損値補完なし）と同様に予測対象プロジェクトの修正履歴に加え，選定したプロジェクトの修正履歴も学習データとして用いるモデル．
% ただし，欠損値は，欠損値を含むプロジェクトにおいて他の規約における平均修正率で補完する．（選定方法の詳細は\ref{subsec:選定方法}節参照）

選定学習モデル（欠損値補完あり）とは，前述の「欠損値補完なし」のモデルと同様に，予測対象プロジェクトの修正履歴と，選定した類似プロジェクトの修正履歴を組み合わせて学習データとするモデルを指す．
本モデルの特徴は，プロジェクト間で規約違反の発生状況が異なるために生じる欠損値を補完し，類似度を算出した上で学習に利用する点にある．
具体的には，ある規約の修正率が欠損している場合，当該プロジェクトにおける他の規約の平均修正率を算出し，その値で欠損値を補完する（選定方法の詳細は\ref{subsec:選定方法}節参照）．

本モデルでは，欠損値補完を行うことにより，欠損値補完を行わない手法と比較して，より多くの規約違反の種類を用いた厳密な類似度算出が可能となる．
これにより，修正傾向の異なるプロジェクトの混在をさらに抑制できるという利点がある．
その一方で，類似度の判定基準が厳格化されるため，学習データとして採用できる類似プロジェクトが減少する可能性がある．
その結果，欠損値補完を行わないモデルよりも混合するプロジェクトが集まりづらく，単一学習モデルと同様のコールドスタート問題が発生するリスクが高まる懸念点がある．



\section{学習プロジェクトの選定方法}\label{subsec:選定方法}

全学習モデルおよび2種の選定学習モデルでは，予測対象プロジェクトの修正履歴に加え，他プロジェクトの修正履歴を学習データに含めることで正例データを拡張する．
全学習モデルではデータセット内の全プロジェクトを対象とするのに対し，選定学習モデルでは，予測対象プロジェクトと規約の設定状況および修正率が類似するプロジェクトの修正履歴のみを選択的に利用する．

プロジェクト選定にあたっては，各プロジェクトの規約設定状況と規約の種類ごとの修正率を計測し，類似度を算出する．
各規約違反における修正率は，式(\ref{eq:fixrate})によって定義する．

\begin{equation}
\label{eq:fixrate}
\text{修正率} = \frac{\text{同一種類の違反の修正された数}}{\text{同一種類の違反を検出した数}} \quad (0 \le \text{修正率} \le 1)
\end{equation}

本研究において，プロジェクトの選定基準として「規約の設定状況」と「修正率」の類似性を採用した動機を以下に述べる．
まず，規約の設定状況の類似性を考慮することで，開発環境が近いプロジェクトを抽出可能である．
これにより，自プロジェクトとは無関係な規約に基づくノイズの混入を抑制できる．
次に，修正率の類似性を考慮することで，規約違反に対する修正の方針が近いプロジェクトの選定が可能である．
プロジェクト間での修正傾向の不一致は，モデルの学習において互いにノイズとなり，予測精度の低下を招く要因となる．
したがって，これら2つの観点から類似プロジェクトの選定を行う．



\subsection{ジャッカード係数の測定}

\begin{table}[h]
    \centering
    \caption{プロジェクト別規約遵守状況}
    \label{tab:example_sim_table}
    \begin{tabular}{lcccc}
        \hline
         & 規約1 & 規約2 & 規約3 & 規約4 \\
        \hline
        プロジェクトA & 0.70 & 0.25 & 0.40 & 0.20 \\
        プロジェクトB & 0.60 & - & 0.30 & 0.30 \\
        プロジェクトC & - & 0.70 & - & 0.60 \\
        \hline
    \end{tabular}
\end{table}

各プロジェクトが設定する規約の類似度は，本研究で対象とするFlake8で検出可能な規約違反を対象とする．
プロジェクトの規約設定有無（バイナリーデータ）の類似度を判定するためには，ジャッカード係数を用いる．
表\ref{tab:example_sim_table}に，プロジェクトごとの各規約違反に対する修正率の例を示す．
表中の「規約1」は，プロジェクトAでは規約1が0.70の割合で修正されており，プロジェクトBでは0.60の割合で修正されている．
そして，プロジェクトCでは規約1への違反が一度も発生していないため，欠損値が入っている．
プロジェクトAとプロジェクトBのジャッカード係数を計算する場合，発生しているコーディング規約違反のうち，規約2以外が共通して発生しているため，ジャッカード係数は式\ref{eq:jaccard_exm}のように求められる．

\begin{equation}
\label{eq:jaccard_exm}
Jac(A, B) = \frac{3}{4} = 0.75
\end{equation}

\subsection{ユークリッド距離の測定}

プロジェクト間の規約違反に対する修正率（スカラーデータ）の類似度の測定には，ユークリッド距離を用いる．
なお，規約の修正率は，一方のプロジェクトのみが規約を設定している場合，他方のプロジェクトでは欠損値となるため，次の2通りの方法で欠損値補完し，類似度を計測する．

%ユークリッド距離の計算においては，ある規約違反が一度も発生していない場合，修正率が欠損値となる．この場合に備え，以下の2通りの処理を実施する．
\begin{itemize}
    \item 欠損値を計算から除外してユークリッド距離を測定する方法（選定学習モデル（欠損値補完なし））
    \item 欠損値を当該プロジェクトの平均修正率で補完し，ユークリッド距離を測定する方法（選定学習モデル（欠損値補完あり））
\end{itemize}

具体的なユークリッド距離の測定の説明を行うために，表\ref{tab:example_sim_table}中のプロジェクトAとプロジェクトBのユークリッド距離の測定を例に挙げる．
表\ref{tab:example_sim_table}の各値が修正率を示しているため，選定学習手法（欠損値補完なし）の修正率のユークリッド距離は，式\ref{eq:euc_exm}のように求められる．
式中の平方根における第1項は規約1の修正率の差（距離）を示している．
規約2はプロジェクトBでは違反が発生していないため，計算から除外している．
続く2項および3項は，それぞれ規約3，規約4に対する修正率の差を示している．

\begin{equation}
\label{eq:euc_exm}
Euc(A, B) = \sqrt{(0.7 - 0.60)^2 + (0.3 - 0.2)^2 + (0.2 - 0.3)^2}
\end{equation}

最後に，欠損値補完を行う場合のユークリッド距離を算出する方法について説明する．
プロジェクトBでは，規約2が発生していないため，プロジェクトBの他規約の修正率の平均値で補完して計算を行う．
その結果，選定学習手法（欠損値補完あり）の類似プロジェクト分析に利用するユークリッド距離は式\ref{eq:euc_exm2}のように求められる．
式\ref{eq:euc_exm2}では，式\ref{eq:euc_exm}で示した3つの項に加え，新たに第2項として欠損値補完された規約2の修正率に基づく差の計算が追加されている．
このように欠損値補完を用いることで，発生していない規約に対しても距離の計算を行うことが可能である．

\begin{equation}
\label{eq:euc_exm2}
Euc'(A, B) = \sqrt{(0.7 - 0.60)^2 + (0.25 - 0.40)^2 + (0.3 - 0.2)^2 + (0.2 - 0.3)^2}
\vspace{10pt}
\end{equation}

ここで欠損値を平均値で補完しているのは，特定のプロジェクトにおいて発生していない規約は，そのプロジェクトの開発者が設定ファイルで当該規約を無効にしているか，単に出現していないだけかの区別が困難なため，プロジェクト全体の平均的な修正傾向を代入することで近似するためである．

%==================================


%==================================

実験を行う際には，表\ref{tab:example_sim_table}のような修正率の表を全プロジェクトの全コーディング規約に拡張したものを計算し，類似度の計算に利用する．
プロジェクト間でそれぞれの指標が類似するか否かは，実証データに基づき閾値を決定する．
具体的な閾値の決定方法は，ジャッカード係数（0.0から1.0をステップ0.1）とユークリッド距離（1.0から5.0をステップ1.0）のすべての組み合わせ（50種類）に対してグリッドサーチを行い，学習データにおいて最も高い予測精度のものを採用する．

% 修正率を基に，ジャッカード係数とユークリッド距離の2種類の類似度指標を算出し，それぞれに閾値を設定することで，類似度が高いと判断されたプロジェクトのみを学習対象として選定する．


\begin{table}[ht]
    \centering
    \small % フォントサイズを小さくして収まりを良くする
    \renewcommand{\arraystretch}{1.1} % 行間を少し広げて読みやすく
    \setlength{\tabcolsep}{4pt} % 列間の余白を微調整
    \caption{変数一覧と説明}
    \label{tab:variables}
    \begin{tabularx}{\textwidth}{llX} % X列が自動改行・幅調整される
        \toprule
        種類 & 変数名 & 説明 \\
        \midrule
        flake8情報 & Violation ID & 静的解析ツールが検出した違反の種類を示すID（One-hot） \\
        & Category & 違反のカテゴリ（One-hot） \\
        & Violation Line Number & 違反が検出された行番号 \\
        \midrule
        Git情報 & File Change Frequency & ファイルの変更頻度 \\
        & Lines Added Past 25 Revisions & 過去25リビジョンで追加された行数 \\
        & Lines Added Past 3 Months & 過去3ヶ月で追加された行数 \\
        \midrule
        コード特徴量 & File Size & ファイルサイズ（バイト数） \\
        & Total Lines & ファイルの総行数 \\
        & Code Lines & コード行数 \\
        & Comment Lines & コメント行数 \\
        & Blank Lines & 空白行数 \\
        & File Depth & ファイルの階層の深さ \\
        & Filename Length & ファイル名の長さ \\
        & Total Functions & ファイル内の関数数 \\
        & Total Classes & ファイル内のクラス数 \\
        & Total Imports & インポート文の数 \\
        & Total Variables & 変数の数 \\
        & Cyclomatic Complexity & 循環的複雑度（ファイルレベル） \\
        & Line Length & 違反行の長さ（文字数） \\
        & Line Length No Whitespace & 違反行の長さ（空白を除く） \\
        & Indent Level & 違反行のインデントレベル \\
        & Line Complexity & 違反行の複雑度 \\
        & Special Chars & 違反行の特殊文字数 \\
        & Variable Count & 違反行の変数数 \\
        & Function Calls & 違反行の関数呼び出し数 \\
        & Operators & 違反行の演算子数 \\
        & In Function & 違反が関数内にあるかどうか（0/1） \\
        & Function Params & 関数のパラメータ数 \\
        & Function Lines & 関数の行数 \\
        & Function Complexity & 関数の複雑度 \\
        & In Class & 違反がクラス内にあるかどうか（0/1） \\
        & Class Methods & クラスのメソッド数 \\
        & Class Lines & クラスの行数 \\
        \bottomrule
    \end{tabularx}
\end{table}

\section{データセットの収集}



\subsection{対象言語とその選定理由}

検証に使用するプログラミング言語には，Pythonを採用する．
Pythonは，近年，機械学習やデータ分析における需要の高まりを背景に，重要性が増しているためである．
また，Java言語やC言語といったコンパイル言語に比べて，Pythonのようなスクリプト言語はを対象とした研究が少ないことも理由の一つである．

\subsection{検証プロジェクトの選定方法}

\begin{figure}[ht]
    \centering
    \includegraphics[width=1\linewidth]{@Master2025_Kameoka/fig/all_dataset_histogram.pdf}
    \caption{フィルタリング前のプロジェクトごとの規約違反数分布}
    \label{fig:all_dataset_summary}
    \vspace{20pt}

    \centering
    \includegraphics[width=1\linewidth]{@IPSJjournal2025_Kameoka/fig/dataset_size_histogram.pdf}
    \caption{フィルタ条件適用後のプロジェクトごとの規約違反数分布}
    \label{fig:dataset_summary}
\end{figure}

検証に使用するデータセットととして，OSSライブラリ検索サービスであるLibraries.io\footnote{\url{https://libraries.io/}}に登録されているPythonライブラリを用いる．
検証に使用するライブラリの条件としては，以下の条件を満たすものを採用した．

\begin{itemize}
    \item SourceRank上位2,000プロジェクト
    \item Githubでソースコードが公開
    \item 静的解析ツールであるFlake8の設定ファイルを保有
    \item 学習データ，評価データの双方に正例・負例が存在
    \item 規約違反データが500件以上，20,000件以下
    \item 開発リポジトリが重複しているプロジェクトを削除
\end{itemize}

結果として条件を満たした170プロジェクトのデータを検証に使用する．
コーディング規約違反のデータを取得する期間は，2024年1月1日から2024年12月31日までの１年間のコミット履歴を対象とする．

本研究において，対象とする規約違反件数を500件以上かつ20,000件以下に制限した理由は，以下の2点である．

第一に，統計的な評価の信頼性を担保するためである．データセットを学習用とテスト用に分割した際，テスト用データが不足していると，少数のデータが評価指標に過度な影響を及ぼし，結果の安定性が損なわれる懸念がある．
本研究では，データを4対1の比率で分割することを前提とし，テスト用データとして最低限100件を確保するため，全データ数が500件以上であることを条件とした．

第二に，静的解析ツールが実質的に運用されていないプロジェクトを排除するためである．規約違反数が極端に多いプロジェクトは，設定ファイルのみを保持し，実際の開発プロセスではツールのコーディング規約違反を無視している可能性が高い．
図\ref{fig:all_dataset_summary}に示す適用前のプロジェクト数分布を確認すると，違反数20,000件付近を境に分布の不連続性が確認できる．
そのため，解析対象としての妥当性を考慮し，区切りの良い数値である20,000件を上限として設定した．

取得したデータセットの規約違反を図\ref{fig:dataset_summary}に示す．
規約違反の発生量としては，中央値が2,160件で，500件から1,000件のプロジェクトが最も多い．
また正例数と負例数の割合が，中央値で正例数が0.34という負例数が多い不均衡データであった．


\chapter{RQ1: 複数プロジェクトを学習に用いることによって，修正予測精度は向上するか}\label{chap:rq1}

\section{概要}

RQ1では従来手法である単一学習と提案手法である全学習，選定学習（欠損値補完なし），選定学習（欠損値補完あり）との修正要否の予測結果の評価を行う．
また，提案手法によって，従来手法の課題点としてあげていた，学習データの正例数が少ない場合において予測精度が改善するかを明らかにする．
\ref{sec:result_boxplot}節では，選定学習手法の評価を行う際に，主に選定学習手法（欠損値補完あり）について言及し，その理由について\ref{sec:result_ruijinodatou}節にて説明する．

提案手法である選定学習では，プロジェクト間の修正傾向のジャッカード係数とユークリッド距離の閾値を定めることで類似プロジェクトを決定している．
選定学習手法で，学習データに混合しているプロジェクトを分析することで，本研究で提案している，類似プロジェクトの決定方法の妥当性についての分析を行う．

\section{結果}\label{sec:result_boxplot}

\begin{figure}[ht]
	\centering
        % \includegraphics[width=0.25\textwidth, bb=0 0 4 3]{fig/dataset_hist.pdf}
	\includegraphics[width=1\linewidth]{@Master2025_Kameoka/fig/boxplot_general..pdf}
	\caption{4手法による予測結果の箱ひげ図}
	\label{fig:boxplot_summary}
\end{figure}

	% \centering
 %        % \includegraphics[width=0.25\textwidth, bb=0 0 4 3]{fig/dataset_hist.pdf}
	% \includegraphics[width=1\linewidth]{fig/boxplot_filtered.pdf}
	% \caption{選定学習手法（欠損値補完あり）で複数プロジェクトのデータを学習したプロジェクトに絞った予測結果の箱ひげ図}
	% \label{fig:boxplot_filtered}

%---------------------

データセット内のプロジェクト全体の規約違反の修正要否予測の結果を図\ref{fig:boxplot_summary}に示す．
図は左から各手法の予測結果の適合率，再現率，F1値を順に示し，縦軸にその値を示している．
選定学習と選定学習（欠損値補完あり）の2手法では，プロジェクト間類似度の測定の際に，ジャッカード係数とユークリッド距離のそれぞれに閾値を設けている．閾値の決定方法は，ジャッカード係数とユークリッド距離の組み合わせの全50通りの中から，学習データでの予測精度が最も良かった際の値を採用した場合の，評価データでの予測結果を採用している．

結果としては，単一学習の結果と比較して提案手法3種類では，適合率が僅かに改善し，再現率が僅かに悪化する結果となった．
各メトリクスに対して，4手法間の全ての組み合わせでWilcoxonの符合順位検定（有意水準0.05）を行ったところ，全ての組み合わせにおいて，統計的有意差なしの結果となった．

データセット全体のプロジェクトを対象とした検証において，予測精度に顕著な差が見られなかったのは\ref{chap:background}章でも懸念していた通り，本提案手法が本来，学習データの確保が困難なプロジェクトに対する精度向上を主眼として設計したものであることに起因すると考えられる．
また，本研究で使用したデータセットは，ライブラリ検索サービス上で評価の高いライブラリを採用しているため，コーディング規約違反の修正予測を行う学習のための開発データが十分にあるものが多い．
そのため，データセットの大部分を占める正例数の多いプロジェクトでは，単一学習ですでに精度が飽和しており，提案手法の利点が少なく，全体的な結果として有意差が出なかったと考えられる．


\subsection{選定学習手法による予測精度への影響}

\begin{figure}[ht]
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{@IPSJjournal2025_Kameoka/fig/precision_improvement_by_positive_samples.pdf}
    	\caption{選定学習（欠損値補完あり）による適合率の改善度}
    	\label{fig:boxplot_precision_improvement_by_selected}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{@IPSJjournal2025_Kameoka/fig/recall_improvement_by_positive_samples.pdf}
    	\caption{選定学習（欠損値補完あり）による再現率の改善度}
    	\label{fig:boxplot_recall_improvement_by_selected}
    \end{minipage}
\end{figure}

% \begin{figure}[ht]
%     \centering
%     \includegraphics[width=1.0\linewidth]{@IPSJjournal2025_Kameoka/fig/precision_improvement_by_positive_samples.pdf}
%     \caption{選定学習（欠損値補完あり）による適合率の改善度}
%     \label{fig:boxplot_precision_improvement_by_selected}

%     \centering
%     \includegraphics[width=1.0\linewidth]{@IPSJjournal2025_Kameoka/fig/recall_improvement_by_positive_samples.pdf}
%     \caption{選定学習（欠損値補完あり）による再現率の改善度}
%     \label{fig:boxplot_recall_improvement_by_selected}
% \end{figure}

提案手法の効果が顕著であったプロジェクトの分析結果を示す．
図\ref{fig:boxplot_precision_improvement_by_selected}は，提案手法（欠損値補完あり）による適合率の変化量を示した箱ひげ図である．
また，図\ref{fig:boxplot_recall_improvement_by_selected}には，同様の分析を再現率の観点で行った結果を示す．
いずれの図も横軸は，学習データに含まれる正例数に基づき4つの区間に分類している．

これら2つの図から，提案手法（欠損値補完あり）の導入によって，適合率が上昇する一方で再現率が低下する傾向が確認できる．
特に，正例数が100件から500件の範囲において，箱ひげ図の分散が最も大きくなっている．
このことから，正例数が100件から500件のプロジェクトにおいて，提案手法が与える影響が特に大きいと言える．
同様に，欠損値補完を用いない選定学習においても，同様の傾向が見られた．


\subsection{全学習手法による予測精度への影響}

\begin{figure}[ht]
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{@Master2025_Kameoka/fig/all_precision_improvement_by_positive_samples.pdf}
    	\caption{全学習手法による適合率の改善度}
    	\label{fig:boxplot_precision_improvement_by_all}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{@Master2025_Kameoka/fig/all_recall_improvement_by_positive_samples.pdf}
    	\caption{全学習手法による再現率の改善度}
    	\label{fig:boxplot_recall_improvement_by_all}
    \end{minipage}
\end{figure}

% \begin{figure}[ht]
%     \centering
%     \includegraphics[width=1.0\linewidth]{@Master2025_Kameoka/fig/all_precision_improvement_by_positive_samples.pdf}
%     \caption{全学習手法による適合率の改善度}
%     \label{fig:boxplot_precision_improvement_by_all}

%     \centering
%     \includegraphics[width=1.0\linewidth]{@Master2025_Kameoka/fig/all_recall_improvement_by_positive_samples.pdf}
%     \caption{全学習手法による再現率の改善度}
%     \label{fig:boxplot_recall_improvement_by_all}
% \end{figure}

次に全学習手法による，修正予測精度への影響について述べる．
全学習手法での学習データの正例数ごとの適合率の改善度を図\ref{fig:boxplot_precision_improvement_by_all}に示し，再現率の改善度を図\ref{fig:boxplot_recall_improvement_by_all}に示す．
全学習手法の結果からも，選定学習の際と同様に単一学習の結果と比較して適合率が上昇傾向にあり，再現率が低下傾向にあることがわかる．単一学習からの適合率の改善度と再現率の悪化度が，選定学習より変化幅が大きいことがわかる．



\subsection{全学習と選定学習（欠損値補完あり）の予測結果の比較}

\begin{figure}[ht]
    \centering
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{@Master2025_Kameoka/fig/precision_selected_vs_all.pdf}
    	\caption{全学習から選定学習による適合率の改善度}
    	\label{fig:boxplot_precision_improvement_selected_vs_all}
    \end{minipage}
    \hfill
    \begin{minipage}{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{@Master2025_Kameoka/fig/recall_selected_vs_all.pdf}
    	\caption{全学習手法による再現率の改善度}
    	\label{fig:boxplot_recall_improvement_selected_vs_all}
    \end{minipage}
\end{figure}

% \begin{figure}[ht]
%     \centering
%     \includegraphics[width=1.0\linewidth]{@Master2025_Kameoka/fig/precision_selected_vs_all.pdf}
%     \caption{全学習から選定学習による適合率の改善度}
%     \label{fig:boxplot_precision_improvement_selected_vs_all}
    
%     \centering
%     \includegraphics[width=1.0\linewidth]{@Master2025_Kameoka/fig/recall_selected_vs_all.pdf}
%     \caption{全学習手法による再現率の改善度}
%     \label{fig:boxplot_recall_improvement_selected_vs_all}
% \end{figure}

提案手法である，全学習と選定学習（欠損値補完あり）間の修正要否予測結果の比較を行う．
図\ref{fig:boxplot_precision_improvement_selected_vs_all}に，全学習の適合率から，選定学習による適合率の改善度を示す．
図\ref{fig:boxplot_recall_improvement_selected_vs_all}に，全学習の再現率から，選定学習による再現率の改善度を示す．
図から見てとれるように，全学習と選定学習（欠損値補完あり）を比較した場合，全学習の方が適合率の高いプロジェクトが多く，選定学習の方が再現率の高いプロジェクトが多い結果となっている．

ここまでの結果から，全学習と選定学習（欠損値補完あり）では，箱ひげ図の分散に違いはあるものの，改善度合いの分布に大きな違いがないことから，単一学習から適合率が改善するプロジェクトと，再現率が低下するプロジェクトは共通しており，全学習の方が選定学習（欠損値補完あり）と比較して，適合率の改善幅と再現率の低下幅が大きいと言える．
全学習は，大規模なデータ量によってポジティブな傾向を学習できる一方で，ノイズとなってしまうデータも大量に学習するため，判定が厳しくなり，再現率が低下しやすくなったと考えられる．


\section{類似度測定手法の妥当性の評価}\label{sec:result_ruijinodatou}

\subsection{概要}

本研究では，予測対象プロジェクトと類似しているプロジェクトを探すために，ジャッカード係数とユークリッド距離の2種類の値を用いて，類似プロジェクトを決定している．
2種類の値を利用することによって，発生しているコーディング規約違反の種類の類似度と，違反に対する修正率の類似度を測ることができるため，この2種類の値を採用している．
この手法は本研究において提案していものであるので，本説では，実験において実際に類似プロジェクトが収集できているのかを明らかにする．

分析方法として，類似度測定手法を使用している，選定学習（欠損値他なし）と選定学習（欠損値補完あり）で，類似していると判断するためのジャッカード係数とユークリッド距離の閾値を最も厳しくした場合のプロジェクトの混合関係を見ることで，妥当なプロジェクトが収集されて言えるかを確認する．
最も厳しい閾値を採用する理由は，
本研究において最も厳しい閾値は，ジャッカード係数が1，ユークリッド距離が1.0未満の場合である．

\subsection{結果}

\begin{table}[htbp]
    \centering
    \caption{ターゲットプロジェクトと類似プロジェクトの比較}
    \label{tab:merged_projects}
    \begin{tabularx}{\textwidth}{l p{3cm} p{3cm}}
        \toprule
        \textbf{予測対象プロジェクト} & \textbf{選定学習（欠損値補完なし）} & \textbf{選定学習（欠損値補完あり）} \\
        \midrule
        Jinja2 & click & click \\
        click & Jinja2 & Jinja2 \\
        pytest-cov & tmuxp & (なし) \\
        nbconvert & aiortc & (なし) \\
        pelican & apispec, awacs & apispec \\
        pytest-benchmark & aiosmtplib, mcstatus, openai-whisper, xhtml2pdf & (なし) \\
        apispec & awacs, pelican & pelican \\
        aiortc & nbconvert & (なし) \\
        aiosmtplib & mcstatus, openai-whisper, pytest-benchmark, xhtml2pdf & mcstatus, openai-whisper, xhtml2pdf \\
        openai-whisper & aiosmtplib, mcstatus, pytest-benchmark, xhtml2pdf & aiosmtplib, xhtml2pdf \\
        xhtml2pdf & aiosmtplib, mcstatus, openai-whisper, pytest-benchmark & aiosmtplib, mcstatus, openai-whisper \\
        tmuxp & pytest-cov & (なし) \\
        mcstatus & aiosmtplib, openai-whisper, pytest-benchmark, xhtml2pdf & aiosmtplib, xhtml2pdf \\
        awacs & apispec, pelican & (なし) \\
        \bottomrule
    \end{tabularx}
\end{table}

最も閾値を厳しく設定した場合の選定学習で，予測モデルの構築に複数プロジェクトの学習データを利用していたプロジェクトの混合関係を表\ref{tab:merged_projects}に示す．
表中の最も左の列には予測対象プロジェクトを示し，そのプロジェクトと類似していると判断されたプロジェクトのうち，修正率の欠損値補完を行わない手法を二列目，修正率の欠損値補完を行う手法を三列目に示す．

表の結果から欠損値補完を行わない手法のほうが混合プロジェクト数が多いことがわかる．
これは，欠損値補完を行わない選定学習手法の類似度計算時のユークリッド距離の計算時に，どちらかのプロジェクトでしか発生していないコーディング規約違反があった場合，その修正率はユークリッド距離の計算から除外しているため，ユークリッド距離が小さくなり，類似していると判定されることが原因である．

表中のプロジェクト間の混合関係について詳しく評価する．
表の最初の混合関係である，click2とJinja2は互い混合関係にあることがわかる．
これらは共に，Palletsプロジェクトという同一の開発元によって開発・保守されており，コーディングスタイルの共通点が高いプロジェクトとして，選定学習の目的通りに類似プロジェクトが収集できていることがわかる．

欠損値補完を行わない選定学習手法では，（xhtml2pdf，aiosmtplib，mcstatus，openai-whisper，pytest-benchmark）の5プロジェクトが頻繁に互いに混合関係にあることがわかる．
この5プロジェクトのコーディング規約違反の修正履歴を確認したところ，データにはE501という，他プロジェクトでも最も多く発生している，行内の文字数制限に関するコーディング規約違反の他には，数種類のコーディング規約違反しか存在しなかった．
欠損値補完を行わないプロジェクトの類似度測定手法では，発生しているコーディング規約の種類数が少ない場合に，ユークリッド距離が必然的に高くなってしまう傾向にある．
つまり，欠損値補完を行わない選定学習手法において，本来類似していないプロジェクト同士が混合される要因は，計算対象となる次元数が異なる問題に起因する．
具体的には，発生している規約の種類が極めて少ないプロジェクト間では，距離計算に使用される次元数が著しく低下する．
そのため，実際には修正傾向の異なるプロジェクトであっても，共通発生している規約のみにユークリッド距離の計算が行われるため，修正傾向が類似していると判定される．

一方で，欠損値補完を行う類似度測定手法では，混合プロジェクトが少なくなってしまっているが，先述の発生しているコーディング規約違反の種類が少ないことに起因する，予期しないプロジェクトの混合を抑制できていることがわかる．
しかし，aiosmtplibなどの予測においては，以前同様の問題が残ることもわかる．

欠損値補完を用いない類似プロジェクト測定結果と欠損値補完を用いる類似プロジェクト測定結果を比較した際に，本研究で取得したい，コーディング規約違反の種類に対する，修正率の類似するプロジェクトの収集結果として，欠損値補完を用いる方が，目的と近しいため，結果の分析において，欠損値補完を用いる選定学習手法の結果について主に分析する．

% \begin{screen}

% \end{screen}

\section{まとめ}

本章では，コーディング規約違反の修正要否予測における提案手法の有効性を検証した．得られた知見を以下に総括する．

本研究で使用したデータセット全体のコーディング規約違反の修正予測において，従来手法である単一学習と比較して，提案手法である全学習と選定学習（欠損値補完あり）では，適合率のわずかな改善と，再現率の僅かな低下の傾向が見られた．
比較した4手法間では，適合率，再現率，F1値に統計的有意差は見られなかったが，本研究の対象とするプロジェクトがデータが十分に収集できないプロジェクトに焦点を当てているため，この結果は十分想定されていた結果である．

本研究で提案している，予測対象プロジェクト以外のデータを学習に使用する手法が，有効に働くプロジェクトを調査したところ，学習データ内の正例数が100-500件のプロジェクトにおいて，提案手法による精度の変化の影響が最も大きくなることを確認した．

全学習手法と選定学習（欠損値補完あり）の予測結果の比較では，全学習は選定学習（欠損値補完あり）と比較して，適合率の改善幅と再現率の悪化幅が大きいことが明らかになった．
全学習と選定学習の両手法で，予測精度の変化傾向が共通していることから，単一学習では捉えきれない修正要否を他プロジェクトのデータから補完できていることが示唆される．

また，本研究で提案している，選定学習において類似プロジェクトを選定するための類似度測定手法の妥当性の検討も行った．
結果としては，手法の性質上，欠損値補完を用いない手法では，発生しているコーディング規約違反の種類が少ない場合に，予期せぬ混合が発生する問題が確認された．
しかし，欠損値補完を用いる類似度測定手法において，その問題が緩和されていることも確認した．
そのため，本研究の目的である修正率の類似プロジェクトを収集する方法としては，選定学習（欠損値補完あり）の方が適している．

\chapter{RQ2: 予測精度改善に寄与するプロジェクトの属性およびデータ構造の特定}\label{chap:rq2}



\section{概要}

RQ1では，従来手法である単一学習と提案手法との予測結果の比較を行った．
その結果，提案手法の効果が出やすいプロジェクトの条件が明らかになった．
そこで，RQ2では提案手法によって，予測精度に影響の出やすいプロジェクトのうち，提案手法によって予測精度が改善したプロジェクトと悪化したプロジェクトに分割し，それぞれの特徴について分析することで，提案手法が有効に働くプロジェクト特性を明らかにする．
また，提案手法によって予測精度が低下したプロジェクトについても分析し，提案手法によって，予測精度が低下しているか，または，外部要因によって予測精度が悪化しているのかを明らかにする．

\section{分析方法}

提案手法による予測精度への影響が大きい，学習データの正例数が100-500件のプロジェクトのうち，選定学習によって予測精度が改善した群とそうでない群に分割し，特徴の分析を行う．
単一学習と比較する選定学習は，欠損値補完を用いる選定学習を利用する．
また，選定学習によって予測精度が改善したか否かについては，図\ref{fig:boxplot_precision_improvement_by_selected}と図\ref{fig:boxplot_recall_improvement_by_selected}で単一学習から適合率，再現率が改善したプロジェクトと，悪化したプロジェクトで判断する．

分析する内容として，学習データ内に存在するコーディング規約違反の種類の傾向や説明変数をはじめとする，コードメトリクスや学習データ数，正例数，負例数のような数値的なデータの特徴の傾向を分析する．
分析には，マンホイットニーのU検定による統計的有意差の確認と，コーエンのdによる効果量の分析を行うことにより，傾向を明らかにする．
マンホイットニーのU検定を使用する理由は，分析対象である予測結果の改善群と悪化群の分布は正規分布ではないため，t検定ではなく，ノンパラメトリック検定であるマンホイットニーのU検定を採用した．
コーエンのdについては，一般的に用いられる基準（$0.2$で「小」，$0.5$で「中」，$0.8$以上で「大」）に基づき評価を行う．

\section{分析結果}

\subsection{選定学習で予測精度が改善するプロジェクトの特徴}

% \begin{table}[ht]
%   \centering
%   \caption{適合率が改善したプロジェクトで出現する規約違反ID（上位10件）}
%   \label{tab:improve_precision_id}
%   \begin{tabular}{lrr}
%     \hline
%     Violation ID & 出現回数 & 出現プロジェクト数 \\ \hline
%     E501 & 31,124 & 35 \\
%     E231 & 2,846 & 8 \\
%     F401 & 1,054 & 28 \\
%     F405 & 798 & 7 \\
%     E225 & 532 & 5 \\
%     E402 & 525 & 15 \\
%     E128 & 480 & 6 \\
%     E203 & 357 & 22 \\
%     E265 & 300 & 10 \\
%     F841 & 270 & 15 \\ \hline
%   \end{tabular}
%   \vspace{10pt}

%   \centering
%   \caption{適合率が悪化したプロジェクトで出現する規約違反ID（上位10件）}
%   \label{tab:not_improve_precision_id}
%   \begin{tabular}{lrr}
%     \hline
%     Violation ID & 出現回数 & 出現プロジェクト数 \\ \hline
%     E501 & 20,509 & 20 \\
%     E127 & 2,460 & 7 \\
%     E128 & 1,487 & 8 \\
%     F401 & 1,355 & 16 \\
%     E203 & 1,284 & 11 \\
%     W293 & 699 & 5 \\
%     E265 & 587 & 9 \\
%     E302 & 490 & 9 \\
%     E252 & 429 & 2 \\
%     E303 & 420 & 8 \\ \hline
%   \end{tabular}
% \end{table}

\begin{table}[ht]
    \centering
    \caption{適合率が改善したプロジェクトで出現する規約違反ID（上位10件）}
    \label{tab:improve_precision_id}
    \small % 表がはみ出す場合はサイズを調整
    \begin{tabular}{lrr}
      \hline
      Violation ID & 出現回数 & 出現プロジェクト数 \\ \hline
      E501 & 31,124 & 35 \\
      E231 & 2,846 & 8 \\
      F401 & 1,054 & 28 \\
      F405 & 798 & 7 \\
      E225 & 532 & 5 \\
      E402 & 525 & 15 \\
      E128 & 480 & 6 \\
      E203 & 357 & 22 \\
      E265 & 300 & 10 \\
      F841 & 270 & 15 \\ \hline
    \end{tabular}
    
    \centering
    \caption{適合率が悪化したプロジェクトで出現する規約違反ID（上位10件）}
    \label{tab:not_improve_precision_id}
    \small
    \begin{tabular}{lrr}
      \hline
      Violation ID & 出現回数 & 出現プロジェクト数 \\ \hline
      E501 & 20,509 & 20 \\
      E127 & 2,460 & 7 \\
      E128 & 1,487 & 8 \\
      F401 & 1,355 & 16 \\
      E203 & 1,284 & 11 \\
      W293 & 699 & 5 \\
      E265 & 587 & 9 \\
      E302 & 490 & 9 \\
      E252 & 429 & 2 \\
      E303 & 420 & 8 \\ \hline
    \end{tabular}
\end{table}

% \begin{table}[ht]
%   \begin{minipage}[t]{0.48\textwidth}
%     \centering
%     \caption{適合率が改善したプロジェクトで出現する規約違反ID（上位10件）}
%     \label{tab:improve_precision_id}
%     \small % 表がはみ出す場合はサイズを調整
%     \begin{tabular}{lrr}
%       \hline
%       Violation ID & 出現回数 & 出現プロジェクト数 \\ \hline
%       E501 & 31,124 & 35 \\
%       E231 & 2,846 & 8 \\
%       F401 & 1,054 & 28 \\
%       F405 & 798 & 7 \\
%       E225 & 532 & 5 \\
%       E402 & 525 & 15 \\
%       E128 & 480 & 6 \\
%       E203 & 357 & 22 \\
%       E265 & 300 & 10 \\
%       F841 & 270 & 15 \\ \hline
%     \end{tabular}
%   \end{minipage}
%   \hfill % 左右の表の間に適切な空白を入れる
%   \begin{minipage}[t]{0.48\textwidth}
%     \centering
%     \caption{適合率が悪化したプロジェクトで出現する規約違反ID（上位10件）}
%     \label{tab:not_improve_precision_id}
%     \small
%     \begin{tabular}{lrr}
%       \hline
%       Violation ID & 出現回数 & 出現プロジェクト数 \\ \hline
%       E501 & 20,509 & 20 \\
%       E127 & 2,460 & 7 \\
%       E128 & 1,487 & 8 \\
%       F401 & 1,355 & 16 \\
%       E203 & 1,284 & 11 \\
%       W293 & 699 & 5 \\
%       E265 & 587 & 9 \\
%       E302 & 490 & 9 \\
%       E252 & 429 & 2 \\
%       E303 & 420 & 8 \\ \hline
%     \end{tabular}
%   \end{minipage}
% \end{table}

\begin{table}[ht]
  \centering
  \small 
  \caption{プロジェクトの適合率改善状況別の統計比較}
\label{table:positive_sample}
  \begin{tabular}{lrr}
    \toprule
    指標 & \makecell[r]{適合率が改善した\\プロジェクト} & \makecell[r]{適合率が悪化した\\プロジェクト} \\
    \midrule
    平均総サンプル数 & 1147.6 & 1741.2 \\
    中央値総サンプル数 & 853.0 & 1230.5 \\
    平均正例数 & 302.8 & 222.2 \\
    中央値正例数 & 293.0 & 164.5 \\
    平均負例数 & 844.8 & 1519.0 \\
    中央値負例数 & 635.0 & 928.5 \\
    \bottomrule
  \end{tabular}
\end{table}

\begin{table}[ht]
  \centering
  \small
  \caption{プロジェクトの適合率改善状況別の修正率統計}
    \label{table:positive_rate}
  \begin{tabular}{lrr}
    \toprule
    指標 & \makecell[r]{適合率が改善した\\プロジェクト} & \makecell[r]{適合率が悪化した\\プロジェクト} \\
    \midrule
    平均修正率 & 0.344 & 0.225 \\
    中央値修正率 & 0.350 & 0.201 \\
    標準偏差 & 0.169 & 0.157 \\
    最小値 & 0.038 & 0.022 \\
    最大値 & 0.797 & 0.573 \\
    \bottomrule
  \end{tabular}
\end{table}

適合率が上昇している要因を特定するため，提案手法による適合率の変化幅が最も大きかった，正例数が100件から500の範囲にある57プロジェクトに対象を絞り，出現する規約違反IDの種類に着目した詳細な分析を行った．学習データの正例数が100件から500のプロジェクトで，選定学習（欠損値補完あり）によって単一学習から適合率が改善したプロジェクトは，改善が37，悪化が20であった．

まず，適合率が改善したプロジェクト群において最も頻繁に出現する規約は「E501（1行あたりの文字数制限）」であった．しかし，表\ref{tab:improve_precision_id}および表\ref{tab:not_improve_precision_id}の比較から明らかな通り，本規約は適合率が悪化したプロジェクト群においても同様に高い頻度で出現している．E501はソースコードの書式に関する極めて一般的な違反であり，特定のプロジェクト群に固有の性質を示す特徴とは言い難い．

また，その他の規約について検討したところ，複数のプロジェクト間で共通して発生している違反は極めて少数であった．具体的には，共通性が確認された規約であっても，該当するプロジェクト数は最大で2件に留まっている．以上の分析結果から，適合率が向上したプロジェクト群において，規約違反の種類に基づいた明確な共通性を見出すことは困難であった．このことは，適合率の変動が特定の規約違反の傾向に依存するのではなく，プロジェクト固有の要因や他の変数の影響を受けている可能性を示唆している．

適合率が向上した要因を詳細に検討するため，説明変数の差異に着目した分析を行った．適合率が改善したプロジェクト群と悪化したプロジェクト群を対象に，マン・ホイットニーのU検定を用いた有意差検定を実施したところ，「正例数」および「修正率」の2指標において統計的な有意差が確認された．

具体的には，適合率が改善したプロジェクト群は，悪化した群と比較して正例数が有意に多く，かつ修正率も有意に高い傾向にあることが示された．この結果は，モデルの学習において十分な正例数を確保することの重要性と，人間による修正（フィードバック）の密度が適合率の向上に直接的に寄与していることを示唆している．

一方で，データの構成比にも留意すべき点が確認された．正例数そのものの多寡だけでなく，それに対する負例数の多さも適合率に悪影響を及ぼす阻害要因となっている可能性が高い．したがって，単に正例を増やすだけでなく，正負のデータバランスを考慮したデータセットの構築が，適合率を安定的に改善させるための鍵であると考えられる．

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\linewidth]{@Master2025_Kameoka/fig/jaccard_threshold_boxplot.pdf}
    \caption{選定学習のよる適合率改善・悪化プロジェクトのジャッカード係数の箱ひげ図}
    \label{fig:boxplot_jaccard_analitics}
\end{figure}

続いて，図\ref{fig:boxplot_jaccard_analitics}に，学習データの正例数が100-500件のプロジェクトのうち，選定学習（欠損値補完あり）で予測精度が改善した群と，悪化した群で採用しているジャッカード係数の箱ひげ図で示す．
図から見て取れる通り，選定学習手法で適合率が悪化した群は改善した群に比べて採用されているジャッカード係数の閾値が高いことがわかる．
つまり選定学習で適合率の改善するプロジェクトは，類似判定するための閾値を緩め，悪化したプロジェクトと比較し，厳密な類似性よりも学習データの絶対量の確保が優先される傾向にあることが，採用している閾値からも見て取れる．


\subsection{全学習で予測精度が改善するプロジェクトの特徴}

全学習によって単一学習から適合率が改善した学習データの正例数が100件から500のプロジェクトは，改善が40で，悪化が17であった．
改善したプロジェクト数では選定学習より多くのプロジェクトが改善していることがわかる．

選定学習では，学習データの正例数と修正率に，改善と悪化の有意差が確認されたため，全学習においても検証を行った．
学習データの正例数は，改善群と悪化群の分布でマンホイットニーのU検定を行ったところ，p値は0.60で有意差は確認できなかった．
修正率は，改善群と悪化群でマンホイットニーのU検定を行ったところ，0.09で優位さは確認できなかった．
有意差が確認できなかった結果は，全学習ではプロジェクト全体的な適合率の向上によるものと考えられ，選定学習は特定の条件下（正例数や修正率が高い場合）で効果を発揮するのに対し，全学習はより広範なプロジェクトに対して汎用的に作用する可能性が示唆された．

\section{まとめ}

本章では，RQ2として提案手法である複数プロジェクトのデータを学習に用いることで，予測精度に改善が見られるプロジェクトの特徴を明らかにした．

選定学習では単一学習の予測結果と比較して，発生しているコーディング規約の種類に大きな意味は確認できなかったが，学習データ内の正例数と修正率に統計的有意差があることが確認された．
修正率が高いプロジェクトが適合率の改善が見られるため，悪化群が提案手法で適合率が低下している原因として，膨大な数の負例が予測精度を低下させていることが示唆された．
また，選定学習で各プロジェクトごとに採用されているジャッカード係数の閾値を分析した結果，悪化群では，高い閾値が採用される傾向にあったため，広範囲にデータを学習に取り入れる方法が有効であることが考えられる．

全学習の分析結果では，選定学習で確認された正例数と修正率に改善群と悪化群で有意差が確認されなかった．
全学習では，選定学習より多くのプロジェクトで適合率の改善が見られた．
そのため，選定学習で示唆された，高品質なデータの質より大規模なデータの混合量を学習に取り入れる方針が，効果的に予測精度を改善できることが示唆される結果となった．


\chapter{RQ3: 提案手法によりコーディング規約違反の種類ごとに予測精度は変化するか}\label{chap:rq3}

\section{概要}

本研究が提案する，学習データに予測対象プロジェクト以外の修正履歴を学習に用いることにより，コーディング規約の種類ごとに予測精度がどのように変化するかを分析する．
予測結果の変遷を分析することにより，単一学習と比較して，複数プロジェクトのデータを用いるべきコーディング規約の種類の条件の分析を行う．



\section{分析方法}

RQ1で提案手法による影響を受けやすいことがわかっている，学習データの正例数が100件から500件のプロジェクトの予測結果を，コーディング規約の種類ごとに集計し，正解率の変遷を調査する．
調査対象とするコーディング規約の種類は，データセット内の複数のプロジェクトで検出されている違反であり，違反の発生数が200件以上のコーディング規約とする．
発生している違反数を200件以上としている理由は，数件しか発生していないコーディング規約では，少数の違反の予測結果で正解率の値が大きく変化してしまうため，分析結果の信憑性が損なわれる恐れがある．
そのため，本調査では一定数以上の違反数を持つコーディング規約の種類に限定した調査を行う．

\section{結果}

% \begin{figure}[ht]
% 	\centering
% 	\includegraphics[width=1.0\linewidth]{@Master2025_Kameoka/fig/warning_id_accuracy.pdf}
% 	\caption{手法別規約種類ごとの正解率}
% 	\label{fig:barplot_warningid}
% \end{figure}

\begin{table}[ht]
    \centering
    \caption{コーディング規約違反の種類ごとの学習手法の比較}
    \label{tab:barplot_warningid}
    \small % 表が横に長くなるため、文字サイズを少し調整
    \begin{tabular}{lcccccccc}
        \toprule
        & \multicolumn{3}{c}{正解率} & & \multicolumn{3}{c}{F1値} \\
        \cmidrule{2-4} \cmidrule{6-8}
        規約違反ID & 単一学習 & 全学習 & 選定学習 & & 単一学習 & 全学習 & 選定学習 \\
        \midrule
        E501 & 0.7356 & \bf{0.7741} & 0.7569 & & 0.4825 & 0.4856 & \bf{0.4919} \\
        E128 & 0.7192 & \bf{0.8229} & 0.7290 & & 0.1257 & \bf{0.1275} & \bf{0.1275} \\
        E231 & 0.6180 & \bf{0.6504} & 0.6214 & & 0.2091 & 0.1537 & \bf{0.2161} \\
        E127 & 0.7376 & \bf{0.8115} & 0.7326 & & \bf{0.3139} & 0.3009 & 0.2946 \\
        E203 & 0.7380 & \bf{0.7878} & 0.7363 & & \bf{0.1717} & 0.1638 & 0.1626 \\
        F401 & 0.8643 & 0.8316 & \bf{0.8691} & & 0.1333 & 0.0394 & \bf{0.1484} \\
        F405 & 0.6274 & 0.6206 & \bf{0.7472} & & 0.4702 & 0.4651 & \bf{0.5519} \\
        E111 & \bf{0.9545} & 0.8864 & \bf{0.9545} & & \bf{0.2250} & 0.1667 & \bf{0.2250} \\
        E402 & 0.8455 & 0.8918 & \bf{0.8929} & & 0.1250 & 0.1324 & \bf{0.1389} \\
        E225 & 0.5921 & 0.5930 & \bf{0.7055} & & 0.3471 & 0.2186 & \bf{0.3481} \\
        E261 & \bf{0.8234} & 0.7779 & 0.8061 & & \bf{0.3381} & 0.1321 & 0.2566 \\
        E302 & 0.5834 & 0.5676 & \bf{0.6042} & & \bf{0.1312} & 0.0858 & 0.1311 \\
        F841 & 0.7740 & 0.6438 & \bf{0.7977} & & \bf{0.3393} & 0.1825 & 0.3294 \\
        F821 & \bf{0.7601} & 0.6616 & 0.6919 & & \bf{0.3657} & 0.2778 & 0.3051 \\
        E303 & 0.5417 & \bf{0.7398} & 0.5880 & & 0.2446 & \bf{0.3027} & 0.2317 \\
        E721 & 0.6626 & \bf{0.7505} & 0.6646 & & 0.3446 & 0.3338 & \bf{0.3457} \\
        W291 & 0.5877 & \bf{0.7515} & 0.5877 & & 0.0357 & \bf{0.0762} & 0.0357 \\
        E502 & 0.6500 & \bf{0.8885} & 0.6462 & & \bf{0.1544} & 0.1349 & 0.1493 \\
        \bottomrule
    \end{tabular}
\end{table}

% \begin{table}[ht]
%   \centering
%   \caption{各学習手法において正解率が最大値となった規約種類数}
%   \label{tab:max_accuracy_projects}
%   \begin{tabular}{lr}
%     \toprule
%     学習手法 & 規約種類数 \\
%     \midrule
%     単一学習 & 2 \\
%     全学習 & 6 \\
%     選定学習（欠損値補完あり） & 7 \\
%     \bottomrule
%   \end{tabular}
% \end{table}

表\ref{tab:barplot_warningid}に学習データの正例数が100件から500件のプロジェクトの，手法別のコーディング規約の種類ごとの正解率とF1値を示す．
表のコーディング規約の種類は，発生件数の多いコーディング規約から降順に並んでいる．
また，表中のそれぞれの規約の種類において，最も予測精度が高かった手法の正解率を太字で示す．

正解率が最大値を取ったコーディング規約の種類数は，重複を許して単一学習では3種類，全学習では9種類，選定学習（欠損値補完あり）では7種類であった．
コーディング規約別の予測結果では，全学習が最も多い規約の種類で正解率の最大値を取る結果となった．
一方F1値の変化は，正解率の変化と比較して小さい．
特に単一学習と，選定学習の間では，多くの規約でF1値の差が5ポイント以下である．

例えば`E128'の結果では，正解率が単一学習から全学習によって正解率が10ポイント増加しているが，F1値の変化は1ポイント未満である．
このような結果はコーディング規約の修正データが，負例が多い不均衡データであることに起因する．
`E128'の予測結果は，提案手法によって，予測可能な正例数に大きな変化は見られなかったが，True Negativeの件数が増加していた．
つまり，複数プロジェクトのデータを学習に使用する提案手法は，単一学習と比較して，修正されないコーディング規約違反を，適切に修正不要と予測可能な傾向にある．


\subsection{3手法間のコーディング規約ごとの正解率の評価}

予測対象プロジェクト内のすべてのコーディング規約違反の修正要否予測結果を見ると，発生しているコーディング規約違反の大多数を占める`E501'の予測結果に大きな影響を受ける．
学習データ内の正例数が100件から500件以内のプロジェクトにおいても，`E501'は最も多い40,098件発生しており，次に多い`E128'は2,193件しか発生しておらず，約18倍の差がある．
そのため，予測結果の変化幅が小さく見られた．
しかし，表\ref{tab:barplot_warningid}の結果が示す通り，コーディング規約別の結果を見ると，`E111'と`F821'以外のコーディング規約の種類では，全学習と選定学習の方が多くの規約で高い正解率をとっている．
つまり，提案手法である学習データに予測対象以外の修正履歴を混合する手法は，発生頻度の低いコーディング規約の修正要否予測において，正解率を改善させる．

次に全学習と選定学習間の予測結果の比較を行う．
全学習手法によって単一学習から，`E303'の正解率が19ポイント上昇している一方で，`F841'では，単一学習から正解率が13ポイント低下している．
選定学習では，単一学習から最も正解率が改善した規約は`F405'で，単一学習から12ポイント改善している．
改善幅では選定学習より，全学習の方が大きい．
しかし，選定学習は単一学習より正解率が劣っているコーディング規約が`F821'のみであり，その他規約については，同じ正解率か，選定学習の方が優れている．


\subsection{正解率が変化するグループごとの分析}

\begin{table}[ht]
    \centering
    \caption{グループ別のコーディング規約違反発生プロジェクト数}
    \label{tab:violation-groups}
    \begin{tabular}{lrr}
        \toprule
        グループ & コーディング規約の種類 & 発生プロジェクト数 \\
        \midrule
        グループ1 & E111 & 3 \\
                & E261 & 5 \\
               & F821 & 9 \\
        \midrule
        グループ2 & E501 & 57 \\
               & E128 & 12 \\
               & E231 & 11 \\
               & E127 & 9 \\
               & E203 & 23 \\
               & E303 & 16 \\
               & E721 & 9 \\
               & W291 & 7 \\
               & E502 & 4 \\
        \midrule
        グループ3 & F401 & 29 \\
               & F405 & 4 \\
               & E402 & 13 \\
               & E225 & 9 \\
               & E302 & 17 \\
               & F841 & 14 \\
        \bottomrule
    \end{tabular}
\end{table}

表\ref{tab:barplot_warningid}の結果を，正解率が最大値を取った手法ごとにコーディング規約の種類を3つのグループに分割する．
分割後のグループを表\ref{tab:violation-groups}にまとめる．
表中のグループ1は単一学習，グループ2は全学習，グループ3は選定学習で正解率が最も高い値をとったコーディング規約のグループである．
発生プロジェクト数は，学習データの正例数が100件から500件のプロジェクト中で，当該コーディング規約への違反が発生しているプロジェクトの数を示す．
各グループごとの発生プロジェクト数の中央値は，グループ1では5.0，グループ2では12.0，グループ3では13.5である．
統計的な有意差を示すものではないが，傾向として提案手法によって予測精度が改善したグループ2とグループ3は，グループ1と比較して発生プロジェクト数が多い．
つまり，提案手法によって正解率が改善するコーディング規約の種類は，混合するプロジェクトのデータ内にも同種類のコーディング規約に対する修正履歴が多く含まれているコーディング規約である．
混合するプロジェクト数が多いほど，コーディング規約違反の修正要否予測精度が向上する結果は，RQ2で適合率の改善条件の分析を行った結果とも一致する．

\section{まとめ}

本節では，コーディング規約違反の種類ごとに，提案手法による予測精度の変化を分析した．
学習データの正例数が100件から500件のプロジェクトにおける，18種類のコーディング規約違反に対する予測結果を分析した結果，以下の知見が得られた．

コーディング規約別の予測結果では，全学習が最も多い9種類の規約で正解率の最大値を取り，選定学習が7種類の規約で最大値を取った．
一方，単一学習が最大値を取った規約は3種類のみであった．
特に，`E111'と`F821'以外のコーディング規約の種類では，全学習と選定学習の方が多くの規約で高い正解率をとっており，提案手法は発生頻度の低いコーディング規約の修正要否予測において，正解率を改善させることが明らかになった．

次に，正解率が最大値を取った手法ごとにコーディング規約を3つのグループに分割して分析した結果，提案手法によって予測精度が改善したグループは，単一学習が最も高い正解率を示したグループと比較して，発生プロジェクト数の中央値が大きいことがわかった．
つまり，提案手法によって正解率が改善するコーディング規約の種類は，混合するプロジェクトのデータ内にも同種類のコーディング規約に対する修正履歴が多く含まれているコーディング規約である．
この結果は，RQ2で分析した適合率の改善条件と一致しており，複数プロジェクトのデータを学習に使用する提案手法は，混合するプロジェクト内に同種類の修正履歴が多く存在するコーディング規約において，特に効果的であることが示された．

一方，F1値の変化は正解率の変化と比較して小さく，特に単一学習と選定学習の間では，多くの規約でF1値の差が5ポイント以下であった．
これは，コーディング規約の修正データが負例が多い不均衡データであることに起因し，提案手法は修正されないコーディング規約違反を適切に修正不要と予測する能力を向上させる傾向にあることが明らかになった．


\chapter{考察}\label{chap:consideration}

\begin{figure}[ht]
	\centering
    \begin{minipage}{0.45\textwidth}
        \centering
    	\includegraphics[width=\textwidth]{@IPSJjournal2025_Kameoka/fig/precision_similar_projects_count_boxplot.pdf}
    	\caption{適合率が変化したプロジェクト混合プロジェクト数}
    	\label{fig:precision_similar_projects_count_boxplot}
    \end{minipage}
    \hfil
    \begin{minipage}{0.45\textwidth}
        \centering
    	\includegraphics[width=1\textwidth]{@IPSJjournal2025_Kameoka/fig/recall_similar_projects_count_boxplot.pdf}
    	\caption{再現率が変化したプロジェクト混合プロジェクト数}
    	\label{fig:recall_similar_projects_count_boxplot}
    \end{minipage}
\end{figure}

\section{類似プロジェクトの集約による学習データの不均衡緩和と適合率向上}

学習データを混合した結果，正例数が少ない（100件から500件程度）プロジェクトにおいて，提案する選定学習手法により適合率が改善することが確認された．
この精度の改善をもたらした主要な要因は，類似プロジェクトの集約による「学習データ量の確保」と，それに伴う「正例・負例の不均衡の緩和」にあると考えられる．

図\ref{fig:precision_similar_projects_count_boxplot}は，学習データの正例数が100件から500件の範囲にあるプロジェクトを対象とし，適合率が向上した群と低下した群に分けた際の，混合プロジェクト数に関する箱ひげ図である．
同様に，図\ref{fig:recall_similar_projects_count_boxplot}には再現率に関する結果を示す．

適合率の変動について分析を行ったところ，改善群と悪化群の間で，混合したプロジェクト数にマン・ホイットニーのU検定（有意水準0.1）による有意差が見られた．
この結果は，単一プロジェクトの履歴のみでは不足していた学習データを，他プロジェクトから補完することの有効であることを裏付けている．
再現率についてもp値は0.0994であり，有意差が確認された．
更に，コーエンのdは1.009と非常に高い効果量を示した．
これは，予測精度が低下したプロジェクトにおいては，学習に寄与する類似プロジェクトを十分に収集できなかったことが精度の改善を阻んだ要因であることを示唆している．

しかし，単一学習と比較して単にプロジェクト数を増やすだけでは，対象プロジェクトの特性とは異なるノイズとなるデータも混入し，適合率が低下する．
本手法で適合率が向上した理由は，提案した類似度指標（ジャッカード係数およびユークリッド距離）によって，対象プロジェクトと「規約の選定傾向」および「修正判断の基準（修正率）」が近いプロジェクトを選択的に収集できた点にある．
これにより，対象プロジェクトの開発方針に合致した「質の高い正例データ」を機械的に混合することが可能となった．

一般に，コーディング規約違反のデータセットは，修正されない違反（負例）が多数を占め，実際に修正される違反（正例）が3割程度に留まる不均衡の問題を抱えている．
正例が極端に少ない状態では，モデルの学習が正常に行われず，判定精度が低下する．
本手法によって，予測対象プロジェクトとコーディング規約違反に対する修正履歴の類似性の高いプロジェクトから大量の正例データを混合できたことで，学習データにおける正負の比率が緩和され，不均衡が改善された．
このプロセスにより，モデルが「修正すべき違反」に共通する特徴をより精緻に学習できるようになり，結果として適合率の有意な向上に寄与したものと推察される．


\section{コーディング規約の種類による提案手法による予測結果への影響}

表\ref{tab:violation-groups}の結果から，複数プロジェクトの修正履歴を混合する提案手法は，複数プロジェクトで共通して発生しているプロジェクトで予測結果が向上する傾向が見られた．
しかし，`E502'や`F405'では発生プロジェクト数がグループ1の規約と同程度であるが，正解率が提案手法によって10ポイント以上上昇している．
`E502'と`F405'の規約違反内容を以下に示す．

\begin{itemize}
    \item E502：コードの括弧内に不必要なバックスラッシュが存在する
    \item F405：from module import \textbackslash* を使用している
\end{itemize}

`E502'に定義される，括弧内のバックスラッシュはPython言語において構造的に不必要である．
他言語においては，括弧内のバックスラッシュは構造的に必要な場合があるが，Python言語においては構造的に不必要である．
`F405'に定義される，Python言語において，モジュールから全ての関数をインポートするスターインポートは，モダンな開発では推奨されていない．
これは，利用しない関数やクラスがインポートされることで，名前空間の衝突や定義不一致の原因となるため，推奨されていない．
これらの規約違反は，開発者によるコーディングスタイルの違いによらず，コードの可読性を低下させる要因である．
つまり，`E502'や`F405'は，共通して発生しているプロジェクト数は，単一学習の方が高い正解率であった規約と同程度であるが，修正傾向がプロジェクトによらず共通しており，提案手法によって正解率が向上したと考えられる．

次に，他規約と同程度のプロジェクトに存在する規約であるが，提案手法によって正解率が向上しなかった規約について考察する．  
表\ref{tab:violation-groups}の結果から，正解率が提案手法によって改善しなかった規約は`E111'，`E261'，`F821'である．
`E111'．`E261'．`F821'の規約違反内容を以下に示す．

\begin{itemize}
    \item E111：インデントのスペースの数が4の倍数でない
    \item E261：インラインコメントの前には最低2つのスペースが必要である
    \item F821：定義されていない変数名の参照をしている
\end{itemize}

`E111'に定義される，インデントのためのスペース数は，Python言語では4の倍数であることを推奨している．
しかし，コードベースが古い場合や，標準ではない特定のコードスタイルに準拠している場合，プロジェクトによってはインデントにスペースの数を2の倍数に設定することがある．
`E261'に定義される，インラインコメントの前にスペースが2つ必要である規約は，放置していてもエラーにならず，コメントであるため，コードの可読性にも直接影響しない重要度の低いコーディング規約である．
そのため，`E261'の修正は周辺コードの修正に併せて修正されることが多く，プロジェクト間で修正傾向が異なると考えられる．
`F821'に定義される，定義されていない変数名の参照は，バグのように見えるが，メタプログラミングの副作用により，静的解析ツールがコーディング規約への違反であると検出してしまう．
例えば，フレームワークの利用によって，当該ファイルに定義されていない変数であっても安全に使用することが可能であり，このような事例は修正する必要がない違反である．
つまり，`F821'は常に修正する必要がある規約ではないため，プロジェクトによって修正傾向が異なると考えられる．
以上の結果から，提案手法によって正解率が向上しなかった規約は，プロジェクトによって修正傾向が異なる規約であり，提案手法によって正解率が向上しなかったと考えられる．


\section{提案手法は大規模言語モデルより優れた修正要否予測が可能か}

Pythonの静的解析ツールの検出結果の修正要否予測において，大規模言語モデルが利用できるかを調査した．
大規模言語モデルを用いた修正要予測を行うにあたって，従来研究を基に近似実験を行う\cite{LLMで分類}．
従来研究では，対象言語にJavaを選択しており，対象とする静的解析によるエラーも2種類のみに絞っている．
そのため，本研究で検証を行う際には，対象言語をPythonに変更し，対象アラートもFlake8をカバーできるようにプロンプトを変更した．
予測に使用するプロンプトをListing\ref{prompt:analysis}に示す．
プロンプトには，従来研究で予測精度が最も高かったFew-shotを利用する．
利用する大規模言語モデルには，Openai社のGPT-5 miniを利用する．
GPT-5 miniはGPT-5と比較して，生成精度は低下するものの，従来研究で使用されているGPT-4とGPT-3.5 Turboより高い精度で生成が可能であるため，より低コストで利用可能なGPT-5 miniを利用する．
また，修正要否の予測結果と同時に大規模言語モデルには，その判定結果となった理由も出力させる．

検証に使用するプロジェクトはデータセットから，学習データの正例数が100件から500件のプロジェクトで，修正履歴に存在するしコーディング規約違反の種類が多いものから5プロジェクトを採用する．
検証に使用するプロジェクトは`awscli'，`meson'，`py-cord'，`Telethon'，`gseapy'の5プロジェクトである．
検証には，プロジェクトのデータを学習用とテスト用に4:1の割合で分割したテストデータのみを検証に用いる．

\begin{table}[t]
  \centering
  \caption{大規模言語モデルによる規約違反修正要否予測精度の比較}
  \label{tab:project-metrics}
  \begin{tabular}{lrrrrrr}
    \toprule
    プロジェクト名 & 規約違反数 & 正例数 & 負例数 & 予想正例数 & 予想負例数 & 正解率 \\
    \midrule
    awscli   & 693 & 107 & 586 & 683 & 10 & 0.16 \\
    meson    & 213 & 105 & 108 & 210 & 3  & 0.50 \\
    py-cord  & 223 & 101 & 122 & 220 & 3  & 0.46 \\
    Telethon & 420 & 74  & 346 & 354 & 66 & 0.26 \\
    gseapy   & 312 & 122 & 179 & 292 & 20 & 0.41 \\
    \bottomrule
  \end{tabular}
\end{table}

表\ref{tab:project-metrics}に大規模言語モデルによる，コーディング規約違反修正要否予測の結果の概要を示す．
表の結果から，予想正例数が予想負例数に比べて非常に多いことがわかる．
正解率の高いプロジェクトは，正例数の占める割合が高いプロジェクトであり，プロジェクトごとに予測精度が変化する結果は見られない．
本来，規約違反の修正要否は，放置される方が多いため，大規模言語モデルは開発現場におけるコーディング規約違反への対象方法を捉えられていない．

大規模言語モデルによる予測結果を目視により確認したところ，大規模言語モデルが負例（修正する必要がない）と判定する規約違反には共通性が見られた．
大規模言語モデルが，負例と予測できた規約違反は，全て`E501'という種類の規約に関する修正要否予測のみであった．
大規模言語モデルによる修正要否予測結果の理由を目視したところ，`E501'の中でも文字数が超過しているコンテキストが，docstringやコメントである場合に大規模言語モデルは，その違反を負例と予測していた．
docstringとはPython言語でクラスや関数，モジュールなどのコードに記述する，コードの目的や処理内容を説明するための文章である．
つまり，大規模言語モデルはコメントの文字数超過以外のコーディング規約違反を全て修正が必要と判定する．


大規模言語モデルがコメントの文字数超過以外のコーディング規約違反を，修正が必要と予測する要因の考察として，大規模言語モデルは，一般的なコーディング規約（PEP 8等）の知識を豊富に持ち，実開発における「あえて修正しない」というプロジェクト固有の判断が困難であり，True判定に著しく偏る（高再現率・低適合率）と考えられる．
しかし，この判定結果では開発者のレビューコストの削減にはつながらず，本研究の趣旨と一致していない結果である．
そのため，静的解析ツールの検出結果の修正要否分類には大規模言語モデルの利用より，従来通りの機械学習モデルを利用した予測が適切であることが示唆される．


\begin{lstlisting}[caption=Prediction Prompt, label=prompt:analysis]
You are an experienced Python developer. Analyze the warnings reported by the static analysis tool (flake8) and determine whether the code actually needs to be fixed.

Let's look at some examples:

---

Example 1:
Q: Look at this code. flake8 is reporting "E501: line too long (120 > 79 characters)".

```python
def process_data(data):
    if data is not None:
        return data.value
    return None
```

A: This warning should be fixed. The line exceeds the maximum length limit recommended by PEP 8. To improve code readability, the long line should be split.
Answer: TRUE

---

Example 2:
Q: flake8 is reporting "F401: 'os' imported but unused". What do you think about this code?

```python
import os
import sys

def main():
    print(sys.argv[0])
```

A: Looking at the code, the `os` module is imported but never actually used. Unused imports clutter the codebase and should be removed.
Answer: TRUE

---

Example 3:
Q: There's a warning "E501: line too long (95 > 79 characters)". How would you judge this?

```python
# This is a very long comment that explains the complex algorithm used in this function
def complex_function():
    pass
```

A: In this case, the long line is a comment. Long comment lines are often acceptable in real-world development, and flake8 can be configured to ignore them. Since there's no functional issue, this doesn't need to be fixed.
Answer: FALSE

---

Now, analyze the actual code:

File: {warning.file_path}
Line number: {warning.line_number}
Violation ID: {warning.violation_id}
Violation message: {warning.violation_message}

Problematic code:
```python
{warning.code_snippet}
```

Surrounding context:
```python
{warning.context}
```

Q: Regarding this code, flake8 has reported a warning "{warning.violation_id}: {warning.violation_message}". Should this warning actually be fixed, or is it acceptable to ignore?

A: [Please respond in the following format]
- Write "TRUE" if the warning should be fixed, and explain why.
- Write "FALSE" if the warning can be ignored, and explain why.
\end{lstlisting}



\chapter{妥当性への脅威}\label{chap:heuristic}



\section{内的妥当性}

目的変数の計測において，コーディング規約に違反しているコードが修正された場合と，削除された場合を修正としてとらえ，正例として計測している．
コーディング規約違反の中には，単純に削除するのみで解消されるエラーが存在するため，削除も正例と計測している．
しかし，コーディング規約に違反しているコードが単に不要になり削除された場合も正例と計測している．
コードの移動に関してもGitHubの仕様上，削除と追加という扱いになるため，コードの移動によってコーディング規約に違反しているコードが正例として計測されている可能性がある．

本研究で用いた機械学習アルゴリズム以外にも，より正確な予測を可能にするアルゴリズムが存在する可能性がある．
しかし，本研究において検証した，予測対象プロジェクト以外のデータを学習に使用する手法は，少量の学習データを他プロジェクトのデータで補完する手法であるため，他の機械学習アルゴリズムによる予測を行う際でも効果的に働くと考えられる．
それぞれの機械学習モデルのパラメータの更新回数である，イテレーション回数を10,000に設定したが，データサイズが大きいプロジェクトではモデルが収束しないことが確認された．モデルが収束しない場面も確認されたが，本研究で主に用いた実験環境とは別の環境で，複数回実行した場合でも予測結果に変化はなかったので，モデルが収束しない問題に関しては，本研究の結果に対して大きな影響を与える可能性は低い．

LLMの予測精度はプロンプトの設計（Prompt Engineering）に大きく依存するため，本研究で使用したFew-shotプロンプトがLLMの性能を最大限に引き出しているとは限らない．

\section{外的妥当性}

本研究では検証対象としてPython言語を主な開発言語とした，170件のGithubリポジトリを収集して検証を行った．
そのため，プロジェクト数をさらに拡張した場合や，対象とするプロジェクトや期間を変更した場合に予測精度が変化することが示唆される．
対象言語をPython以外の言語とした場合や，検証対象の静的解析ツールを変更した場合，予測結果が変化することが示唆される．
しかし，本研究で利用したデータセットは，データ数の平均値が4,264であり，十分なデータ数を確保できているため，データ数を拡張することによる予測精度の低下の可能性は低いと考えられる．
また，選定学習においては，より類似度の高いプロジェクトを混合できるため，更なる予測精度の向上が見込める．

\chapter{おわりに}\label{chap:end}

本研究では，静的解析ツールによって検出される膨大な規約違反コードの中から，修正が必要なものを自動分類する手法の改善に取り組んだ．
特に，単一プロジェクトでの学習データ不足に起因するコールドスタート問題を解消するため，他プロジェクトの修正履歴を動的に混合して学習する手法を提案し，その有効性を多角的に検証した．

実験を通じて得られた一つ目の知見は，プロジェクト横断的な学習データの活用が，従来手法におけるコールドスタート問題を解消可能である点である．
全学習及び選定学習のいずれの手法においても，単一プロジェクトのみを対象とした場合と比較し，適合率の改善が見られた．
この傾向は学習データ内の正例数が100件から500件程度のデータを持つプロジェクトにおいて顕著であり，本手法がデータ不足を補完し，予測モデルの安定化に寄与することを示している．

二つ目に，提案した選定学習手法における精度向上の傾向を明らかにした．
適合率の改善したプロジェクト群の分析結果から，類似プロジェクトをより広範囲に集約したケースほど改善幅が大きいことが判明した．
これは，規約の種類や修正率の類似性に基づき選定されたプロジェクトから，修正傾向が類似する正例が大量に供給された結果，学習データにおける正例・負例の不均衡さが緩和されたためであると考えられる．
本研究の結果は，厳密な類似性に基づく選別以上に，不均衡さを改善するための十分な正例データの確保が，予測精度の改善において大きな要因であることを示唆している．

さらに，大規模言語モデルとの比較実験を通じて，本手法の独自性と時y津陽できな優位性を確認した．
汎用的な致死位に基づき「過剰修正」を促す傾向にある大規模言語モデルに対し，本手法は過去の修正履歴を学習データとしている．
これにより，コーディング規約違反を修正しないという現状のの判断基準を反映した，現実的な修正要否予測が可能であることを示した．

以上の結果から，本研究の貢献は，複数プロジェクトの履歴混合が，修正履歴の不均衡さを緩和し，判定精度を向上させることを定量的，定性的に実証した点にある．
特に，開発現場の履歴に基づいた「現実的かつ文脈依存的な修正予測」の有効性を示したことは，静的解析ツールの実運用におけるノイズ削減と開発効率の向上に向けた重要な知見である．
本研究が提示した手法は，リソースの限られた開発初期段階のプロダクトにおいても高精度な品質管理を実現する補助となり，同分野の研究の進展に寄与するものある．

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%
%% 謝辞
%%

%\begin{acknowledgements}
%感謝します．
%\end{acknowledgements}


\bibliographystyle{junsrt}
\bibliography{@Master2025_Kameoka/references}


\end{document}
