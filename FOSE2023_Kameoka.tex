% 英文で執筆する場合はクラスファイルへのオプションを[T,E]としてください．
% If you want to write your paper in English, pass to [T,E] options to document class.
\documentclass[T,J]{fose} % 「コンピュータソフトウェア」用のクラスファイルは compsoft です．
\taikai{2023} % 固定です．出版委員長が毎年変更してAuthor Kitを配布してください．

\usepackage [dvipdfmx] {graphicx}

% ユーザが定義したマクロなどはここに置く．ただし学会誌のスタイルの
% 再定義は原則として避けること．

% 以下は説明のために使用したパッケージであるため，削除可能．
\usepackage{fancyvrb}
\usepackage{url}
\usepackage{cite}
\usepackage{color}
\usepackage{graphicx}
\usepackage{multirow}
% \usepackage{threeparttable} 上手いこと使えない
% \usepackage[dvipdfmx]{color} クラッシュしていてなくても動くのでコメントアウト


\newcommand{\todo}[1]{\colorbox{yellow}{{\bf TODO}:}{\color{red} {\textbf{[#1]}}}}
\newcommand{\wrote}[1]{\colorbox{green}{{\bf Wrote}:} {\textbf{[#1]}}}


\begin{document}

% 論文のタイトル
\title{複数プロジェクト開発履歴を用いた修正を要する\\規約違反ソースコード予測の試み}
% 以下の \etitle（と\@etitle）はFOSE論文フォーマット独自のマクロです．
% FOSEに投稿した論文を発展させてコンピュータソフトウェアに投稿される場合はコメントアウトしてください．
% \setetitleは奇数ページのヘッダに表示する文字列（\etitle）を設定するためのマクロです．
% タイトルが2行に渡る場合は "\\" を 使用することで任意の位置で改行をすることができます．
\setetitle{Toward Predicting Coding Violations Fixing using Multiple Project Dataset}
%\setetitle{Long Long Long Long Long Long \\ Long Long Long Long Long \\ Long Long Long Long Long Long Long Long Long Long Long Long Paper Title}

% タイトル，著者などが複数行にわたり，論文冒頭の著者名が日本語アブストと重複して描画された場合に以下のコメントアウトを外してください．
\longtitle

% 著者
% 和文論文の場合，姓と名の間には半角スペースを入れ，
% 複数の著者の間は全角スペースで区切る
%
\author{亀岡 令　伊原 彰紀　大森 楓己
%
% ここにタイトル英訳 (英文の場合は和訳) を書く．
% 英語タイトルは論文1ページ目左下，著者らの名前・所属一覧の一番上に表示される
%
% 上記\setetitle中で改行した場合は "\etitle" を削除し，改行(\\)を入れていないタイトルを記載してください．
% \ejtitleは1ページ目左下に挿入されるタイトルとして使用されます．
% また，"\etitle"はFOSE論文フォーマット独自のマクロです．
\ejtitle{\etitle}
%
% ここに著者英文表記 および
% 所属 (和文および英文) を書く．
% 複数著者の所属はまとめてよい．
%
% 複数著者の所属は以下のようにまとめてよい．
\shozoku{Ryo Kameoka, Akinori Ihara, Fuki Omori}{和歌山大学}
{Wakayama University}
}

%
% 和文アブストラクト
% In English paper, content of Jabstract will be ignored. 
\Jabstract{%
複数の開発者が参画するソフトウェア開発では．開発者は可読性，保守性の向上のために静的解析ツールを用いて，コーディング規約に違反しているソースコードを検出し，修正に取り組む．しかし，静的解析ツールは規約違反の指摘漏れを抑えるため，大量の規約違反を出力し，その大半を開発者が修正していないことが知られている．従来研究では，規約違反を検証するプロジェクトの過去の修正履歴を学習したモデルを構築し，静的解析ツールの検出結果の中で優先的に修正すべき規約違反ソースコードを予測する手法を提案している．本研究では，従来研究において単一プロジェクトの学習によって十分に学習できない規約違反を，複数プロジェクトのデータの学習により多様な規約違反を予測可能なモデルを構築する．10件のOSSプロジェクトを対象に実験を行った結果，データセットの小さなプロジェクトに対して，本手法が有効であることを確認した．
}
%
% 英文アブストラクト（本サンプルの原論文にはなし）
% \Eabstract{
% \todo{英語アブスト(最後})
% }
%
\maketitle \thispagestyle {empty}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{はじめに}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

複数人で実装するソフトウェア開発では，開発者間のコーディングスタイルを共通化することにより，他の開発者，および将来の開発において，ソースコードの可読性を高め，ソフトウェア保守が容易になることが知られている\cite{EffectsSAT}．コーディングスタイルを共通化するための方策として，各プログラミング言語ではソースコードを記述するためのガイドラインとしてコーディング規約を提供している．具体的には，Java言語のJavaコーディング標準，PythonはPEP8などがある．これらコーディング規約には命名規則やコメント文などに関するルールが定められいる．

従来研究では，コーディング規約の導入により，ソフトウェア開発プロジェクトにとってソースコード理解の促進，バグの早期発見などに効果があることが示されている．
% \todo{\cite{}\cite{}\cite{}}．
% M. Beller, G. Gousios, and A. Zaidman, “How (much) do developers test?,” In Proceedings of the 37th International Conference on Software Engineering (ICSE’15), vol.2, pp.559\UTF{2013}562, 2015.
% B. Johnson, Y. Song, E. Murphy-Hill, and R. Bowdidge, “Why don’t software developers use static analysis tools to find bugs?,” In Proceedings of the 35th IEEE/ACM International Conference on Software Engineering (ICSE’13), pp.672\UTF{2013}681, 2013.
% M. Beller, R. Bholanath, S. McIntosh, and A. Zaidman, “Analyzing the state of static analysis: A large-scale evaluation in open source software,” IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER’16), vol.1, pp.470\UTF{2013}481, 2016.
コーディング規約に従って実装されているか否かの判定には，多くのプロジェクトで静的解析ツールが用いられている．静的解析ツールは，ソースコードを実行することなく，ソースコード中に含まれるコーディング規約違反している箇所，バグを検出することができ，継続的インテグレーションの一つとして使用されることが多い．開発者は，静的解析ツールが検出した規約違反を修正することでプロジェクトの実装方針に従った共通のコーディングスタイルで実装することができる．しかし，多くのプロジェクトでは，規約違反の指摘漏れを抑えるために規約違反の判定基準を厳しく設定しており，静的解析ツールは大量の規約違反を出力し，開発者はその多くを修正していないことが課題とされている．このような静的解析ツールの誤検出を防ぐための研究が数多く発表されている．

従来研究では，機械学習や深層学習を用いることによって，大量に検出されたコーディング規約違反の中から優先して修正すべき違反とそうでない違反の2値に分類している．静的解析ツールの検出結果をトリアージする研究は数多く行われているが，予測精度が低いことや安定していないことが問題点として存在する．この問題点の原因の一つとして，従来研究の機械学習モデルの構築方法として，予測するプロジェクトと同じプロジェクトを学習データとしているのでデータセットサイズや，修正される違反の割合が少ない場合に十分な学習ができずに予測精度が下がってしまうことが考えられる．

単一プロジェクトでは，一部の規約の発生，および修正が少ないため十分な学習データを確保できない．不具合予測，プログラム自動修正などの研究では，データ不足，コールドスタート問題への対応として，異なるプロジェクトの開発履歴を用いることで学習データを補う手法が提案されている．同一プロジェクトのデータの方がプロジェクトの実装方針が同一のため，異なるプロジェクトの開発履歴を用いるよりも高い精度が得られることが知られている．

本研究では，複数プロジェクトの開発履歴を用いて，修正を要する規約違反ソースコードを特定する手法を提案し，評価する．具体的には複数プロジェクトの学習データセットをどのように使うかを提案する．別々のプロジェクトをすべて結合して用いるのではなく，結合したものをクラスタリングすることによって，類似性のある説明変数を持つデータ集めることで，類似性という秩序の下で学習モデルを作成することによって予測精度への影響を明らかにする．

結果の概要として，検証に使用した10プロジェクトの内2プロジェクトで予測結果のF1値を確認した．しかし，提案手法のクラスタリングを行って作成したデータセットより，結合しただけのデータセットを用いた場合のほうが，従来手法より多くの場合高いF1値で修正優先度の予測ができた．

つづく\ref{sec:background}章では，本研究の位置付け，および従来研究を述べる．\ref{sec:approach}章では，提案手法の詳細な学習データの作成方法や機械学習モデルの作成方法の説明を行う．\ref{sec:result}章では，従来手法と提案手法および提案手法を用いずにすべての学習データを結合したものをそれぞれ学習データとした修正優先度予測を行い，手法ごとのモデルの精度および予測内容の分析を行った結果を示す．\ref{sec:consideration}章では，結果に基づく考察を行い，\ref{sec:heuristic}章では本研究の妥当性への脅威について述べ，\ref{sec:end}章でまとめる．



%オープンソースソフトウェアなどの複数人で開発が行われる場合において，開発者は，ほかの開発者や後の自分が理解しやすいようにプログラムのソースコードを適切に記述する必要がある．ソースコードを適切に記述するためのガイドラインとして「コーディング規約」が存在する．コーディング規約は，プログラミング言語ごとに存在し，開発者はこれに従って開発を進めることで可読性を高め，保守性も高めることができる．実際の開発現場で，ソースコードのどの部分がコーディング規約に違反しているかを手作業で確認することは困難であり，非効率的である．そこでソフトウェアの開発・テスト・修正の開発サイクルで頻発しがちな問題を解決するためのツールであるCIツールの一環として静的解析ツールが用いられる．静的解析ツールプログラムを実行することなく，中に含まれるバグやゴーディング規約に対する違反を検出することができる．
%静的解析ツールを用いる際の問題点として，検出される警告が大量に存在することと，検出結果の中には多くの誤検出を含んでいることが従来からの問題点として存在する．また，真の警告であっても，実際の開発現場で修正される違反は一部であり，その大多数は修正されない状態が現状である．

% 従来研究では，機械学習や深層学習を用いることによって，大量に検出されたコーディング規約違反の中から優先して修正すべき違反とそうでない違反の２値に分類している．静的解析ツールの検出結果をトリアージする研究は数多く行われているが，

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{コーディング規約と静的解析ツール}\label{sec:background}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{コーディング規約違反の検出}

コーディング規約は，ソフトウェア開発プロジェクトが，ソースコードの可読性や保守性の向上を目的に，コーディングスタイルを共通化するためのルールとして使用される．規約には，ソースコードの構造から命名規則などのコーディングスタイルについて，禁止事項，制限事項，推奨事項などがルールとして含まれる．各プログラム言語がそれぞれ推奨とするコーディング規約を提供している．Java言語はJavaコーディング標準，Google Java Style Guide，C言語はMISRA-C，CERTコーディングスタンダード，C++はMISRA-C++，PythonはPEP8などを提供している．共同開発する組織は，それぞれの方針に合わせてプログラム言語別に推奨されるコーディング規約を適宜拡張して使用している．

%コーディング規約は，ソースコードの可読性や保守性の向上を目的に，ソースコードの実装方法を定めたルールとして使用される．規約には，ソースコードの構造から命名規則などのコーディングスタイルについて，禁止事項，制限事項，推奨事項などがルールとして含まれる．複数人で同一のソフトウェアを実装する場合には，コーディング規約に遵守することで，実装方法を共通化することができる．各プログラム言語がそれぞれ推奨とするコーディング規約を提供している．Java言語はJavaコーディング標準，Google Java Style Guide，C言語はMISRA-C，CERTコーディングスタンダード，C++はMISRA-C++，PythonはPEP8などを提供している．共同開発する組織は，それぞれの方針に合わせてプログラム言語別に推奨されるコーディング規約を適宜拡張する．

コーディング規約には検出漏れを防ぐために多数のルールがあり，開発者がコーディング規約を違反しているソースコードを目視や手動で発見することは困難である．コーディング規約に従って実装されているか否かの判定には，多くのプロジェクトで静的解析ツールの使用を推奨している\cite{}．
% M. Beller, R. Bholanath, S. McIntosh, and A. Zaidman, “Analyzing the state of static analysis: A large-scale evaluation in open source software,” IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER’16), vol.1, pp.470\UTF{2013}481, 2016.
静的解析ツールは，ソースコードを実行することなく，規約違反しているソースコードを網羅的に検出することができる．コーディング規約と同様に，各プログラミング言語ごとに規約違反するソースコードを検出する静的解析ツールが存在する．JavaはCheckStyle，PMD，FindBugs，C言語はQAC，CX-Checker，Python言語はflake8，JavaScript言語はESLintなどがある．静的解析ツールは低コストで導入できるため，多くの組織で導入されている\cite{UsingStaticAnalysisTools1}\cite{UsingStaticAnalysisTools2}．


%コーディング規約には検出漏れを防ぐために，多数のルールを含むため，開発者がコーディング規約を違反しているソースコードを目視で発見することは困難である．規約違反するソースコードを自動検出するために，開発組織では静的解析ツールの使用を推奨していることが多い．静的解析ツールは，ソースコードを実行することなく，規約違反しているソースコードを網羅的に検出することができる．コーディング規約と同様に，各プログラミング言語ごとに規約違反するソースコードを検出する静的解析ツールが存在する．JavaはCheckStyle，PMD，FindBugs，C言語はQAC，CX-Checker，Python言語はflake8，JavaScript言語はESLintなどがある．静的解析ツールは低コストで導入できるため，多くの組織で導入されている\cite{UsingStaticAnalysisTools1}\cite{UsingStaticAnalysisTools2}．


%ソースコードの可読性向上や保守，管理の観点からコーディング規約に従ったソースコードを記述することが求められる．コーディング規約とは，複数人で同一タスクやプロジェクトを行う際にソースコードに関するルールについてまとめたものである．コーディング規約には，改行や変数の名前に関するルールのようなプログラムの構造から命名規則まで様々なものが含まれる．
%しかし，数多くのルールが存在するコーディング規約がある中で，ソースコード中から開発者が自ら網羅的にコーディング規約違反該当コードを探索することは困難である．そのため，自動静的解析ツールが用いられる．自動静的解析ツールは，プログラムを実行することなく，ソースコード中に含まれるコーディング規約違反コード断片を網羅的に検出することができる．

\subsection{静的解析ツールの問題点}

静的解析ツールは効率的に規約違反を検出できる一方で，多くのプロジェクトは静的解析ツールが定義する膨大な規約違反の検出ルールを変更することなく利用していることが多いため，静的解析ツールが多量の規約違反を検出することが多い~\cite{}．
% M. Beller, R. Bholanath, S. McIntosh, and A. Zaidman, “Analyzing the state of static analysis: A large-scale evaluation in open source software,” IEEE 23rd International Conference on Software Analysis, Evolution, and Reengineering (SANER’16), vol.1, pp.470\UTF{2013}481, 2016.
その結果，検出された規約違反の多くは，開発者によって修正されないままとなり，修正しない規約違反は静的解析ツールの誤検出として取り扱われている．このように膨大な規約違反の中から優先的に修正する規約違反を特定は，開発者の実装経験，組織の慣習の理解が必要であり，容易な作業ではない\cite{HowFar}\cite{shuseisarenai}．優先的に修正する規約違反の特定に向けて，多くの従来研究が機械学習モデルなどを用いて優先的に修正すべき規約違反を特定する手法を提案，検証している．


% コーディング規約には規約違反の検出漏れを防ぐために多数のルールを含むため，静的解析ツールを使用時に多数の規約違反を出力することが多い．その結果，開発者は全ての規約違反を修正することはなく，開発者が修正しない規約違反は静的解析ツールの誤検出として取り扱う．このように膨大な規約違反の中から優先的に修正する規約違反を特定は，開発者の実装経験，組織の慣習の理解が必要であり，容易な作業ではない\cite{HowFar}\cite{shuseisarenai}．従来研究では，静的解析ツールが検出したコーディング規約違反に対して，，および優先的に修正すべき規約違反の特定手法に関する従来研究も多数存在する．




%静的解析ツールの特徴として，大量の誤検出が発生することが従来の研究から問題とされている\cite{HowFar}．そのため，自動静的解析ツールで検出された場合でも，すべての検出内容について修正が必要ではなく，検出されたものの中から修正が必要なものを選んで修正する必要がある．

%\subsection{自動解析ツールを用いた開発の問題点}
%静的解析ツールが正しくコーディング規約に違反しているコード断片を検出した場合にも，開発者が実際に修正を行うことは少ないことが従来研究によって明らかにされている\cite{shuseisarenai}．このことから，自動静的解析ツールによって検出された大量の誤検出を含む内容から，開発者が優先して修正するものを選ぶことは開発者にとって大きな負担となる．


%\section{従来修正予測の手法との比較}
\subsection{従来手法}
静的解析ツールの誤検出による開発効率の低下を防ぐために，Ruthruffらは機械学習モデルを用いて優先的に修正されるコーディング規約違反するコード断片の特定手法を提案している\cite{JyuraiPre}．その他，ベイジアンネットワークと静的解析ツールを用いてコーディング規約に違反しているコード断片の修正優先度を予測する手法を提案している\cite{beizu}．これらのように静的解析ツールによって検出された結果に対して優先度順位付けを行う研究は数多く行われいる．機械学習モデルの構築では，特定のプロジェクトの分析対象期間中に検出された規約違反の修正履歴を用いて機械学習モデルを構築している．分析対象期間中の古い時期の記録を学習データ，新しい時期の記録を検証データとしてモデルを評価している．本研究では，Ruthruffらの従来研究と同様に，ソースコードの特徴量などを説明変数として使用し，規約違反しているコード断片を修正する優先度が高いか否かを予測する2クラス分類モデルを構築すいる．


%自動静的解析ツールを利用した開発が抱える問題を解決するために，Ruthruffらは機械学習を利用したコーディング規約違反コード断片修正優先度予測を行っている．\cite{JyuraiPre}その概要は，リビジョンごとのソースコードの変更量や，特徴量，コーディング規約の種類などを説明変数とすることによって，機械学習モデルを構築し，違反該当コードの修正優先度が高い / 低いの二値に分類し予測している．ここで，予測モデルの構築に用いる学習データは，予測対象のプロジェクトの予測機関の前部分を学習データとし，残り部分をテストデータとすることで，モデルの評価を行っている．

% ソースコードの差分や特徴量を説明変数として機械学習を用いた修正優先度予測を行っている研究は多く存在し，モデルの構築方法を工夫することによって予測精度の向上を図っている．

従来手法では，特定のプロジェクトにおける過去の開発履歴を学習データとして，未来の規約違反の修正を予測するモデルを構築している．機械学習モデルを取り扱う上で評価データと同一のプロジェクトの開発履歴を使用することが良いとされている．しかしPanichellaの研究では規約の種類によって規約違反の修正率，修正数が大きく異なることを示している\cite{}，その結果，規約違反を修正されるコード断片（正例），規約違反を修正されないコード断片（負例）の数が不均衡となり，機械学習モデルの予測性能が低下することが示唆される．
% S. Panichella, V. Arnaoudova, M. Di Penta, and G. Antoniol, “Would static analysis tools help developers with code reviews?,” IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering (SANER’15), pp.161\UTF{2013}170, 2015.
本研究では，学習データに評価対象とは異なるプロジェクトの開発履歴も使用することにより，違反回数の少ない規約であったとしても特定することができると考える．著者らの知る限り，異なるプロジェクトの開発履歴を用いて修正を要する規約違反ソースコードを特定する手法は確認していない．学習データを増やすことで修正する規約違反のコード断片の特定精度の向上が期待できる．その一方で，組織に応じて実装や違反に対する修正の慣習が異なるため，異なる組織の開発履歴が予測精度の低下を招くことも考えられる．この問題を解決するために，本研究では検証対象とするソースコードと類似する特徴量を有する異なる組織の規約違反を学習する方法を提案する．




% 同一プロジェクトであれば実装の慣習が同じであるため高い予測精度が期待されるが，違反回数の少ない規約は十分な学習ができず，予測精度の低下が示唆される．また，違反本研究では，他のプロジェクトの開発履歴も用いることにより，違反回数の少ない規約であったとしても特定することができると考える．著者らの知る限り，異なるプロジェクトにおける開発履歴を用いて修正を要する規約違反ソースコードを特定する手法は提案されていない．%\todo{以降，殴り書きで書いてるけど，ここが一番大事}
% 開発データが増えることで修正を要する規約違反ソースコード特定の精度向上が期待される．その一方で，組織に応じて実装や違反に対する修正の慣習が異なるため，異なる組織の開発履歴が予測精度の低下を招くことも考えられる．この問題を解決するために，本研究では検証対象とするソースコードと類似する特徴量を有する異なる組織の規約違反を学習に使用する．


%従来手法は，修正予測を行うプロジェクトと同じプロジェクト内のデータを学習データとしているので，例えばコーディング規約の種類によって修正の特徴がある場合，その特徴を捉えることで高い精度で修正予測ができることが考えられる．しかし，発生回数の少ないコーディング規約の場合は，十分な学習ができずに予測精度が低下することがデメリットとして考えられる．また，機械学習を利用しているので，学習データが小さい場合に高い精度が得られないというデータセットサイズに依存する課題も抱えている．



%\subsection{アプローチ\todo{XX手法と書きたい}}


%本研究では，従来手法の課題を解決するために修正予測できなかったものを修正予測することを目的とする．キーアイデアとして，機械学習モデルの学習に用いる学習データを，他プロジェクトのコーディング規約違反修正履歴を用いて補完することによって，モデルの予測精度が向上することを期待する．デメリットとして挙げた，学習データサイズに精度が依存すること，コーディング規約の種類によって精度が低下することをキーアイデアによって解決する．

%他プロジェクトのデータによって機械学習モデルの学習データの補完を行うが，すべてのコーディング規約違反の修正に関するデータを無秩序に結合た学習データをそのままモデルに学習してしまうと，プロジェクトごとに存在する予測に有効な修正に関する特徴が大多数のデータによって打ち消されてしまうことが考えられる．そこで，結合した学習データをクラスタリングすることによって，説明変数が似ているデータを集め，各クラスタごとに学習モデルを作成することによって，大多数のデータに修正の特徴が消されないように学習を行う．

%提案手法の有効性を確かめるために，RQ1として従来手法で予測できなかったコーディング規約違反コード断片は，他のプロジェクトのデータを結合した学習データのどのクラスタに含まれているのかを明らかにする．ここで予測できなかったデータが予測するプロジェクト内で少数のクラスタに属するものであった場合，他プロジェクトで学習したほうが予測できることの一つの要因となる．RQ2では提案手法のクラスタごとに学習モデルを作成し，従来手法の予測結果との精度と比較することによって提案手法の有効性を明らかにする．

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{修正を要する規約違反ソースコードの特定手法}\label{sec:approach}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{概要}
%------------
\begin{figure}[t]
	\centering
	\includegraphics[width=1.0\linewidth]{Kameoka_fig/teiannsyuhou.pdf}
	\caption{提案手法の流れ}
	\label{fig:Teiannsyuhou}
\end{figure}
%------------

図\ref{fig:Teiannsyuhou}は，本研究の提案手法の概略図を示す．本研究では，違反回数の少ない規約であったとしても特定するために，評価対象プロジェクトに加えた複数のプロジェクトの開発履歴を使用することで学習データを拡大する．さらに，規約違反に対する修正の慣習が異なるプロジェクトの開発履歴を用いることによる予測精度の低下を防ぐために，コード断片の特徴量が類似する規約違反しているコード断片をクラスタリングする．各クラスタでそれぞれ予測モデルを構築する．クラスタリングでは，学習データと検証データを統合し，両データのの説明変数に基づき分類することで，検証データが類似する規約違反するコード断片によって生成された機械学習モデルで予測を行えるようにする．
% \todo{言い回しがくどい．}．
予測モデルの構築には各クラスタの学習データのみ使用する．
% \todo{文章が図中のどこに対応しているかは書いたほうがよさそう．}

% 学習データに評価対象とは異なるプロジェクトの開発履歴も使用することにより，違反回数の少ない規約であったとしても特定することができると考える．著者らの知る限り，異なるプロジェクトの開発履歴を用いて修正を要する規約違反ソースコードを特定する手法は確認していない．学習データを増やすことで修正する規約違反のコード断片の特定精度の向上が期待できる．その一方で，組織に応じて実装や違反に対する修正の慣習が異なるため，異なる組織の開発履歴が予測精度の低下を招くことも考えられる．この問題を解決するために，本研究では検証対象とするソースコードと類似する特徴量を有する異なる組織の規約違反を学習する方法を提案する．

% 提案するモデル構築の流れとして，図\ref{fig:Teiannsyuhou}のように，複数プロジェクトの学習データセットを一つに結合し，それぞれのコーディング規約の違反データをクラスタリングを行い，作成されたクラスタごとにそれぞれ機械学習モデルを作成し，修正優先度予測を行う．

\subsection{学習データと評価データの収集}

本研究では，機械学習モデルの構築において複数のプロジェクトの開発履歴を統合するが，全てのプロジェクトが学習データと評価データの両方に含まれるように各々の開発履歴を分割した後，統合する．学習データと検証データの分割割合は，各プロジェクトの分析対象期間に発生するコミットのうち，前半8割を学習データ，後半2割を検証データとし，各プロジェクトにおいて未来のデータを含まないために交差検証を行わない．
%ここで，学習データとテスト用データを交差検証を行わない理由は，データセットには，時系列が存在しており，ランダムに学習データとテストデータを分割した場合，学習データに未来の情報を含んでしまうため，データセットの分割時にシャッフルは行わない．

\subsection{説明変数の計測方法}

%-------------------------
\begin{figure}[t]
	\centering
	\includegraphics[width=1.0\linewidth]{Kameoka_fig/mokutekihensu.pdf}
	\caption{目的変数の計測方法}
	\label{fig:mokutekihensu}
\end{figure}
%-------------------------

本研究では，分析対象期間中のコミット全てに静的解析ツールを実行し，コーディング規約に違反しているコード断片がはじめて検出されたコミットで説明変数を計測する．
%機械学習モデルの学習，テストに用いる説明変数の計測方法について説明する．まず，説明変数の計測地点について，計測地点はコーディング規約に違反しているコードが生成されたリビジョンである．
図\ref{fig:mokutekihensu}は，説明変数と目的変数の計測例を示す．この例では，コーディング規約への違反が3箇所で検出され，上2つはリビジョン1で発生し，下の1つはリビジョン2で発生しており，それぞれのリビジョンにおいて説明変数を計測する．説明変数の計測地点において，コーディング規約に違反しているコード断片を含むソースコードファイルの関数，クラス，モジュールに対して特徴量を計測する．本研究では，ソースコードの特徴量を静的解析ツールUnderstandを使用する．説明変数は，従来研究で使用される特徴量
% \todo{コード行数，コメント行数，循環的複雑度，ネストの深さの最大値など含むソースコードに関する特徴量をX個，コーディング規約の違反検出時に得られる規約違反IDをOne-hotベクトル化した特徴量をX個．．．，合計X種類，44個}
を使用する．

\subsection{目的変数の計測方法}

本研究では，分析対象期間中に修正されるか否かを目的変数とする．分析対象期間中に修正された規約違反のコード断片と修正されなかった規約違反のコード断片は表\ref{tab:pos_neg}に示すように正例と負例の2クラスに分類する．
% 図\ref{fig:mokutekihensu}の例を，本分類に従うと上2つは\todo{...}，下1つは\todo{．．．}となる．

%----------------------
\begin{table}[t]
    \centering
    \caption{正例と負例の分類}
    \label{tab:pos_neg}
    \scalebox{0.8}{
    \begin{tabular}{l|l}
         \hline
            分類 & 説明\\ \hline
            負例 & コーディング規約の違反が放置されている\\
            負例 & コーディング規約に違反していたコードが削除された\\
            正例 & コーディング規約に違反していたコードが修正され\\
         \hline
    \end{tabular}
    }
\end{table}
%----------------------

% %-------------------------
% \begin{itemize}
%     \item コーディング規約の違反が放置されている：負例
%     \item コーディング規約がなくなっている
%     \begin{itemize}
%         \item コーディング規約に違反していたコードが削除された：負例
%         \item コーディング規約に違反していたコードが修正された：正例
%     \end{itemize}
% \end{itemize}
% %-------------------------

\subsection{規約違反しているコード断片のクラスタリング}

本研究では，説明変数の特徴量が類似する規約違反しているコード断片をクラスタリングしたのちに，各クラスタに分類されたコード断片の学習データを用いてモデルを構築する．クラスタリングには，クラスタ間の類似度を確認するため階層的クラスタリングを用いる．
% \todo{本当に確認する？}
また，階層的クラスタリングにおける，クラスタ間の距離はユークリッド距離を用い，クラスタの連結法にはWard法を用いる．また，本研究ではクラスタ数を5, 10, 15, 20の４段階に分けて検証を行う．階層クラスタリングにおける，枝切りの場所を変化させることによって，従来手法で予測できなかった修正予測が可能であるかを検証する．
% \todo{最後の1文は考察で書きたい．}


\subsection{機械学習モデルの構築と評価}

予測モデルの構築には，
% \todo{従来研究と同様に？}
ロジスティック回帰モデルを用いる．本研究で取り扱うコーディング規約に違反しているコード断片は，修正されることが少なく不均衡なデータとなっている．したがって，本研究ではロジスティック回帰分析にはPythonパッケージであるsklearnのlinear\_model.LogisticRegression\footnote{https://scikit-learn.org/stable/modules/generated/\\sklearn.linear\_model.LogisticRegression.html}を使用し，パッケージのオプションclass\_weightsを使用することで2クラスデータの分類に重み付けし，不均衡による問題を解決する．

予測モデルの予測性能を評価する指標として，従来研究で用いられている適合率，再現率，F1値，成果率を使用する．機械学習モデルの予測結果は以下の4つに分類することができ，分類結果に基づき各評価指標を算出する．
% \todo{TPなどの定義はいらないかも．}
\begin{itemize}
\item True Positive（TP）： 修正された規約違反に対して，修正されると正しく予測するケース
\item False Positive（FP）： 放置された規約違反に対して，修正されると誤って予測するケース
\item True Negative（TN）：放置された規約違反に対して，放置されると正しく予測するケース
\item False Negative（FN）：修正された規約違反に対して，放置されると誤って予測するケース
\end{itemize}
%また，データセットの学習データとテストデータの分割の割合は，リビジョンごとのデータの前8割を学習用データとし，後2割をテスト用データとして用いる．ここで，学習データとテスト用データを交差検証を行わない理由は，データセットには，時系列が存在しており，ランダムに学習データとテストデータを分割した場合，学習データに未来の情報を含んでしまうため，データセットの分割時にシャッフルは行わない．

%クロスプレディクションを行う際に用いる学習データは，従来手法でも用いたデータセットの前8割をクラスタリングし，それぞれのクラスタに属しているものをそのクラスタの機会学習モデルの学習データとすることによって，クラスタごとのモデル構築を行う．


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{評価実験}\label{sec:result}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{データセット}
%------------
\begin{table*}[t]
    \centering
    \caption{分析対象プロジェクトの統計量}
    \label{datasetTB}
    \scalebox{1.0}{
    \begin{tabular}{l|r|r|r|r|r}
         \hline
         \multirow{2}{*}{プロジェクト名} & \multirow{2}{*}{対象リビジョン数} & \multicolumn{1}{c|}{違反修正数} & \multicolumn{1}{c|}{違反放置数}& \multicolumn{1}{c|}{総違反数} & \multicolumn{1}{c}{違反修正率} \\ 
                      &               &\multicolumn{1}{c|}{(正例)} & \multicolumn{1}{c|}{(負例)} &&\\ \hline
         \hline %
python-bugzilla & 243 & 189 & 183 & 372 & 51\%\\
python-cloudant & 657 & 269 & 1299 & 1568 & 17\%\\
pynput & 507 & 431 & 3595 & 4026 & 11\%\\
pyscard & 380 & 681 & 2705 & 3386 & 20\%\\
howdoi & 593 & 721 & 434 & 1155 & 62\%\\
hickle & 245 & 920 & 1293 & 2213 & 42\%\\
transitions & 496 & 1182 & 2620 & 3802 & 31\%\\
OWSLib & 422 & 1547 & 3080 & 4627 & 33\%\\
schema\_salad & 564 & 1990 & 3009 & 4999 & 40\%\\
schematics & 524 & 6950 & 4829 & 11779 & 59\%\\
         \hline
    \end{tabular}
    }
\end{table*}
%------------

本研究ではケーススタディとして，Libraries.io\footnote{Libraries.io: \url{https://libraries.io/}}からPythonで実装され，静的解析ツールPylintを開発に使用しているプロジェクトを対象とする．当該プロジェクトの中でstar数が上位の100プロジェクトから，コーディング規約違反の修正割合が高い10プロジェクト（transitions, schematics, schema\_salad, python-bugzilla, python-cloudant, pyscard, pynput, OWSLib, howdoi, hickle）を対象とする．全てのプロジェクトがGitHubによってソフトウェア，および開発履歴を公開している．本研究では，各分析対象プロジェクトにおいて，2018年12月から1,000日間のコミット履歴を分析対象とする．表\ref{datasetTB}は，各プロジェクトに関する開発履歴の統計量を示す．本研究では，コーディング規約違反の修正割合が高いプロジェクトを選定しているが，修正割合はプロジェクトによって大きく異なる．

\subsection{結果}

本研究では，学習データに評価対象とは異なるプロジェクトの開発履歴も使用することにより，違反回数の少ない規約であったとしても特定するモデルを構築する．本手法の有効性を評価するために3種類のモデルを構築し，比較する．
\begin{itemize}
\item \textbf{従来手法}：評価対象プロジェクトと同じプロジェクトの開発履歴を学習するモデル
\item \textbf{本手法（クラスタリングなし）}：評価対象プロジェクトを含めた10プロジェクトの開発履歴を学習するモデル
\item \textbf{本手法（クラスタリングあり）}：評価対象プロジェクトを含めた10プロジェクトの開発履歴を，説明変数が類似するクラスタに分割し，それぞれのクラスタで学習するモデル
\end{itemize}

%--------------------
\begin{table*}[t]
    \centering
    \caption{予測結果}
    \label{PrevPrediction}
    \begin{tabular}{l|ccc|ccc|ccc}
         \hline
         \multirow{3}{*}{プロジェクト名}&\multicolumn{3}{c|}{従来手法} & \multicolumn{3}{c|}{提案手法} & \multicolumn{3}{c}{提案手法}\\
         &\multicolumn{3}{c|}{} & \multicolumn{3}{c|}{（クラスタリングなし）} & \multicolumn{3}{c}{（クラスタリングあり）}\\ \cline{2-10}
          & 適合率 & 再現率 & F1値 & 適合率 & 再現率 & F1値 & 適合率 & 再現率 & F1値\\ \hline
         \hline %
            python-bugzilla & 0.54 & 0.13 & 0.21 & \textbf{\underline{0.69}} & \textbf{\underline{0.64}} & \textbf{\underline{0.67}} & 0.63 & 0.23 & 0.33\\
            python-cloudant & \textbf{\underline{0.77}} & \textbf{\underline{0.81}} & \textbf{\underline{0.79}} & 0.17 & 0.17 & 0.17 & 0.65 & 0.32 & 0.43\\
            pynput & 0.41 & \textbf{\underline{0.94}} & 0.58 & 0.42 & 0.71 & 0.53 & \textbf{\underline{0.57}} & 0.65 & \textbf{\underline{0.61}}\\
            pyscard & \textbf{\underline{0.29}} & \textbf{\underline{0.91}} & \textbf{0.44} & 0.18 & 0.89 & 0.30 & 0.12 & 0.41 & 0.18\\
            howdoi & 0.92 & \textbf{\underline{0.96}} & \textbf{\underline{0.94}} & \textbf{\underline{0.93}} & 0.59 & 0.72 & \textbf{\underline{0.93}} & 0.51 & 0.66\\
            hickle & 0.33 & \textbf{\underline{0.73}} & 0.45 & 0.36 & 0.66 & \textbf{\underline{0.47}} & \textbf{\underline{0.41}} & 0.47 & 0.44\\
            transitions & \textbf{\underline{0.80}} & \textbf{\underline{0.87}} & \textbf{\underline{0.83}} & 0.68 & 0.5 & 0.57 & 0.68 & 0.21 & 0.32\\
            OWSLib & \textbf{\underline{0.84}} & 0.86 & \textbf{\underline{0.85}} & 0.76 & \textbf{\underline{0.92}} & 0.83 & 0.83 & 0.88 & \textbf{\underline{0.85}}\\
            schema\_salad & \textbf{\underline{0.52}} & \textbf{\underline{0.66}} & \textbf{\underline{0.58}} & 0.21 & 0.52 & 0.30 & 0.15 & 0.21 & 0.17\\
            schematics & \textbf{\underline{0.30}} & 0.79 & \textbf{\underline{0.44}} & 0.26 & \textbf{\underline{0.94}} & 0.41 & 0.27 & 0.84 & 0.40\\
    \hline
    \end{tabular}
\end{table*}
%--------------------

表\ref{PrevPrediction}は，従来手法，提案手法（クラスタリングなし），提案手法により構築した予測モデルの結果を示す．各プロジェクトにおいて3つの手法の中で最も予測性能の高い手法は太字と下線で示す．

\noindent\textbf{知見1: 複数プロジェクトの開発履歴を用いて構築した予測モデルの性能が，評価対象とするプロジェクトの過去の開発履歴のみを用いて構築した予測モデルよりも高い性能になることもある．}

各プロジェクトのF1値に着目すると，2プロジェクト（python\-bugzilla，hickle）は従来手法よりも提案手法（クラスタリングなし）のほうが予測性能が高く，2プロジェクト（pynput，OWSLib）は従来手法と比べて，提案手法（クラスタリングあり）と同等，またはそれよりも予測性能が高いが．その他の6プロジェクトは従来手法のほうが予測性能が高かった．複数のプロジェクトを使用したとしても精度が下がらないケースもあることを確認した．\todo{もう少し書いてもいいけど，ひとまずここまで．}

\noindent\textbf{知見2: 学習データの少ないプロジェクト（python\-bugzilla）は複数プロジェクトの開発履歴を用いることで，従来手法より高い精度で予測できる．}

python\-bugzillaは，従来手法のF1値が0.21であるが，提案手法（クラスタリングなし）と提案手法（クラスタリングあり）のF1値がそれぞれ0.67と0.33となり，複数プロジェクトの開発履歴を用いることにより精度が向上することを明らかとなった．クラスタリングするほうが精度が悪いのは．．．データ数が減るから？\todo{要修正}
python/-bugzillaほど少ないわけではないけど，howdoiもデータ数が少ないが，提案手法を用いることで精度が下がるのは，他のプロジェクトを踏襲できない？\todo{要修正}
pynputはpositiveが極端に少ないため，提案手法の方が精度高いと示唆される．同様にpython-cloudatnもpotsitiveが少ないが精度が下がった．こちらについては後ほど考察する．

hincleとOWSLibは従来手法と同じ精度，または僅差で提案手法なので，それほど効果があるとは言えない．

\colorbox{red}{{\bf ここまで修正完了}}


% 本手法の有効性を評価するために，2つのリサーチクエスチョン (RQ) に回答する．
% \begin{itemize}
%     \item RQ1 従来研究で修正予測できなかったデータの特徴とは
%     \item RQ2 クロスプレディクションを行った場合，従来研究で予測できなかった修正予測ができるのか
% \end{itemize}
% \vspace{0.2\baselineskip}  % 余白の調整
%
%RQ1では，従来手法で予測できていないデータの分析を行う．分析内容は，提案アプローチであるクラスタリングを行った結果を用いて，予測できなかったデータがどのクラスタに含まれるのかを確認する．予測できていないデータがそのプロジェクトが保持するデータの中で少数クラスタに存在すれば，提案アプローチが有効である可能性が考えられる．
%
%RQ2では実際に提案アプローチで構築した機械学習モデルの有効性を評価する．評価方法として修正優先度予測を行い，その適合率，再現率，F1値，正解率を比較することによって評価する．



表\ref{AproPredictionCrustering}は，本研究の提案手法において10のクラスタ分類したときの，クラスタ別の性能を示す．また，表\ref{PrevPredictionCrustering}，表\ref{MergePredictionCrustering}はそれぞれ提案手法（クラスタリングあり）と同じ評価データが，従来手法のモデルと提案手法（クラスタリングなし）のモデルを用いた場合の予測性能の結果を示す．

\noindent\textbf{知見3: 特定のクラスタのみで性能が向上するプロジェクトがある．}

python-bugzillaにおいてcluster 1とcluster 2では，大きな予測性能向上は見られないが，cluster 3では従来手法に比べて提案手法（クラスタリングなし）のモデルの予測性能が極めて向上している．また，sceme|\_saladでは，表\ref{PrevPrediction}において従来手法の方が提案手法よりも精度が高いが，cluster 4では従来手法よりも提案手法（クラスタリングなし）の方が予測性能が向上している．\todo{cluster4が何か書きたい．}hickleでは，表\ref{PrevPrediction}において従来手法の方が提案手法よりも高い予測性能であるが，cluster 3においてのみ提案手法（クラスタリングあり）が従来手法よりも高い予測性能となっている．\todo{hickleはcluster2しかないのに，なぜ全体的な精度は従来よりも低くなる？従来と同じ値になるはずでは？}

\noindent{知見4: 従来手法（評価対象プロジェクトの過去の開発データのみ用いたモデル）が提案手法に比べて高い性能となることもある．}

cluster 1やcluster 2は，分析対象とする全てのプロジェクトの規約違反を含んでおり，hickleのように高い性能となる場合もあるが，一方で，異なるプロジェクトを学習することで性能が低下することの方が多いことがわかった．



 



%\subsection{RQ1 従来研究で修正予測できなかったデータの特徴とは}
% \begin{table}[tb]
%     \centering
%     \caption{従来手法による修正優先度予測結果}
%     \label{PrevPrediction}
%     \begin{tabular}{|l|c|c|c|c|}
%          \hline
%          プロジェクト名 & 適合率 & 再現率 & F1値 & 正解率 \\ \hline
%          \hline %
%          pynput & 0.41 & 0.94 & 0.58 & 0.86 \\ \hline
%          pyscard & 0.29 & 0.91 & 0.44 & 0.78 \\ \hline
%          howdoi & 0.92 & 0.96 & 0.94 & 0.90 \\ \hline
%          schema\_salad & 0.52 & 0.66 & 0.58 & 0.74 \\ \hline
%          python-bugzilla & 0.54 & 0.13 & 0.21 & 0.31 \\ \hline
%          OWSLib & 0.84 & 0.86 & 0.85 & 0.82 \\ \hline
%          python-cloudant & 0.77 & 0.81 & 0.79 & 0.93 \\ \hline
%          hickle & 0.33 & 0.73 & 0.45 & 0.50 \\ \hline
%          transitions & 0.80 & 0.87 & 0.83 & 0.82 \\ \hline
%          schematics & 0.30 & 0.79 & 0.44 & 0.50 \\
%          \hline
%     \end{tabular}
% \end{table}

表\ref{PrevPrediction}は，従来手法による修正優先度予測の結果である．F1値が0.21から0.94まで幅広く存在しており，修正優先度予測の結果が安定していないことがわかる．この結果の原因を追求するために，それぞれの保有しているデータが，すべてのプロジェクト全体でどのような類似性があるファイルを使っているかを追求した．



\begin{table*}[tb]
    \centering
    \caption{クラスタリングによる従来手法の予測結果分析(k=10)}
    \label{PrevPredictionCrustering}
    \scalebox{0.8}{
    \begin{tabular}{|l|c|c|c|c|c|c|c|c|c|c|}
         \hline
         プロジェクト名 & cluster\_0 & cluster\_1 & cluster\_2 & cluster\_3 & cluster\_4 & cluster\_5 & cluster\_6 & cluster\_7 & cluster\_8 & cluster\_09\\ \hline
         \hline %
         python-bugzilla & 0.67* & -- & 0.33* & -- & 0.13* & -- & --* & -- & -- & -- \\ \hline
         python-cloudant & 0.95* & -- & 0.89* & -- & 0.89* & -- & 0.97* & -- & -- & -- \\ \hline
         pynput & 0.70* & -- & 0.35* & -- & -- & -- & -- & -- & -- & 1.00* \\ \hline
         pyscard & 0.76* & 1.00* & 0.78* & -- & -- & --* & -- & -- & 1.00* & -- \\ \hline
         howdoi & 0.57* & -- & 0.91* & -- & -- & -- & -- & -- & -- & -- \\ \hline
         hickle & -- & -- & 0.51* & -- & -- & -- & -- & -- & -- & -- \\ \hline
         transitions & 0.82* & -- & 0.86* & -- & --* & -- & 0.80* & -- & -- & -- \\ \hline
         OWSLib & 0.94* & 1.00* & 0.80* & -- & 1.00* & -- & 0.87* & 1.00* & -- & -- \\ \hline
         schema\_salad & 0.72* & -- & 0.86* & 0.62* & 0.92* & -- & 0.26* & -- & -- & -- \\ \hline
         schematics & 0.47* & -- & 0.47* & -- & -- & -- & 0.56* & -- & -- & -- \\
         \hline
    \end{tabular}
    }
\vspace{1mm}
    \centering
    \caption{クラスタリングによる提案手法の予測結果分析(k=10)}
    \label{AproPredictionCrustering}
    \scalebox{0.8}{
    \begin{tabular}{|l|c|c|c|c|c|c|c|c|c|c|}
         \hline
         プロジェクト名 & cluster\_0 & cluster\_1 & cluster\_2 & cluster\_3 & cluster\_4 & cluster\_5 & cluster\_6 & cluster\_7 & cluster\_8 & cluster\_09\\ \hline
         \hline %
         python-bugzilla & 0.67* & -- & 0.37* & -- & 0.27* & -- & --* & -- & -- & -- \\ \hline
         python-cloudant & 0.90* & -- & 0.77* & -- & 0.91* & -- & 0.73* & -- & -- & -- \\ \hline
         pynput & 0.80* & -- & 0.64* & -- & -- & -- & -- & -- & -- & 1.00* \\ \hline
         pyscard & 0.63* & 1.00* & 0.64* & -- & -- & --* & -- & -- & 1.00* & -- \\ \hline
         howdoi & 0.57* & -- & 0.55* & -- & -- & -- & -- & -- & -- & -- \\ \hline
         hickle & -- & -- & 0.67* & -- & -- & -- & -- & -- & -- & -- \\ \hline
         transitions & 0.61* & -- & 0.21* & -- & --* & -- & 0.53* & -- & -- & -- \\ \hline
         OWSLib & 0.95* & 1.00* & 0.80* & -- & 1.00* & -- & 0.86* & 1.00* & -- & -- \\ \hline
         schema\_salad & 0.44* & -- & 0.51* & 0.62* & 0.03* & -- & 0.22* & -- & -- & -- \\ \hline
         schematics & 0.23* & -- & 0.42* & -- & -- & -- & 0.55* & -- & -- & -- \\
         \hline
    \end{tabular}
    }
\vspace{1mm}

    \centering
    \caption{クラスタリングによる単純結合手法の予測結果分析(k=10)}
    \label{MergePredictionCrustering}
    \scalebox{0.8}{
    \begin{tabular}{|l|c|c|c|c|c|c|c|c|c|c|}
         \hline
         プロジェクト名 & cluster\_0 & cluster\_1 & cluster\_2 & cluster\_3 & cluster\_4 & cluster\_5 & cluster\_6 & cluster\_7 & cluster\_8 & cluster\_09\\ \hline
         \hline %
         python-bugzilla & 0.67* & -- & 0.42* & -- & 1.00* & -- & --* & -- & -- & -- \\ \hline
         python-cloudant & 0.71* & -- & 0.72* & -- & 0.73* & -- & 0.73* & -- & -- & -- \\ \hline
         pynput & 0.57* & -- & 0.56* & -- & -- & -- & -- & -- & -- & 1.00* \\ \hline
         pyscard & 0.58* & 1.00* & 0.60* & -- & -- & --* & -- & -- & 1.00* & -- \\ \hline
         howdoi & 0.57* & -- & 0.62* & -- & -- & -- & -- & -- & -- & -- \\ \hline
         hickle & -- & -- & 0.59* & -- & -- & -- & -- & -- & -- & -- \\ \hline
         transitions & 0.69* & -- & 0.60* & -- & --* & -- & 0.52* & -- & -- & -- \\ \hline
         OWSLib & 0.91* & 1.00* & 0.75* & -- & 1.00* & -- & 0.85* & 1.00* & -- & -- \\ \hline
         schema\_salad & 0.54* & -- & 0.09* & 0.78* & 0.03* & -- & 0.78* & -- & -- & -- \\ \hline
         schematics & 0.20* & -- & 0.34* & -- & -- & -- & 0.45* & -- & -- & -- \\
         \hline
    \end{tabular}
    }
\end{table*}


表\ref{PrevPredictionCrustering}は，従来手法で予測した結果をクラスタリング(k=10)の結果の分布に従ってそれぞれの正解率を記したものである．"--"が入っているものは，評価用データ内に正例 / 負例がともに存在しない場合である．この結果から分かることは，クラスタ0とクラスタ2の精度が他に比べて高く，"--"が多いことがわかる．これは，どのプロジェクトでも類似度が高いファイルがクラスタ0, 2に集約され，プロジェクトの差が出る他クラスタは，単一プロジェクト内でしか類似性が無いこということである．

表\ref{PrevPredictionCrustering}について詳細に言及すると，cluster\_4のpython-bugzillaは，他プロジェクトのcluster\_4の結果と比較して精度が低いことがわかる．cluster\_4のpython-bugzillaのテストデータは15件存在しており，そのうち2件しか正解していない．また，python-bugzillaは全体的な精度も低い．原因として，ほかのデータセットと比較して全体のコミット数が少なく，ロジスティック回帰のモデルが十分に学習できなかったが考えられる．このような事象に対して，本研究のアプローチである，クラスタリングの結果に基づいて他プロジェクトのデータも含めて学習を行うことで学習データを保管すれば精度向上を見込むことができる．

多くのデータが含まれるcluster\_0とcluster\_2は，自プロジェクトの他のクラスタに属する予測結果と比較して予測精度が低下していることがわかる．これは，互いに修正優先度の予測に有効なパラメータを相殺してしまっていると考えられる．

\subsection{RQ2 クロスプレディクションを行った場合，従来研究で予測できなかった修正予測ができるのか}
\subsubsection{従来手法の結果との比較}
% \begin{table}[tb]
%     \centering
%     \caption{提案手法による修正優先度予測結果(k=10)}
%     \label{AproachPrediction}
%     \begin{tabular}{|l|c|c|c|c|}
%          \hline
%          プロジェクト名 & 適合率 & 再現率 & F1値 & 正解率 \\ \hline
%          \hline %
%             pynput & 0.57 & 0.65 & 0.61 & 0.71 \\
%             pyscard & 0.12 & 0.41 & 0.18 & 0.64 \\
%             howdoi & 0.93 & 0.51 & 0.66 & 0.55 \\
%             schema\_salad & 0.15 & 0.21 & 0.17 & 0.44 \\
%             python-bugzilla & 0.63 & 0.23 & 0.33 & 0.36 \\
%             OWSLib & 0.83 & 0.88 & 0.85 & 0.82 \\
%             python-cloudant & 0.65 & 0.32 & 0.43 & 0.86 \\
%             hickle & 0.41 & 0.47 & 0.44 & 0.67 \\
%             transitions & 0.68 & 0.21 & 0.32 & 0.54 \\
%             schematics & 0.27 & 0.84 & 0.40 & 0.38 \\
%          \hline
%     \end{tabular}
% \end{table}

表\ref{AproachPrediction}は提案手法である，データセットを一度結合し，クラスタリングの結果に基づいて予測を行った結果の表である．従来手法と比較して１０プロジェクト中２プロジェクトでF1値の向上が確認できる．向上したプロジェクトはpython-bugzillaとpynputの2プロジェクトである．このうちpython-bugzillaはRQ1で考察したようにデータセットサイズが小さく，負例が大半を占めているため，提案手法によるデータセットの補完によって精度が向上したと考えられる．しかし，pynputプロジェクトのデータ数はほかのプロジェクトと比較して多いが，F1値は向上している．pynputプロジェクトの他のプロジェクトと異なる点は，正例の割合が0.11であることである．本研究で用いているロジスティック回帰モデルの構築方法は，オプションとして正例と負例の予測割合が等しくなるように重みづけを行っているため，従来手法のモデル構築方法では，重みづけが過度に発生するため予測精度が低下してしまい，提案手法によって過度の重みづけが解消され予測精度が向上したと考えられる．

\subsubsection{クラスタリングせずに全てのデータを学習データとした場合との結果の比較}
% \begin{table}[tb]
%     \centering
%     \caption{全てのデータセットをマージした学習データを利用した予測結果}
%     \label{AllPrediction}
%     \begin{tabular}{|l|c|c|c|c|}
%          \hline
%          プロジェクト名 & 適合率 & 再現率 & F1値 & 正解率 \\ \hline
%          \hline %
%             pynput & 0.42 & 0.71 & 0.53 & 0.87 \\
%             pyscard & 0.18 & 0.89 & 0.30 & 0.60 \\
%             howdoi & 0.93 & 0.59 & 0.72 & 0.61 \\
%             schema\_salad & 0.21 & 0.52 & 0.30 & 0.31 \\
%             python-bugzilla & 0.69 & 0.64 & 0.67 & 0.55 \\
%             OWSLib & 0.76 & 0.92 & 0.83 & 0.78 \\
%             python-cloudant & 0.17 & 0.17 & 0.17 & 0.72 \\
%             hickle & 0.36 & 0.66 & 0.47 & 0.59 \\
%             transitions & 0.68 & 0.50 & 0.57 & 0.62 \\
%             schematics & 0.26 & 0.94 & 0.41 & 0.32 \\
%          \hline
%     \end{tabular}
% \end{table}

表\ref{AllPrediction}は，機械学習モデルを構築する際に10プロジェクトの全ての学習データセットを，無秩序にマージしたものを学習データとして，それぞれのプロジェクトのテストデータを予測した結果である．この表と従来手法と提案手法の表である表\ref{PrevPrediction},\ref{AproachPrediction}の結果と比較すると従来手法より2プロジェクト，提案手法より6プロジェクトにおいて結果のF1値が向上していた．この結果は，仮説として立てていた「無秩序なデータセットの結合では，修正の特徴が大多数のデータに相殺され予測精度が低下する．」ことに矛盾する．


\section{考察}\label{sec:consideration}
RQの結果から，複数プロジェクトのデータセットを結合することによって，特定の状況下において予測精度が向上することが分かった．特定の状況下というのは，以下の2通りである．

\begin{itemize}
    \item 全体的な学習データ数が少ない場合
    \item 修正される（正例）の割合が非常に低い場合
\end{itemize}

これらの状況下では，従来手法でのモデル構築手法は学習データ不足の点から，うまく学習できず，データの類似性を問わず他プロジェクトのデータを結合することによって適度な正例割合を持つ学習データを確保するほうが予測に有効である．クラスタリングによる学習データセットの分割が予測に悪影響を与えた原因として，本研究では，クラスタ数10の場合で検証を行っており，一部のクラスタにデータが集まり，その他クラスタに少数のデータがクラスタリングされた．その結果データ数が多いクラスタは，それぞれのプロジェクトごとに存在する違反修正の特徴が汎化され，データ数が少ないクラスタは学習データが足りずに予測精度が下がってしまったと考えられる．この問題を解決するための今後の展望として，階層的クラスタリングを行った際に，ある深さで一直線に枝切りを行うのではなく，クラスタごとに恣意的に枝切りの場所を変化させて予測を行うことによって予測精度を向上させることができると考えられる．


\section{妥当性への脅威}\label{sec:heuristic}
\subsection{内的妥当性}
表\ref{AproachPrediction}の予測結果は，クラスタ数10にクラスタリングし，それぞれの予測モデルを作成した場合の予測結果であるが，クラスタリングされた学習データセット内に正例あるいは負例のどちらかしか存在しない場合，機械学習モデルは構築できず，予測をせずに学習データに含まれているラベルを返すような手法をとっているので，実際に機械学習モデルだけで予測した結果の精度とは異なっている．また本研究では，ロジスティック回帰モデルの学習のイテレーションの最大値を10,000回に設定しており，クラスタ数が少ない場合に，モデルが最後まで収束しないことが起きたため，最後まで収束させた場合の結果とでは若干のずれが生じる可能性がある．

提案手法または，クラスタリングを行わずに複数プロジェクトのデータをマージすることによって学習データの補完を行ったが，各プロジェクト内では時系列を考慮したデータセットの分割を行っているが，プロジェクト間では対象期間を考慮していないため，あるプロジェクトから見れば未来のデータを使っているので，本来起こり得ない学習を行なってしまっているので，プロジェクト間でも時系列を考慮した学習を行うことが今後の課題である．



\subsection{外的妥当性}
本研究ではケーススタディとして10プロジェクト分のデータを学習し予測を行ったが，データセットを拡張することによってそれぞれのクラスターごとのモデルが更に汎化され，各プロジェクトの予測に有効な特徴まで薄くなり，精度の低下につながる可能性がある．また，十分に成熟しているプロジェクトの場合，クラスタリングした学習データを用いるより，自プロジェクトの過去のデータだけを学習データとするほうが予測に効果的であることが考えられる．


\section{おわりに}\label{sec:end}
本研究では，静的解析ツールによって大量に検出されるコーディング規約に違反しているコード断片の中から，優先して修正すべき違反の予測を，複数プロジェクトのデータを結合し，類似性に基づいてクラスタリングしたデータセットを用いることによる予測精度への影響を明らかにした．検証の結果，予測精度だけを見れば，単一プロジェクトのデータだけを用いて学習するほうが予測に効果的であった．

\textbf{謝辞}\

\textbf{ありがとうございます．}

% 本フォーマットの基になったスタイルファイルを作成してくださった方々に感謝します．

\bibliographystyle{junsrt}
\bibliography{kameoka}


\end{document}

