\documentclass[T,J]{fose} % 「コンピュータソフトウェア」用のクラスファイルは compsoft です．
\taikai{2024}


\usepackage [dvipdfmx] {graphicx}

% ユーザが定義したマクロなどはここに置く．
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage[dvipdfmx]{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{listings}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\newcommand{\todo}[1]{\colorbox{yellow}{{\bf TODO}:}{\color{red} {\textbf{[#1]}}}}

\lstset{
basicstyle=\small\ttfamily,
abovecaptionskip=0pt,
captionpos=b,
frame=tb,
framexleftmargin=2em,
numbers=left,
numberstyle={\scriptsize},
xleftmargin=\parindent
}

%ListingのキャプションがFigureになってしまうのをListingに直すコマンド
\usepackage{caption}
\makeatletter
\let\MYcaption\@makecaption
\makeatother
\usepackage{caption}
\makeatletter
\let\@makecaption\MYcaption
\makeatother


\begin{document}

\title{○○○○○○○○○○○○○○○○}
\setetitle{○○○○○○○○○○○○○○○○}

\author{大森 楓己　伊原 彰紀　柏 祐太郎
\ejtitle{\etitle}
\shozoku{Fuki Omori, Akinori Ihara}{和歌山大学}
{Wakayama University}
\shozoku{Yutaro Kashiwa}{奈良先端科学技術大学院大学}
{Nara Institute of Science and Technology}
}

% 和文アブストラクト
\Jabstract{
○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○
}
% 英文アブストラクト（本サンプルの原論文にはなし）
\Eabstract{
○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○○
}
\maketitle \thispagestyle {empty}

\section{はじめに}
プログラムは，その外的振る舞いが等しい別のプログラムに書き換えることで品質を高めることができる．そのような改良はリファクタリングと呼ばれ，保守性や性能効率性等さまざまな品質を高めるために行われる．例えば，Webアプリケーション開発ではリファクタリングを行うことでプログラムの実行を25\%から70\%高速化できる\cite{Selakovic_2016}．

リファクタリングはプログラム開発における重要なステップであり，これを効率化するため欠陥箇所の検出や修正を自動化する手法が多数提案されている．例えばプログラムの可読性は，命名規則や文法上の欠陥を修正する静的解析ツール\footnote{https://eslint.org/}によって欠陥箇所を容易に特定することができ，それらを自動修正する研究は多数発表されている\todo{要引用}．一方で，実行速度の遅いプログラムに対する自動修正に関する研究は数少ない．速度上の欠陥はベンチマークテストを用いて定期的に実行速度を測定することで実行速度が低下する原因箇所を特定するが，実行速度を高めるための改良は糖衣構文や外部ライブラリ等の知識に依存した非自明な代替実装を発見するための知識を要する．特に，JavaScriptに代表される動的型付け言語は設計上，静的解析によるトレースが困難であるため代替実装の発見には一層の技術的課題が存在する．これは多くの動的型付け言語がインタプリタ言語であり，その実行速度がコンパイラ言語に比べて遅いことを考えると，非常に重要な問題である．

実行速度の欠陥を修正する開発者はどのように代替実装の知識をどのように得ることができるか？JavaScript開発者にとっては，マイクロベンチマーク共有サービス\footnote{https://jsperf.app/}が学習手段の1つである．このサービスを介して，開発者はJavaScriptプログラムをブラウザ上で実行し，その実行速度を測定できる．開発者は外的振る舞いが互いに等しいJavaScriptプログラム同士の実行速度を比較することで，より高速な実装を確認できる．さらに，比較されたプログラムセットは保存され，すべてのユーザに公開される．このプログラムセット（大抵は非常に短いコードスニペット）はマイクロベンチマークと呼ばれる．開発者は，サービスに保存されているマイクロベンチマークを検索することで未知の実装を学習できる．以下にマイクロベンチマークの例を示す:\todo{listing1,2,3を1つにまとめたい．}

%----------------------------------
\begin{figure*}[t]
\captionsetup{name=Listing}
  \caption{Setup}\label{setup}
\begin{lstlisting}
var i, array = []
for(i=0; i<10000; i++)
    array[i] = i;
\end{lstlisting}
  \begin{minipage}[b]{0.48\linewidth}
  \caption{Test Program 1}\label{test-a}
\begin{lstlisting}[firstnumber=4]
for(i=0; i<array.length; i++)
    console.log(array[i]);
\end{lstlisting}
  \end{minipage}
    \hspace{0.07\columnwidth} % ここで隙間作成
  \begin{minipage}[b]{0.48\linewidth}
    \caption{Test Program 1}\label{test-b}
\begin{lstlisting}[firstnumber=4]
array.forEach((item) => console.log(item));
\end{lstlisting}
  \vspace{3.5mm}
  \end{minipage}
\end{figure*}
%----------------------------------

マイクロベンチマーク全体は，1つのセットアッププログラムと1つ以上のテストプログラムからなり，各テストプログラムを実行する前にセットアッププログラムが実行される．マイクロベンチマーク共有サービス上では，セットアッププログラムの実行速度は測定されず，テストプログラムの実行速度のみが測定される．以下で両プログラムの役割について説明する．


\begin{description}

\item[セットアッププログラム]\mbox{}\\
実行速度を測定する前に，テストプログラム中で用いる配列や関数を定義するプログラム部である．1つのセットアッププログラムが，すべてのテストプログラムに共通して使用される．例えばプログラム\ref{setup}では，後にテストプログラム\ref{test-a}および\ref{test-b}で使用する配列を定義している．

\item[テストプログラム]\mbox{}\\
実行速度を測定する1つ以上の実装を記述するプログラム部である．例えばプログラム\ref{test-a}および\ref{test-b}では，外的振る舞いが互いに等しい2つの実装をそれぞれ記述している．

\end{description}


このサービスは膨大かつ多様なマイクロベンチマークを提供するが，これを用いた実行速度上の欠陥の自動検出・修正手法は筆者らの知る限り提案されていない．本研究では，マイクロベンチマーク共有サービスからリファクタリングのための大規模なデータセットを作成し，実行速度の向上のための2種の自動修正モデルを作成する．2種のモデルとは，パターンマッチを用いた自動修正モデルおよび深層学習を用いた自動修正モデルである．第1に，パターンマッチモデルを作成して従来手法と比較することでマイクロベンチマーク共有サービスをもとにした学習データセットの有用性を明らかにする．第2に，深層学習モデルを作成して提案パターンマッチモデルおよび従来手法と比較することで，リファクタリングタスクにおける最新の言語処理技術の有効性を明らかにする．特に，深層学習モデルはパターンマッチモデルとは異なり周辺のコンテキストを入力に含むため，より文意に沿った柔軟な修正が行えることが期待される．JavaScriptプログラムに対しては静的解析による実行フローの同定が困難であるため，このような特徴は深層学習モデルの大きな優位性になりうる．一方で，修正箇所が大規模である場合等には機械的なパターンマッチモデルがむしろ有効であることも考えられる．両モデルを比較することで，それぞれの適正な修正対象を明らかにする．

\todo{続く，2章では．．．3章では．．．}


%%%%%%%%%%%%%%%%
\section{関連研究}\label{sec:related}
%%%%%%%%%%%%%%%%
Selakovicら\cite{Selakovic_2016}は，JavaScriptプロジェクトにおいて開発者が高速化のために行ったリファクタリングを調査した．その結果，広くリファクタリングが試まれているにも関わらず，実際には半数の改良が失敗していることを明らかにした．この結果は本研究課題の重要性を示している．また，\cite{Selakovic_2016}はJavaScriptプロジェクトの解析によって10件の頻出する改良パターンを得た．この正規表現パターンを用いた自動修正モデルは一定の高速化効果を示しているが，修正機会の網羅には至っていない．我々は，マイクロベンチマークから大規模なデータセットを構築することによってこのモデルを改良する．

Gongら\cite{Gong_2015}はJITコンパイラによる高速化のアンチパターンとなるプログラムをJIT-unfriendlyと形容し，JIT-unfriendlyなプログラムに対する修正パターンを7件提案した．この修正パターンのマッチングは動的解析によって取得した情報を用いる点で，我々の提案モデルに対して優位性を持つ．一方で，パターン数については提案モデルが大きく上回る．我々は，静的解析のみを用いた自動修正モデルの最新の修正性能を明らかにする．

Selakovicら\cite{Selakovic_2017}は条件式の演算順序に着目し，動的解析と探索的手法を用いて条件演算を最適化する自動修正モデルを提案した．このモデルは探索的手法を用いる点で，局所的な実装の修正による高速化の1つの上限を示すものである．したがって，\cite{Selakovic_2017}と我々の提案モデルを比較することで高速化効果を明らかにする．

また，近年では大規模な開発履歴を活用した深層学習によるプログラム自動生成手法が多く提案されていることも特筆に値する．特にOpenAIによって開発されたChatCPTモデルはソフトウェア開発のみならず，非常に広範なタスクで人間の専門家に近い性能を誇る．しかし，その詳細な学習データセットは公開されておらず，高速化修正タスクにおける性能は明らかではない．一般に開発者が行うリファクタリングは複数の品質を考慮することが多く，他の品質（例えば可読性）を向上させるために実行速度を低下させるような修正や，改良に失敗しているような修正も行われる場合がある．頻繁に行われる改良が必ずしも高速化にとって最適とは限らないため，既存の大規模学習モデルが最適な代替実装を学習しているとは限らない．提案手法は実行速度の観点からのみ学習データセットを作成するため，特定の領域では既存手法を上回ると考える．本研究では，従来モデルの中でも特に高い性能を持つGPTモデルと提案手法を比較し，実行速度の改良に特化した学習データセットの有用性を明らかにする．

todo


\section{方法論}

自動修正モデルを作成するため，マイクロベンチマーク共有サービスから互いに代替可能な実装対を収集する．実装対の収集および自動修正モデルの作成概要を図\ref{fig-overview}に示す．また，以下で各ステップを説明する．

\begin{figure*}[t]
\centerline{\includegraphics[width=1.0\linewidth]{Omori_fig/dummy.pdf}}
\caption{overview}
\label{fig-overview}
\end{figure*}


\subsection{マイクロベンチマークの収集}
マイクロベンチマーク共有サービスjsPerfからプログラムセットを収集する．ただし，jsPerfには既存のマイクロベンチマークを修正し，新たなリビジョンとして保存する機能が有るため，複数のリビジョンを持つマイクロベンチマークによってデータセットが偏るおそれがある．これを防ぐため，我々は最新リビジョンのマイクロベンチマークのみを収集する．\todo{Setup，比較しているProgramをすべて収集する．できればSetupと比較プログラムを合わせてトピックのような名前をつけておきたい．}

\subsection{実行時間の測定}
マイクロベンチマーク中のセットアッププログラムとテストプログラムを結合し，プログラム全体の時間を計測する．測定後，実行時間の長いプログラムと短いプログラムを対応づけ，修正前後の対を作成する．測定手順は従来研究に従う．まず，NVMインスタンスを起動し，NwarmUp回プログラムを実行する．これにより，JITコンパイラをウォーミングアップさせる．続けて，Nmeasure回プログラムを実行し，その実行時間を測定する．この手順を繰り返してNVM回の測定を行い，プログラムごとにNVM個の測定結果を得る．測定結果から実行時間の95\%信頼区間を算出し，その閉区間に重なりのない実装対を収集する．\todo{重なったら対象外？データセットではどれぐらいあるのか要説明．}次のステップでは，この実装対のうち実行時間の長い方を変更元，短い方を変更先としてその変換をモデルに学習させる．本ステップでは，テストプログラムについてプログラム1回の実行時間や計測器の分解能を考慮してNwarmUp=5，Nmeasure=1,000，NVM=10に設定する．また，JavaScript実行環境にはNode.jsを用いる．すべての測定はCPUコア数12のIntel(R) Xeon(R) Silver 4214R CPU @ 2.40GHz上で行う．


\subsection{前処理}
一般的に，プログラム自動修正モデルの作成時には汎化性能を高めるために学習プログラムセット中の変数名や関数名，リテラルの抽象化を行う．本研究でも同様にプログラムセットに対して抽象化を施す．ただし，一般的なプログラム自動修正モデルがバグ修正への利用を目的として作成されるのに対して我々の提案手法はリファクタリングへの利用を目的としているため，バグ修正タスクとは異なる手法で抽象化を施す．具体的には，変数名，関数名，リテラルのうち，特定のトークンのみを抽象化する．以下でそれぞれの抽象化基準について説明する．


\begin{description}

\item[変数名]\mbox{}\\
プログラム中で宣言されている変数のみを抽象化する．プログラム\ref{test-a}中のlengthのようなプログラム中で明示的に宣言されていないメンバ変数は，同等の実装において常に固定の変数名を持つため，抽象化しない．抽象化後の変数名は，VAR\_1のようになる．

\item[関数名]\mbox{}\\
変数名と同様に，プログラム中で宣言されている関数のみを抽象化する．抽象化後の関数名は，FUNCTION\_1のようになる．

\item[リテラル]\mbox{}\\
すべて抽象化しない．これは，リテラルを抽象化することで修正を捉えられなくなるパターンが一定数存在するためである．\todo{事例を使って説明}

\end{description}


実装対の両方に共通する変数名や関数名の抽象化後トークン名を一致させるため，GumTree\cite{Falleri_2014}を用いて修正元のプログラムと修正先のプログラムの共通部分を検出した．その際，処理に時間がかかることから，文字数\todo{ノード数ではなく，文字数？}が多い上位5\%のプログラムを除外し，95\%分位までのプログラムのみを対象\todo{対象外とするのはIII-A節でかけるのでは？}とした．

また，マイクロベンチマーク内でセットアッププログラムが共通して用いられるため，プログラム中に使用されていない変数や関数が有る場合がある．このようなコードスニペットは学習の妨げになるため，プログラムから除去する．使用されていない変数や関数の検出には，静的解析ツールESLintを使用する．

例えばプログラム\ref{test-a}および\ref{test-b}に対して前処理を行った場合，最終的なプログラムは以下のようになる．


\begin{lstlisting}[caption=Abstracted Program 1, label=abstract-a,captionpos=t]
var VAR_1, VAR_2 = []
for(VAR_1=0; VAR_1<10000; VAR_1++)
    VAR_2[VAR_1] = VAR_1;

for(VAR_1=0; VAR_1<VAR_2.length; VAR_1++)
    console.log(VAR_2[VAR_1]);
\end{lstlisting}

\begin{lstlisting}[caption=Abstracted Program 2, label=abstract-b,captionpos=t]
var VAR_1, VAR_2 = []
for(VAR_1=0; VAR_1<10000; VAR_1++)
    VAR_2[VAR_1] = VAR_1;

VAR_2.forEach((VAR_3) => console.log(VAR_3));
\end{lstlisting}


\subsection{モデル構築}
\subsubsection{パターンマッチモデルの作成}
抽象構文木上で実装対の差分を抽出し，修正ルールを作成する．提案手法では従来研究と異なり，抽象構文木に基づいたパターンを作成することで，正規表現パターンよりも細かなプログラムを作成する．実装対の差分はGumTreeを用いて検出する．実装対の修正箇所は1箇所とは限らないため，修正ルールは複数のパターン対からなることがある．例えばプログラム\ref{test-a}と\ref{test-b}はforEachメソッドとfor文との書き換えに加え，変数itemとarray\_iの書き換えという2つのパターン対からなる．それぞれのパターン対は部分木の追加または部分木の削除，またはその両方の3種類に分けられる．ただし，部分木の追加のみからなる修正ルールは検出不可能であるため，データセットから除外する．また，基本的にパターン化する部分木はGumTreeによって検出された箇所に従うが，特殊な場合には部分木を拡大して（ルートノードをさらに浅い先祖ノードに変更して）パターン化する．特殊な場合とは，メンバ変数を書き換える場合と引数を書き換える場合である．メンバ変数を書き換える場合，そのメンバ変数を持つオブジェクトに応じて書き換え可能かが変化するため，オブジェクトまでをパターンに含める．同様に，引数を変更する場合もその引数を取る関数またはメソッドまでをパターンに含める．また，リテラルについては型レベルに抽象化し，パターンを検出する．


\subsubsection{深層学習モデルの作成}
本研究では事前学習モデルCodeT5+を用いてプログラム自動修正モデルを作成する．CodeT5+はオープンソースソフトウェア開発履歴をもとにプログラミング言語間，自然言語-プログラミング言語間の変換タスクについて膨大な学習を施された最新の大規模事前学習モデルである．本研究では，マイクロベンチマークから作成したデータセットを用いてCodeT5+をファインチューニングし，高速化のためのリファクタリングタスクに適用させる．ハイパーパラメータには，エポック数10，学習率2e-5，バッチサイズ8，最大トークン長400を設定した．



\section{評価実験}
提案モデルによる修正効果を明らかにするため，本研究では2つの評価実験を行う．第1に，学習データセットを10分割し，交差検証を行う．これは提案モデルがどれほど修正方法を学習しているかを明らかにするためである．第2に，GitHubプロジェクトに対して提案モデルを用いた修正を試み，その修正効果を既存モデルと比較する．これにより，既存モデルと比較した提案モデルの定量的な修正性能を明らかにする．

\subsection{10分割交差検証}
学習データセットの90\%のみを用いて2つの提案モデルそれぞれを作成する．そして，学習に用いなかった残り10\%の実装対を用いて提案モデルの性能を検証する．具体的には，検証用に残した実装対のうち，修正元となる実行時間の長い方のプログラムを提案モデルに入力し，修正プログラムを出力させる．修正成否は，実装対のうち修正先となる実行時間の短い方のプログラムに完全一致する修正プログラムを生成できるか否かをもとに判定する．

\subsection{GitHubプロジェクトへの適用}
評価データセットとして，従来研究において特定された，開発者による高速化のためのリファクタリングが行われたGitHubプルリクエストを使用する．このデータセットは，クライアントサイドとサーバサイドの両プロジェクトを含むプルリクエスト100件の変更差分およびテストプログラム，ベンチマークからなるデータセットである．このデータセットを用いて，提案モデルと4つの既存モデル\cite{Selakovic_2016}\cite{Gong_2015}\cite{Selakovic_2017}\footnote{https://chat.openai.com/}，開発者による修正とを比較する．既存モデルの実装は，それぞれの著者が公開する公式のツール\footnote{https://github.com/marijaselakovic/JavaScriptIssuesStudy}\footnote{https://github.com/Berkeley-Correctness-Group/JITProf}\footnote{https://github.com/Samsung/jalangi2}を用いる．

具体的にはまず，それぞれのモデルにプルリクエスト投稿時点のプログラムを入力する．各モデルが出力した修正プログラムに対して，プロジェクトに付属のテストプログラムを適用して動作を確認する．テストプログラムを通過した修正プログラムに対してベンチマークまたはテストプログラムの実行時間を測定し，修正効果を検証する．実行時間の詳細な測定方法は前章と同様である．

\section{結果}
結果．


\section{おわりに}
まとめ．


\textbf{謝辞}\
本フォーマットの基になったスタイルファイルを作成してくださった方々に感謝します．


%\begin{adjustvboxheight} % needed only when Appendix follows
\bibliographystyle{jssst}
\bibliography{sample}
%\end{adjustvboxheight} % needed only when Appendix follows

%\begin{adjustvboxheight} % needed only when Appendix follows
\begin{thebibliography}{9}
\bibitem{Selakovic_2016}
    M. Selakovic, and M. Pradel,
    "Performance issues and optimizations in JavaScript: an empirical study,"
    in Proceedings of the 38th International Conference on Software Engineering (ICSE),
    2016,
    pp.61-72.
\bibitem{Gong_2015}
    L. Gong, M. Pradel, and K. Sen,
    "JITProf: pinpointing JIT-unfriendly JavaScript code,"
    in Proceedings of the 2015 10th Joint Meeting on Foundations of Software Engineering (ESEC/FSE),
    2015,
    pp.357-368.
\bibitem{Selakovic_2017}
    M. Selakovic, T. Glaser, and M. Pradel,
    "An actionable performance profiler for optimizing the order of evaluations,"
    in Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA),
    2017,
    pp.170-180.
\bibitem{Falleri_2014}
    J.R. Falleri, F. Morandat, X. Blanc, M. Martinez, and M. Monperrus,
    "Fine-grained and accurate source code differencing,"
    in Proceedings of the 29th ACM/IEEE International Conference on Automated Software Engineering (ASE),
    2014,
    pp.313-324.
\bibitem{Wang_2023}
    Y. Wang, H. Le, A. D. Gotmare, N. D. Q. Bui, J. Li, and S. C. H. Hoi,
    "CodeT5+: Open Code Large Language Models for Code Understanding and Generation,"
    arXiv preprint,
    2023.
\end{thebibliography}
%\end{adjustvboxheight} % needed only when Appendix follows

%以下は付録の例です．必要ならコメントアウトして使用してください．
%なお，その際には参考文献の前後にある adjustvboxheight 環境のコメントアウトを解除してください．
%\appendix
%\section{付録A} 
%これは付録の例です．

\end{document}

